{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 🚀 Risk Model Pipeline - Master End-to-End Notebook\n",
    "\n",
    "Bu notebook baştan sona tüm pipeline'ı çalıştırır:\n",
    "- Kurulum (pip install)\n",
    "- Data hazırlama\n",
    "- Veri sözlüğü oluşturma\n",
    "- Model eğitimi\n",
    "- Kalibrasyon\n",
    "- Skorlama\n",
    "- Raporlama\n",
    "\n",
    "**NOT:** Tüm hücreler sırayla çalıştırılmalıdır."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 📦 BÖLÜM 1: KURULUM VE IMPORT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1.1 - Paket Kurulumu (ilk kurulum için)\n",
    "# NOT: Eğer zaten kuruluysa bu hücreyi atlayabilirsiniz\n",
    "\n",
    "# GitHub'dan kurulum\n",
    "!pip install git+https://github.com/selimoksuz/risk-model-pipeline.git\n",
    "\n",
    "# Veya lokal kurulum (eğer clone yaptıysanız)\n",
    "# !pip install -e ../  # notebook klasöründen bir üst dizin\n",
    "\n",
    "print(\"✅ Paket kurulumu tamamlandı!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1.2 - Gerekli kütüphaneleri import et\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "import os\n",
    "import sys\n",
    "import json\n",
    "import joblib\n",
    "from datetime import datetime, timedelta\n",
    "from pathlib import Path\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Pipeline imports\n",
    "try:\n",
    "    from risk_pipeline.pipeline16 import RiskModelPipeline, Config\n",
    "    from risk_pipeline.utils.pipeline_runner import run_pipeline_from_dataframe\n",
    "    from risk_pipeline.utils.scoring import score_data, load_model_artifacts\n",
    "    print(\"✅ Pipeline modülleri başarıyla import edildi (pip install)\")\n",
    "except ImportError:\n",
    "    # Lokal import (eğer pip install yapmadıysanız)\n",
    "    sys.path.append('..')\n",
    "    from src.risk_pipeline.pipeline16 import RiskModelPipeline, Config\n",
    "    from src.risk_pipeline.utils.pipeline_runner import run_pipeline_from_dataframe\n",
    "    from src.risk_pipeline.utils.scoring import score_data, load_model_artifacts\n",
    "    print(\"✅ Pipeline modülleri başarıyla import edildi (lokal)\")\n",
    "\n",
    "print(f\"Python version: {sys.version}\")\n",
    "print(f\"Pandas version: {pd.__version__}\")\n",
    "print(f\"Numpy version: {np.__version__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 📊 BÖLÜM 2: VERİ HAZIRLAMA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2.1 - Ana veri setini oluştur\n",
    "np.random.seed(42)  # Tekrarlanabilirlik için\n",
    "\n",
    "# Parametreler\n",
    "n_train = 10000  # Eğitim verisi boyutu\n",
    "n_calibration = 2000  # Kalibrasyon verisi boyutu\n",
    "n_scoring = 3000  # Skorlama verisi boyutu\n",
    "\n",
    "print(\"📊 Veri setleri oluşturuluyor...\")\n",
    "\n",
    "# Yardımcı fonksiyon: Veri seti oluştur\n",
    "def create_dataset(n_samples, start_date, id_prefix, target_rate=0.2, add_missing=True):\n",
    "    \"\"\"Risk modeli için sentetik veri oluştur\"\"\"\n",
    "    \n",
    "    df = pd.DataFrame({\n",
    "        # ID ve tarih\n",
    "        'app_id': [f'{id_prefix}_{i:06d}' for i in range(n_samples)],\n",
    "        'app_dt': pd.date_range(start_date, periods=n_samples, freq='D'),\n",
    "        \n",
    "        # Target\n",
    "        'target': np.random.binomial(1, target_rate, n_samples),\n",
    "        \n",
    "        # Numerik özellikler\n",
    "        'yas': np.random.randint(18, 70, n_samples),\n",
    "        'gelir': np.random.lognormal(10, 0.5, n_samples),\n",
    "        'kredi_skoru': np.random.normal(650, 100, n_samples).clip(300, 850),\n",
    "        'borc_tutari': np.random.exponential(30000, n_samples),\n",
    "        'kredi_tutari': np.random.exponential(50000, n_samples),\n",
    "        'calisma_suresi': np.random.exponential(5, n_samples).clip(0, 40),\n",
    "        'bagimlı_sayisi': np.random.poisson(1.5, n_samples).clip(0, 6),\n",
    "        'ev_deger': np.random.lognormal(12, 0.8, n_samples),\n",
    "        \n",
    "        # Kategorik özellikler\n",
    "        'egitim': np.random.choice(['Ilkokul', 'Lise', 'Lisans', 'Y.Lisans', 'Doktora'], \n",
    "                                   n_samples, p=[0.1, 0.3, 0.35, 0.2, 0.05]),\n",
    "        'istihdam': np.random.choice(['Maasli', 'Serbest', 'Emekli', 'Ogrenci', 'Issiz'], \n",
    "                                     n_samples, p=[0.5, 0.25, 0.1, 0.05, 0.1]),\n",
    "        'medeni_hal': np.random.choice(['Bekar', 'Evli', 'Bosanmis', 'Dul'], \n",
    "                                       n_samples, p=[0.3, 0.5, 0.15, 0.05]),\n",
    "        'konut_durumu': np.random.choice(['Kendi', 'Kira', 'Aile', 'Lojman'], \n",
    "                                         n_samples, p=[0.4, 0.35, 0.2, 0.05]),\n",
    "        'sehir_tipi': np.random.choice(['Buyuksehir', 'Sehir', 'Ilce', 'Koy'], \n",
    "                                       n_samples, p=[0.4, 0.3, 0.2, 0.1]),\n",
    "        'bolge': np.random.choice(['Marmara', 'Ege', 'Akdeniz', 'IC_Anadolu', 'Karadeniz', 'Dogu', 'GDogu'], \n",
    "                                 n_samples, p=[0.3, 0.15, 0.15, 0.15, 0.1, 0.1, 0.05]),\n",
    "        'sektor': np.random.choice(['Kamu', 'Ozel', 'Serbest'], n_samples, p=[0.3, 0.5, 0.2]),\n",
    "        'cinsiyet': np.random.choice(['E', 'K'], n_samples, p=[0.52, 0.48])\n",
    "    })\n",
    "    \n",
    "    # Eksik değerler ekle (gerçekçilik için)\n",
    "    if add_missing:\n",
    "        missing_cols = ['calisma_suresi', 'bagimlı_sayisi', 'medeni_hal', 'sektor']\n",
    "        for col in missing_cols:\n",
    "            missing_idx = np.random.choice(df.index, size=int(0.05 * len(df)), replace=False)\n",
    "            df.loc[missing_idx, col] = np.nan\n",
    "    \n",
    "    return df\n",
    "\n",
    "print(\"✅ Veri oluşturma fonksiyonu hazır\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2.2 - Veri setlerini oluştur\n",
    "\n",
    "# Eğitim verisi\n",
    "train_df = create_dataset(\n",
    "    n_samples=n_train,\n",
    "    start_date='2022-01-01',\n",
    "    id_prefix='TRAIN',\n",
    "    target_rate=0.15  # %15 default rate\n",
    ")\n",
    "\n",
    "# Kalibrasyon verisi (biraz farklı dağılım)\n",
    "calibration_df = create_dataset(\n",
    "    n_samples=n_calibration,\n",
    "    start_date='2023-07-01',\n",
    "    id_prefix='CAL',\n",
    "    target_rate=0.18  # Biraz daha yüksek default rate\n",
    ")\n",
    "\n",
    "# Skorlama verisi (bazıları target'sız)\n",
    "scoring_df = create_dataset(\n",
    "    n_samples=n_scoring,\n",
    "    start_date='2023-10-01',\n",
    "    id_prefix='SCORE',\n",
    "    target_rate=0.20\n",
    ")\n",
    "\n",
    "# Skorlama verisinin bir kısmını target'sız yap\n",
    "no_target_idx = np.random.choice(scoring_df.index, size=int(0.6 * len(scoring_df)), replace=False)\n",
    "scoring_df.loc[no_target_idx, 'target'] = np.nan\n",
    "\n",
    "print(\"📊 Veri Setleri Özeti:\")\n",
    "print(\"=\"*60)\n",
    "print(f\"1. Eğitim Verisi:\")\n",
    "print(f\"   - Shape: {train_df.shape}\")\n",
    "print(f\"   - Target rate: {train_df['target'].mean():.2%}\")\n",
    "print(f\"   - Tarih aralığı: {train_df['app_dt'].min()} - {train_df['app_dt'].max()}\")\n",
    "\n",
    "print(f\"\\n2. Kalibrasyon Verisi:\")\n",
    "print(f\"   - Shape: {calibration_df.shape}\")\n",
    "print(f\"   - Target rate: {calibration_df['target'].mean():.2%}\")\n",
    "print(f\"   - Tarih aralığı: {calibration_df['app_dt'].min()} - {calibration_df['app_dt'].max()}\")\n",
    "\n",
    "print(f\"\\n3. Skorlama Verisi:\")\n",
    "print(f\"   - Shape: {scoring_df.shape}\")\n",
    "print(f\"   - Target olan: {(~scoring_df['target'].isna()).sum()} kayıt\")\n",
    "print(f\"   - Target olmayan: {scoring_df['target'].isna().sum()} kayıt\")\n",
    "print(f\"   - Tarih aralığı: {scoring_df['app_dt'].min()} - {scoring_df['app_dt'].max()}\")\n",
    "\n",
    "print(\"\\n✅ Tüm veri setleri hazır!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 📚 BÖLÜM 3: VERİ SÖZLÜĞÜ HAZIRLAMA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3.1 - Veri sözlüğü oluştur\n",
    "\n",
    "data_dictionary = pd.DataFrame({\n",
    "    'alan_adi': [\n",
    "        'yas', 'gelir', 'kredi_skoru', 'borc_tutari', 'kredi_tutari', \n",
    "        'calisma_suresi', 'bagimlı_sayisi', 'ev_deger',\n",
    "        'egitim', 'istihdam', 'medeni_hal', 'konut_durumu', \n",
    "        'sehir_tipi', 'bolge', 'sektor', 'cinsiyet'\n",
    "    ],\n",
    "    'alan_aciklamasi': [\n",
    "        'Müşteri yaşı (yıl)',\n",
    "        'Aylık gelir tutarı (TL)',\n",
    "        'Kredi risk skoru (300-850)',\n",
    "        'Mevcut borç tutarı (TL)',\n",
    "        'Talep edilen kredi tutarı (TL)',\n",
    "        'Mevcut işyerinde çalışma süresi (yıl)',\n",
    "        'Bakmakla yükümlü kişi sayısı',\n",
    "        'Konut değeri (TL)',\n",
    "        'En yüksek eğitim seviyesi',\n",
    "        'İstihdam durumu',\n",
    "        'Medeni durum',\n",
    "        'Konut sahiplik durumu',\n",
    "        'Yerleşim yeri tipi',\n",
    "        'Coğrafi bölge',\n",
    "        'Çalışılan sektör',\n",
    "        'Cinsiyet (E/K)'\n",
    "    ]\n",
    "})\n",
    "\n",
    "print(\"📚 Veri Sözlüğü:\")\n",
    "print(\"=\"*80)\n",
    "print(data_dictionary.to_string(index=False))\n",
    "\n",
    "# Excel'e de kaydet (opsiyonel)\n",
    "data_dict_path = 'outputs/data_dictionary.xlsx'\n",
    "os.makedirs('outputs', exist_ok=True)\n",
    "data_dictionary.to_excel(data_dict_path, index=False)\n",
    "print(f\"\\n✅ Veri sözlüğü kaydedildi: {data_dict_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ⚙️ BÖLÜM 4: PIPELINE KONFIGÜRASYONU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4.1 - Pipeline konfigürasyonunu oluştur\n",
    "\n",
    "cfg = Config(\n",
    "    # Kolon tanımları\n",
    "    id_col='app_id',\n",
    "    time_col='app_dt',\n",
    "    target_col='target',\n",
    "    \n",
    "    # Veri bölme ayarları\n",
    "    use_test_split=True,\n",
    "    test_size_row_frac=0.2,  # %20 test\n",
    "    oot_window_months=3,  # 3 aylık OOT penceresi\n",
    "    \n",
    "    # Veri sözlüğü ve kalibrasyon\n",
    "    data_dictionary_df=data_dictionary,  # Veri sözlüğü DataFrame\n",
    "    calibration_df=calibration_df,  # Kalibrasyon DataFrame\n",
    "    calibration_method='isotonic',  # Kalibrasyon metodu\n",
    "    \n",
    "    # Model ayarları\n",
    "    cv_folds=5,  # Cross-validation fold sayısı\n",
    "    random_state=42,\n",
    "    n_jobs=-1,  # Tüm CPU'ları kullan\n",
    "    \n",
    "    # Hyperparameter optimization\n",
    "    hpo_timeout=120,  # 2 dakika timeout\n",
    "    hpo_n_trials=20,  # 20 deneme\n",
    "    \n",
    "    # Feature engineering\n",
    "    rare_threshold=0.02,  # %2'den az görülen kategoriler\n",
    "    psi_threshold=0.20,  # PSI eşiği\n",
    "    iv_min=0.02,  # Minimum IV değeri\n",
    "    corr_threshold=0.95,  # Korelasyon eşiği\n",
    "    \n",
    "    # Çıktılar\n",
    "    output_folder='outputs',\n",
    "    output_excel_path='master_model_report.xlsx',\n",
    "    log_file='pipeline.log',\n",
    "    write_artifacts=True,  # Model artifacts kaydet\n",
    "    write_csv=False,  # CSV yazma (Excel yeterli)\n",
    "    write_parquet=False  # Parquet yazma\n",
    ")\n",
    "\n",
    "print(\"⚙️  Konfigürasyon Özeti:\")\n",
    "print(\"=\"*60)\n",
    "print(f\"Output klasörü: {cfg.output_folder}\")\n",
    "print(f\"Excel raporu: {cfg.output_excel_path}\")\n",
    "print(f\"Veri sözlüğü: {len(data_dictionary)} değişken tanımı\")\n",
    "print(f\"Kalibrasyon: {len(calibration_df)} kayıt\")\n",
    "print(f\"CV Folds: {cfg.cv_folds}\")\n",
    "print(f\"HPO Trials: {cfg.hpo_n_trials}\")\n",
    "print(f\"Random State: {cfg.random_state}\")\n",
    "print(\"\\n✅ Konfigürasyon hazır!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 🚀 BÖLÜM 5: PİPELINE ÇALIŞTIRMA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5.1 - Pipeline'ı çalıştır\n",
    "\n",
    "print(\"🚀 Pipeline başlatılıyor...\")\n",
    "print(\"=\"*80)\n",
    "start_time = datetime.now()\n",
    "\n",
    "# Pipeline oluştur ve çalıştır\n",
    "pipeline = RiskModelPipeline(cfg)\n",
    "pipeline.run(train_df)\n",
    "\n",
    "end_time = datetime.now()\n",
    "duration = (end_time - start_time).total_seconds()\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(f\"✅ Pipeline tamamlandı! (Süre: {duration:.1f} saniye)\")\n",
    "print(f\"\\nRun ID: {pipeline.cfg.run_id}\")\n",
    "print(f\"Best Model: {pipeline.best_model_name_}\")\n",
    "print(f\"Final Features: {len(pipeline.final_vars_)} değişken\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 📈 BÖLÜM 6: MODEL SONUÇLARINI İNCELEME"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6.1 - Model performansını incele\n",
    "\n",
    "print(\"📈 Model Performans Özeti:\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "if pipeline.models_summary_ is not None:\n",
    "    # En önemli metrikleri göster\n",
    "    summary_cols = ['model', 'auc_traincv', 'auc_test', 'auc_oot', 'gini_oot', 'ks_oot']\n",
    "    available_cols = [col for col in summary_cols if col in pipeline.models_summary_.columns]\n",
    "    \n",
    "    print(\"\\nTüm Modellerin Performansı:\")\n",
    "    print(pipeline.models_summary_[available_cols].to_string())\n",
    "    \n",
    "    # En iyi model detayı\n",
    "    best_model_row = pipeline.models_summary_[pipeline.models_summary_['model'] == pipeline.best_model_name_].iloc[0]\n",
    "    print(f\"\\n🏆 En İyi Model: {pipeline.best_model_name_}\")\n",
    "    print(f\"   - AUC (Train/CV): {best_model_row.get('auc_traincv', 'N/A')}\")\n",
    "    print(f\"   - AUC (Test): {best_model_row.get('auc_test', 'N/A')}\")\n",
    "    print(f\"   - AUC (OOT): {best_model_row.get('auc_oot', 'N/A')}\")\n",
    "    print(f\"   - Gini (OOT): {best_model_row.get('gini_oot', 'N/A')}\")\n",
    "    print(f\"   - KS (OOT): {best_model_row.get('ks_oot', 'N/A')}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6.2 - En iyi model değişkenlerini incele (veri sözlüğü ile)\n",
    "\n",
    "print(\"📊 En İyi Model Değişkenleri (İlk 20):\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "if pipeline.best_model_vars_df_ is not None:\n",
    "    # Gösterilecek kolonlar\n",
    "    display_cols = ['variable', 'description', 'coef_or_importance', 'variable_group']\n",
    "    available_cols = [col for col in display_cols if col in pipeline.best_model_vars_df_.columns]\n",
    "    \n",
    "    # İlk 20 değişkeni göster\n",
    "    print(pipeline.best_model_vars_df_[available_cols].head(20).to_string())\n",
    "    \n",
    "    # Açıklamaların yüklendiğini kontrol et\n",
    "    if 'description' in pipeline.best_model_vars_df_.columns:\n",
    "        has_desc = pipeline.best_model_vars_df_['description'].notna().sum()\n",
    "        print(f\"\\n✅ Veri sözlüğünden {has_desc} değişken açıklaması yüklendi\")\n",
    "else:\n",
    "    print(\"❌ Model değişkenleri bulunamadı\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6.3 - WOE raporunu incele (monotonic sıralı)\n",
    "\n",
    "print(\"📊 WOE Raporu Örneği (İlk 2 Değişken):\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "if pipeline.best_model_woe_df_ is not None:\n",
    "    # İlk 2 değişken için WOE binlerini göster\n",
    "    unique_vars = pipeline.best_model_woe_df_['variable'].unique()[:2]\n",
    "    \n",
    "    for var in unique_vars:\n",
    "        var_woe = pipeline.best_model_woe_df_[pipeline.best_model_woe_df_['variable'] == var]\n",
    "        \n",
    "        print(f\"\\n📌 Değişken: {var}\")\n",
    "        \n",
    "        # Açıklama varsa göster\n",
    "        if 'variable_description' in var_woe.columns:\n",
    "            desc = var_woe['variable_description'].iloc[0]\n",
    "            if desc:\n",
    "                print(f\"   Açıklama: {desc}\")\n",
    "        \n",
    "        # WOE binleri\n",
    "        display_cols = ['group', 'bin_from', 'bin_to', 'count', 'event_rate', 'woe']\n",
    "        available_cols = [col for col in display_cols if col in var_woe.columns]\n",
    "        \n",
    "        print(\"\\n   WOE Binleri (event_rate'e göre sıralı):\")\n",
    "        print(var_woe[available_cols].to_string())\n",
    "        \n",
    "        # Monotonicity kontrolü\n",
    "        event_rates = var_woe['event_rate'].values\name",
    "        is_monotonic = all(event_rates[i] <= event_rates[i+1] for i in range(len(event_rates)-1))\n",
    "        print(f\"   Monotonic: {'✅ Evet' if is_monotonic else '❌ Hayır'}\")\n",
    "else:\n",
    "    print(\"❌ WOE raporu bulunamadı\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 🎯 BÖLÜM 7: SKORLAMA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 7.1 - Model artifacts'ları yükle\n",
    "\n",
    "print(\"📦 Model Artifacts Yükleniyor...\")\n",
    "\n",
    "run_id = pipeline.cfg.run_id\n",
    "output_folder = pipeline.cfg.output_folder\n",
    "\n",
    "# Model dosyaları\n",
    "model_file = f\"{output_folder}/best_model_{run_id}.joblib\"\n",
    "features_file = f\"{output_folder}/final_vars_{run_id}.json\"\n",
    "woe_file = f\"{output_folder}/woe_mapping_{run_id}.json\"\n",
    "calibrator_file = f\"{output_folder}/calibrator_{run_id}.pkl\"\n",
    "\n",
    "# Dosyaları kontrol et\n",
    "print(f\"\\nDosya Kontrolü:\")\n",
    "print(f\"  Model: {'✅' if os.path.exists(model_file) else '❌'}\")\n",
    "print(f\"  Features: {'✅' if os.path.exists(features_file) else '❌'}\")\n",
    "print(f\"  WOE Mapping: {'✅' if os.path.exists(woe_file) else '❌'}\")\n",
    "print(f\"  Calibrator: {'✅' if os.path.exists(calibrator_file) else '❌'}\")\n",
    "\n",
    "# Yükle\n",
    "if all(os.path.exists(f) for f in [model_file, features_file, woe_file]):\n",
    "    model = joblib.load(model_file)\n",
    "    with open(features_file, 'r') as f:\n",
    "        final_features = json.load(f)\n",
    "    with open(woe_file, 'r') as f:\n",
    "        woe_mapping = json.load(f)\n",
    "    \n",
    "    # Calibrator (varsa)\n",
    "    calibrator = None\n",
    "    if os.path.exists(calibrator_file):\n",
    "        calibrator = joblib.load(calibrator_file)\n",
    "    \n",
    "    print(f\"\\n✅ Artifacts yüklendi:\")\n",
    "    print(f\"  Model tipi: {type(model).__name__}\")\n",
    "    print(f\"  Feature sayısı: {len(final_features)}\")\n",
    "    print(f\"  WOE değişken sayısı: {len(woe_mapping)}\")\n",
    "    print(f\"  Calibrator: {'Var' if calibrator else 'Yok'}\")\n",
    "else:\n",
    "    print(\"❌ Bazı dosyalar bulunamadı!\")\n",
    "    model = pipeline.models_[pipeline.best_model_name_]\n",
    "    final_features = pipeline.final_vars_\n",
    "    woe_mapping = {}\n",
    "    for v, vw in pipeline.woe_map.items():\n",
    "        woe_mapping[v] = vw.__dict__\n",
    "    calibrator = pipeline.calibrator_ if hasattr(pipeline, 'calibrator_') else None\n",
    "    print(\"✅ Pipeline'dan yüklendi\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 7.2 - Skorlama yap\n",
    "\n",
    "print(\"🎯 Skorlama Başlatılıyor...\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Score data fonksiyonunu import et\n",
    "try:\n",
    "    from risk_pipeline.utils.scoring import score_data\n",
    "except:\n",
    "    from src.risk_pipeline.utils.scoring import score_data\n",
    "\n",
    "# Skorlama yap\n",
    "scoring_results = score_data(\n",
    "    scoring_df=scoring_df,\n",
    "    model=model,\n",
    "    final_features=final_features,\n",
    "    woe_mapping=woe_mapping,\n",
    "    calibrator=calibrator,\n",
    "    training_scores=None,  # PSI hesaplama için (şimdilik None)\n",
    "    feature_mapping=None\n",
    ")\n",
    "\n",
    "print(\"\\n📊 Skorlama Sonuçları:\")\n",
    "print(f\"  Toplam skorlanan: {scoring_results['n_total']:,}\")\n",
    "print(f\"  Target'lı kayıt: {scoring_results['n_with_target']:,}\")\n",
    "print(f\"  Target'sız kayıt: {scoring_results['n_without_target']:,}\")\n",
    "\n",
    "# Target'lı kayıtlar için performans\n",
    "if 'with_target' in scoring_results and scoring_results['with_target']:\n",
    "    print(f\"\\n📈 Performans (Target'lı Kayıtlar):\")\n",
    "    print(f\"  AUC: {scoring_results['with_target']['auc']:.4f}\")\n",
    "    print(f\"  Gini: {scoring_results['with_target']['gini']:.4f}\")\n",
    "    print(f\"  KS: {scoring_results['with_target']['ks']:.4f}\")\n",
    "\n",
    "# Skor dağılımı\n",
    "if 'scores' in scoring_results:\n",
    "    scores = np.array(scoring_results['scores'])\n",
    "    print(f\"\\n📊 Skor Dağılımı:\")\n",
    "    print(f\"  Min: {scores.min():.4f}\")\n",
    "    print(f\"  Q1: {np.percentile(scores, 25):.4f}\")\n",
    "    print(f\"  Median: {np.median(scores):.4f}\")\n",
    "    print(f\"  Q3: {np.percentile(scores, 75):.4f}\")\n",
    "    print(f\"  Max: {scores.max():.4f}\")\n",
    "    print(f\"  Mean: {scores.mean():.4f}\")\n",
    "    print(f\"  Std: {scores.std():.4f}\")\n",
    "\n",
    "print(\"\\n✅ Skorlama tamamlandı!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 📊 BÖLÜM 8: EXCEL RAPORU İNCELEME"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 8.1 - Excel raporunu kontrol et\n",
    "\n",
    "excel_path = os.path.join(cfg.output_folder, cfg.output_excel_path)\n",
    "\n",
    "print(\"📊 Excel Raporu Kontrolü:\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "if os.path.exists(excel_path):\n",
    "    print(f\"✅ Excel dosyası bulundu: {excel_path}\")\n",
    "    print(f\"   Boyut: {os.path.getsize(excel_path) / 1024:.1f} KB\")\n",
    "    \n",
    "    # Excel'deki sheet'leri listele\n",
    "    excel_file = pd.ExcelFile(excel_path)\n",
    "    sheets = excel_file.sheet_names\n",
    "    \n",
    "    print(f\"\\n📋 Toplam {len(sheets)} sheet bulundu:\")\n",
    "    print(\"-\"*60)\n",
    "    \n",
    "    # Sheet'leri kategorize et\n",
    "    main_sheets = ['final_vars', 'best_name', 'models_summary', 'best_model_vars_df', 'best_model_woe_df']\n",
    "    performance_sheets = ['ks_info_traincv', 'ks_info_test', 'ks_info_oot', 'gini_summary']\n",
    "    feature_sheets = ['top20_iv_df', 'top50_univariate', 'psi_summary', 'psi_dropped_features']\n",
    "    correlation_sheets = ['correlation_matrix', 'correlation_clusters', 'corr_dropped']\n",
    "    \n",
    "    print(\"\\n🔹 Ana Raporlar:\")\n",
    "    for sheet in main_sheets:\n",
    "        if sheet in sheets:\n",
    "            print(f\"   ✅ {sheet}\")\n",
    "    \n",
    "    print(\"\\n🔹 Performans Raporları:\")\n",
    "    for sheet in performance_sheets:\n",
    "        if sheet in sheets:\n",
    "            print(f\"   ✅ {sheet}\")\n",
    "    \n",
    "    print(\"\\n🔹 Feature Raporları:\")\n",
    "    for sheet in feature_sheets:\n",
    "        if sheet in sheets:\n",
    "            print(f\"   ✅ {sheet}\")\n",
    "    \n",
    "    print(\"\\n🔹 Korelasyon Raporları:\")\n",
    "    for sheet in correlation_sheets:\n",
    "        if sheet in sheets:\n",
    "            print(f\"   ✅ {sheet}\")\n",
    "    \n",
    "    # Diğer sheet'ler\n",
    "    other_sheets = [s for s in sheets if s not in main_sheets + performance_sheets + feature_sheets + correlation_sheets]\n",
    "    if other_sheets:\n",
    "        print(\"\\n🔹 Diğer Raporlar:\")\n",
    "        for sheet in other_sheets:\n",
    "            print(f\"   ✅ {sheet}\")\n",
    "    \n",
    "    # Veri sözlüğü kontrolü\n",
    "    print(\"\\n📚 Veri Sözlüğü Entegrasyonu:\")\n",
    "    if 'best_model_vars_df' in sheets:\n",
    "        best_vars = pd.read_excel(excel_path, sheet_name='best_model_vars_df')\n",
    "        if 'description' in best_vars.columns:\n",
    "            has_desc = best_vars['description'].notna().sum()\n",
    "            print(f\"   ✅ {has_desc}/{len(best_vars)} değişken açıklaması mevcut\")\n",
    "        else:\n",
    "            print(\"   ❌ Açıklama kolonu bulunamadı\")\n",
    "    \n",
    "    # WOE monotonic kontrolü\n",
    "    print(\"\\n📈 WOE Monotonic Sıralama:\")\n",
    "    if 'best_model_woe_df' in sheets:\n",
    "        woe_df = pd.read_excel(excel_path, sheet_name='best_model_woe_df')\n",
    "        if 'bin_from' in woe_df.columns and 'bin_to' in woe_df.columns:\n",
    "            print(\"   ✅ bin_from/bin_to kolonları mevcut\")\n",
    "        if 'variable_description' in woe_df.columns:\n",
    "            print(\"   ✅ Değişken açıklamaları mevcut\")\n",
    "        \n",
    "        # Monotonic kontrol\n",
    "        first_var = woe_df['variable'].iloc[0] if len(woe_df) > 0 else None\n",
    "        if first_var:\n",
    "            var_woe = woe_df[woe_df['variable'] == first_var]\n",
    "            event_rates = var_woe['event_rate'].values\n",
    "            is_mono = all(event_rates[i] <= event_rates[i+1] for i in range(len(event_rates)-1))\n",
    "            print(f\"   {'✅' if is_mono else '❌'} İlk değişken monotonic sıralı\")\n",
    "    \n",
    "else:\n",
    "    print(f\"❌ Excel dosyası bulunamadı: {excel_path}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"✅ Excel raporu kontrolü tamamlandı!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 🎯 BÖLÜM 9: ÖZET VE SONUÇLAR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 9.1 - Genel özet\n",
    "\n",
    "print(\"🎯 PIPELINE ÇALIŞTIRMA ÖZETİ\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "print(\"\\n📊 Veri:\")\n",
    "print(f\"  • Eğitim: {train_df.shape[0]:,} kayıt\")\n",
    "print(f\"  • Kalibrasyon: {calibration_df.shape[0]:,} kayıt\")\n",
    "print(f\"  • Skorlama: {scoring_df.shape[0]:,} kayıt\")\n",
    "print(f\"  • Toplam değişken: {len(train_df.columns) - 3} (ID, tarih, target hariç)\")\n",
    "\n",
    "print(\"\\n🏆 Model:\")\n",
    "print(f\"  • En iyi model: {pipeline.best_model_name_}\")\n",
    "print(f\"  • Final değişken sayısı: {len(pipeline.final_vars_)}\")\n",
    "print(f\"  • Kalibrasyon: {'Uygulandı ✅' if pipeline.calibrator_ is not None else 'Uygulanmadı ❌'}\")\n",
    "\n",
    "if pipeline.models_summary_ is not None and pipeline.best_model_name_:\n",
    "    best_row = pipeline.models_summary_[pipeline.models_summary_['model'] == pipeline.best_model_name_].iloc[0]\n",
    "    print(f\"\\n📈 Performans:\")\n",
    "    print(f\"  • AUC (OOT): {best_row.get('auc_oot', 'N/A')}\")\n",
    "    print(f\"  • Gini (OOT): {best_row.get('gini_oot', 'N/A')}\")\n",
    "    print(f\"  • KS (OOT): {best_row.get('ks_oot', 'N/A')}\")\n",
    "\n",
    "print(f\"\\n📁 Çıktılar:\")\n",
    "print(f\"  • Excel raporu: {cfg.output_folder}/{cfg.output_excel_path}\")\n",
    "print(f\"  • Log dosyası: {cfg.output_folder}/{cfg.log_file}\")\n",
    "print(f\"  • Model artifacts: {cfg.output_folder}/best_model_{pipeline.cfg.run_id}.joblib\")\n",
    "print(f\"  • Run ID: {pipeline.cfg.run_id}\")\n",
    "\n",
    "print(\"\\n✨ Özellikler:\")\n",
    "print(f\"  • Veri sözlüğü entegrasyonu ✅\")\n",
    "print(f\"  • WOE monotonic sıralama ✅\")\n",
    "print(f\"  • DataFrame kalibrasyon desteği ✅\")\n",
    "print(f\"  • Gelişmiş Excel raporlama ✅\")\n",
    "print(f\"  • Otomatik feature engineering ✅\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"🎉 TÜM İŞLEMLER BAŞARIYLA TAMAMLANDI!\")\n",
    "print(\"=\"*80)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 💾 BÖLÜM 10: SONUÇLARI KAYDETME"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 10.1 - Önemli sonuçları kaydet\n",
    "\n",
    "# Sonuçları bir dictionary'de topla\n",
    "results_summary = {\n",
    "    'run_id': pipeline.cfg.run_id,\n",
    "    'run_date': datetime.now().isoformat(),\n",
    "    'best_model': pipeline.best_model_name_,\n",
    "    'n_final_features': len(pipeline.final_vars_),\n",
    "    'final_features': pipeline.final_vars_,\n",
    "    'n_train': train_df.shape[0],\n",
    "    'n_calibration': calibration_df.shape[0],\n",
    "    'n_scoring': scoring_df.shape[0],\n",
    "    'calibration_applied': pipeline.calibrator_ is not None,\n",
    "    'output_folder': cfg.output_folder,\n",
    "    'excel_report': cfg.output_excel_path\n",
    "}\n",
    "\n",
    "# Performans metrikleri ekle\n",
    "if pipeline.models_summary_ is not None and pipeline.best_model_name_:\n",
    "    best_row = pipeline.models_summary_[pipeline.models_summary_['model'] == pipeline.best_model_name_].iloc[0]\n",
    "    results_summary['performance'] = {\n",
    "        'auc_traincv': float(best_row.get('auc_traincv', 0)),\n",
    "        'auc_test': float(best_row.get('auc_test', 0)),\n",
    "        'auc_oot': float(best_row.get('auc_oot', 0)),\n",
    "        'gini_oot': float(best_row.get('gini_oot', 0)),\n",
    "        'ks_oot': float(best_row.get('ks_oot', 0))\n",
    "    }\n",
    "\n",
    "# JSON olarak kaydet\n",
    "results_file = f\"{cfg.output_folder}/run_summary_{pipeline.cfg.run_id}.json\"\n",
    "with open(results_file, 'w') as f:\n",
    "    json.dump(results_summary, f, indent=2)\n",
    "\n",
    "print(f\"💾 Sonuç özeti kaydedildi: {results_file}\")\n",
    "\n",
    "# Skorlama sonuçlarını da kaydet\n",
    "if 'scoring_results' in locals():\n",
    "    scoring_file = f\"{cfg.output_folder}/scoring_results_{pipeline.cfg.run_id}.json\"\n",
    "    \n",
    "    # Numpy array'leri liste'ye çevir\n",
    "    scoring_save = {\n",
    "        'n_total': scoring_results['n_total'],\n",
    "        'n_with_target': scoring_results['n_with_target'],\n",
    "        'n_without_target': scoring_results['n_without_target']\n",
    "    }\n",
    "    \n",
    "    if 'with_target' in scoring_results:\n",
    "        scoring_save['with_target_metrics'] = scoring_results['with_target']\n",
    "    \n",
    "    with open(scoring_file, 'w') as f:\n",
    "        json.dump(scoring_save, f, indent=2)\n",
    "    \n",
    "    print(f\"💾 Skorlama sonuçları kaydedildi: {scoring_file}\")\n",
    "\n",
    "print(\"\\n✅ Tüm sonuçlar başarıyla kaydedildi!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 🎉 TEBRİKLER!\n",
    "\n",
    "End-to-end pipeline başarıyla tamamlandı. Oluşturulan dosyalar:\n",
    "\n",
    "1. **Excel Raporu**: `outputs/master_model_report.xlsx` - Tüm raporlar tek dosyada\n",
    "2. **Model**: `outputs/best_model_[run_id].joblib`\n",
    "3. **WOE Mapping**: `outputs/woe_mapping_[run_id].json`\n",
    "4. **Final Features**: `outputs/final_vars_[run_id].json`\n",
    "5. **Calibrator**: `outputs/calibrator_[run_id].pkl`\n",
    "6. **Log Dosyası**: `outputs/pipeline.log`\n",
    "7. **Sonuç Özeti**: `outputs/run_summary_[run_id].json`\n",
    "\n",
    "### Sonraki Adımlar:\n",
    "- Diğer simulation notebook'larını deneyin\n",
    "- Excel raporunu detaylı inceleyin\n",
    "- Model'i production'a deploy edin"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}