{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Risk Model Pipeline - Dual Pipeline Example\n",
    "\n",
    "This notebook demonstrates the dual pipeline approach with both WOE transformation and raw variables.\n",
    "\n",
    "## Requirements\n",
    "Before running, ensure you have installed the requirements:\n",
    "```bash\n",
    "pip install -r ../requirements.txt\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup and Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add parent directory to path\n",
    "import sys\n",
    "import os\n",
    "sys.path.insert(0, os.path.abspath('..'))\n",
    "\n",
    "# Suppress warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Core imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "# Pipeline imports\n",
    "from src.risk_pipeline.pipeline16 import Config, RiskModelPipeline\n",
    "\n",
    "print(\"Imports successful!\")\n",
    "print(f\"NumPy version: {np.__version__}\")\n",
    "print(f\"Pandas version: {pd.__version__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Generate Sample Data\n",
    "\n",
    "Create realistic credit risk data with features that achieve 70-80% Gini."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_sample_data(n_samples=10000, seed=42):\n",
    "    \"\"\"Create sample credit risk data\"\"\"\n",
    "    np.random.seed(seed)\n",
    "    \n",
    "    # Generate features\n",
    "    data = {\n",
    "        'app_id': range(1, n_samples + 1),\n",
    "        'app_dt': pd.date_range(start='2022-01-01', periods=n_samples, freq='H')[:n_samples],\n",
    "    }\n",
    "    \n",
    "    # Risk features (numeric)\n",
    "    data['risk_score'] = np.random.beta(2, 5, n_samples)\n",
    "    data['payment_score'] = np.random.beta(3, 2, n_samples)\n",
    "    data['debt_ratio'] = np.random.beta(2, 3, n_samples)\n",
    "    data['income_level'] = np.random.lognormal(10, 1.5, n_samples)\n",
    "    data['credit_history_months'] = np.random.gamma(3, 10, n_samples)\n",
    "    data['num_credit_lines'] = np.random.poisson(3, n_samples)\n",
    "    data['utilization_rate'] = np.random.beta(3, 2, n_samples)\n",
    "    data['num_inquiries'] = np.random.poisson(2, n_samples)\n",
    "    \n",
    "    # Categorical features\n",
    "    data['employment_type'] = np.random.choice(['Full-time', 'Part-time', 'Self-employed', 'Unemployed'], \n",
    "                                               n_samples, p=[0.6, 0.2, 0.15, 0.05])\n",
    "    data['region'] = np.random.choice(['North', 'South', 'East', 'West'], n_samples)\n",
    "    data['product_type'] = np.random.choice(['A', 'B', 'C'], n_samples, p=[0.5, 0.3, 0.2])\n",
    "    \n",
    "    # Create target based on features (with realistic relationship)\n",
    "    risk_factor = (\n",
    "        3.0 * data['risk_score'] + \n",
    "        2.5 * data['payment_score'] + \n",
    "        2.0 * data['debt_ratio'] + \n",
    "        1.5 * data['utilization_rate'] +\n",
    "        0.5 * (data['num_inquiries'] / 10) +\n",
    "        -0.3 * np.log1p(data['income_level'] / 10000) +\n",
    "        -0.2 * np.log1p(data['credit_history_months'] / 12) +\n",
    "        np.random.normal(0, 0.5, n_samples)\n",
    "    )\n",
    "    \n",
    "    # Convert to probability\n",
    "    default_prob = 1 / (1 + np.exp(-2 * (risk_factor - np.median(risk_factor))))\n",
    "    \n",
    "    # Generate binary target\n",
    "    data['target'] = np.random.binomial(1, default_prob)\n",
    "    \n",
    "    # Ensure reasonable default rate (10-20%)\n",
    "    if data['target'].mean() > 0.25:\n",
    "        threshold = np.percentile(default_prob, 75)\n",
    "        data['target'] = (default_prob > threshold).astype(int)\n",
    "    elif data['target'].mean() < 0.10:\n",
    "        threshold = np.percentile(default_prob, 90) \n",
    "        data['target'] = (default_prob > threshold).astype(int)\n",
    "    \n",
    "    # Add some missing values for realism\n",
    "    missing_cols = ['income_level', 'credit_history_months']\n",
    "    for col in missing_cols:\n",
    "        missing_idx = np.random.choice(n_samples, size=int(0.05 * n_samples), replace=False)\n",
    "        data[col][missing_idx] = np.nan\n",
    "    \n",
    "    df = pd.DataFrame(data)\n",
    "    \n",
    "    print(f\"Dataset created: {len(df):,} samples\")\n",
    "    print(f\"Features: {len(df.columns) - 3} (excluding id, date, target)\")\n",
    "    print(f\"Default rate: {df['target'].mean():.2%}\")\n",
    "    print(f\"Date range: {df['app_dt'].min().date()} to {df['app_dt'].max().date()}\")\n",
    "    print(f\"Missing values: {df.isnull().sum().sum():,}\")\n",
    "    \n",
    "    return df\n",
    "\n",
    "# Generate data\n",
    "df = create_sample_data(n_samples=10000, seed=42)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Configure Pipeline\n",
    "\n",
    "Set up configuration with dual pipeline enabled."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create configuration\n",
    "config = Config(\n",
    "    # Core columns\n",
    "    id_col='app_id',\n",
    "    time_col='app_dt',\n",
    "    target_col='target',\n",
    "    \n",
    "    # Enable DUAL PIPELINE\n",
    "    enable_dual_pipeline=True,\n",
    "    \n",
    "    # Raw pipeline settings\n",
    "    raw_imputation_strategy='median',\n",
    "    raw_outlier_method='iqr',\n",
    "    raw_outlier_threshold=1.5,\n",
    "    \n",
    "    # Data split\n",
    "    use_test_split=True,\n",
    "    test_size_row_frac=0.2,\n",
    "    oot_window_months=2,\n",
    "    \n",
    "    # Feature engineering\n",
    "    rare_threshold=0.01,\n",
    "    psi_threshold=0.30,\n",
    "    iv_min=0.01,\n",
    "    rho_threshold=0.95,\n",
    "    \n",
    "    # Model settings (reduced for speed)\n",
    "    cv_folds=3,\n",
    "    hpo_timeout_sec=30,\n",
    "    hpo_trials=5,\n",
    "    \n",
    "    # Output\n",
    "    output_folder='outputs_dual_example',\n",
    "    output_excel_path='dual_pipeline_results.xlsx',\n",
    "    \n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "print(\"Configuration created:\")\n",
    "print(f\"  Dual Pipeline: {config.enable_dual_pipeline}\")\n",
    "print(f\"  Raw Imputation: {config.raw_imputation_strategy}\")\n",
    "print(f\"  Raw Outlier Method: {config.raw_outlier_method}\")\n",
    "print(f\"  HPO Timeout: {config.hpo_timeout_sec}s\")\n",
    "print(f\"  Output Folder: {config.output_folder}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Run Dual Pipeline\n",
    "\n",
    "Execute both WOE and Raw pipelines simultaneously."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create pipeline instance\n",
    "pipeline = RiskModelPipeline(config)\n",
    "\n",
    "# Run pipeline\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"STARTING DUAL PIPELINE EXECUTION\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "start_time = time.time()\n",
    "pipeline.run(df)\n",
    "elapsed = time.time() - start_time\n",
    "\n",
    "print(f\"\\nTotal execution time: {elapsed:.2f} seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Review Results\n",
    "\n",
    "Compare performance between WOE and Raw pipelines."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if models were created\n",
    "if pipeline.models_summary_ is not None and not pipeline.models_summary_.empty:\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"MODEL PERFORMANCE SUMMARY\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    # Get summary\n",
    "    summary = pipeline.models_summary_\n",
    "    \n",
    "    # Check available columns\n",
    "    print(\"\\nAvailable columns:\", list(summary.columns))\n",
    "    \n",
    "    # Display key metrics\n",
    "    if 'Gini_OOT' in summary.columns:\n",
    "        # Sort by Gini OOT\n",
    "        summary_sorted = summary.sort_values('Gini_OOT', ascending=False)\n",
    "        \n",
    "        # Select columns to display\n",
    "        display_cols = ['model_name', 'Gini_TrainCV', 'Gini_Test', 'Gini_OOT', 'n_features']\n",
    "        available_display_cols = [col for col in display_cols if col in summary.columns]\n",
    "        \n",
    "        print(\"\\nTop 5 Models by Gini OOT:\")\n",
    "        print(summary_sorted[available_display_cols].head().to_string())\n",
    "        \n",
    "        # Compare pipelines if dual pipeline was run\n",
    "        if 'pipeline' in summary.columns:\n",
    "            print(\"\\n\" + \"=\"*60)\n",
    "            print(\"PIPELINE COMPARISON\")\n",
    "            print(\"=\"*60)\n",
    "            \n",
    "            woe_models = summary[summary['pipeline'] == 'WOE']\n",
    "            raw_models = summary[summary['pipeline'] == 'RAW']\n",
    "            \n",
    "            if not woe_models.empty:\n",
    "                best_woe = woe_models.nlargest(1, 'Gini_OOT').iloc[0]\n",
    "                print(f\"\\nBest WOE Model:\")\n",
    "                print(f\"  Model: {best_woe['model_name']}\")\n",
    "                print(f\"  Gini OOT: {best_woe['Gini_OOT']:.4f}\")\n",
    "                print(f\"  Features: {int(best_woe.get('n_features', 0))}\")\n",
    "            \n",
    "            if not raw_models.empty:\n",
    "                best_raw = raw_models.nlargest(1, 'Gini_OOT').iloc[0]\n",
    "                print(f\"\\nBest RAW Model:\")\n",
    "                print(f\"  Model: {best_raw['model_name']}\")\n",
    "                print(f\"  Gini OOT: {best_raw['Gini_OOT']:.4f}\")\n",
    "                print(f\"  Features: {int(best_raw.get('n_features', 0))}\")\n",
    "else:\n",
    "    print(\"No models were created. Check the pipeline logs for errors.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Export Reports\n",
    "\n",
    "Generate comprehensive Excel reports."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export reports\n",
    "pipeline.export_reports()\n",
    "\n",
    "print(\"Reports exported successfully!\")\n",
    "print(f\"\\nCheck the '{config.output_folder}' folder for:\")\n",
    "print(f\"  - {config.output_excel_path}: Comprehensive Excel report\")\n",
    "print(f\"  - Parquet files: Model artifacts and data\")\n",
    "\n",
    "# List generated files\n",
    "import os\n",
    "if os.path.exists(config.output_folder):\n",
    "    files = os.listdir(config.output_folder)\n",
    "    print(f\"\\nGenerated files ({len(files)}):\")\n",
    "    for f in sorted(files)[:10]:  # Show first 10 files\n",
    "        size = os.path.getsize(os.path.join(config.output_folder, f)) / 1024\n",
    "        print(f\"  - {f} ({size:.1f} KB)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Score New Data (Optional)\n",
    "\n",
    "Demonstrate how to score new applications using the trained model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create small test dataset for scoring\n",
    "new_data = create_sample_data(n_samples=100, seed=123)\n",
    "\n",
    "# Score using best model\n",
    "if hasattr(pipeline, 'best_model_name_') and pipeline.best_model_name_:\n",
    "    print(f\"Scoring with best model: {pipeline.best_model_name_}\")\n",
    "    \n",
    "    # Note: Actual scoring would require implementing a score method\n",
    "    # This is a placeholder to show the concept\n",
    "    print(f\"\\nNew data shape: {new_data.shape}\")\n",
    "    print(f\"Features available for scoring: {len(new_data.columns) - 3}\")\n",
    "    print(\"\\nScoring would apply:\")\n",
    "    print(\"  1. WOE transformation (if WOE model)\")\n",
    "    print(\"  2. Feature selection\")\n",
    "    print(\"  3. Model prediction\")\n",
    "    print(\"  4. Calibration (if configured)\")\n",
    "else:\n",
    "    print(\"No model available for scoring.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "This notebook demonstrated:\n",
    "1. **Data Generation**: Creating realistic credit risk data\n",
    "2. **Dual Pipeline Configuration**: Enabling both WOE and Raw pipelines\n",
    "3. **Model Training**: Running both pipelines simultaneously\n",
    "4. **Performance Comparison**: Comparing WOE vs Raw model performance\n",
    "5. **Report Generation**: Exporting comprehensive Excel reports\n",
    "\n",
    "The dual pipeline approach provides:\n",
    "- **WOE Models**: Interpretable with binning and business logic\n",
    "- **Raw Models**: Higher performance with automated preprocessing\n",
    "- **Best of Both**: Choose based on your needs (interpretability vs performance)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}