{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Risk Model Pipeline - Dual Pipeline Example\n",
    "\n",
    "## ‚ö†Ô∏è IMPORTANT: Installation from GitHub\n",
    "\n",
    "### Known Issues and Solutions\n",
    "\n",
    "#### If you get `llvmlite` uninstall error:\n",
    "```bash\n",
    "# Option 1: Ignore the installed version\n",
    "pip install --ignore-installed llvmlite\n",
    "pip install git+https://github.com/selimoksuz/risk-model-pipeline.git\n",
    "\n",
    "# Option 2: Use conda to manage llvmlite\n",
    "conda update llvmlite\n",
    "pip install git+https://github.com/selimoksuz/risk-model-pipeline.git\n",
    "\n",
    "# Option 3: Force reinstall without dependencies\n",
    "pip install --force-reinstall --no-deps git+https://github.com/selimoksuz/risk-model-pipeline.git\n",
    "pip install numpy==1.24.3 pandas==1.5.3 scikit-learn==1.3.0\n",
    "```\n",
    "\n",
    "### Standard Installation\n",
    "```bash\n",
    "pip install git+https://github.com/selimoksuz/risk-model-pipeline.git\n",
    "```\n",
    "\n",
    "### Create Clean Environment (Recommended)\n",
    "```bash\n",
    "# Create new environment\n",
    "python -m venv risk_env\n",
    "risk_env\\Scripts\\activate  # Windows\n",
    "source risk_env/bin/activate  # Linux/Mac\n",
    "\n",
    "# Install in clean environment\n",
    "pip install git+https://github.com/selimoksuz/risk-model-pipeline.git\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Environment Check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python: 3.9.13 (main, Aug 25 2022, 23:51:50) [MSC v.1916 64 bit (AMD64)]\n",
      "Python executable: C:\\Users\\Acer\\anaconda3\\python.exe\n",
      "--------------------------------------------------\n",
      "‚úì numpy: 1.24.3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Acer\\anaconda3\\lib\\site-packages\\pandas\\core\\computation\\expressions.py:21: UserWarning: Pandas requires version '2.8.4' or newer of 'numexpr' (version '2.8.3' currently installed).\n",
      "  from pandas.core.computation.check import NUMEXPR_INSTALLED\n",
      "C:\\Users\\Acer\\anaconda3\\lib\\site-packages\\pandas\\core\\arrays\\masked.py:61: UserWarning: Pandas requires version '1.3.6' or newer of 'bottleneck' (version '1.3.5' currently installed).\n",
      "  from pandas.core import (\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úì pandas: 2.3.2\n",
      "‚úì sklearn: 1.6.1\n",
      "\n",
      "‚úì All packages imported successfully!\n"
     ]
    }
   ],
   "source": [
    "# Check Python and package versions\n",
    "import sys\n",
    "print(f\"Python: {sys.version}\")\n",
    "print(f\"Python executable: {sys.executable}\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "# Try importing packages and show versions\n",
    "packages = [\n",
    "    ('numpy', 'np'),\n",
    "    ('pandas', 'pd'),\n",
    "    ('sklearn', 'sklearn')\n",
    "]\n",
    "\n",
    "import_success = True\n",
    "for package_name, import_name in packages:\n",
    "    try:\n",
    "        module = __import__(package_name)\n",
    "        print(f\"‚úì {package_name}: {module.__version__}\")\n",
    "    except ImportError as e:\n",
    "        print(f\"‚úó {package_name}: Not installed\")\n",
    "        import_success = False\n",
    "    except Exception as e:\n",
    "        print(f\"‚úó {package_name}: Error - {e}\")\n",
    "        import_success = False\n",
    "\n",
    "if not import_success:\n",
    "    print(\"\\n‚ö†Ô∏è Please install missing packages:\")\n",
    "    print(\"pip install git+https://github.com/selimoksuz/risk-model-pipeline.git\")\n",
    "else:\n",
    "    print(\"\\n‚úì All packages imported successfully!\")\n",
    "\n",
    "# Output should appear here when cell is run"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Setup and Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updating risk-model-pipeline from GitHub...\n",
      "1. Uninstalling existing version...\n",
      "2. Installing from GitHub (with all requirements)...\n",
      "‚úì Package installed successfully!\n",
      "‚úì Ready to import pipeline\n"
     ]
    }
   ],
   "source": [
    "# Reinstall package from GitHub to get latest changes\n",
    "import subprocess\n",
    "import sys\n",
    "\n",
    "print(\"Updating risk-model-pipeline from GitHub...\")\n",
    "\n",
    "# Uninstall existing version\n",
    "print(\"1. Uninstalling existing version...\")\n",
    "subprocess.run([sys.executable, \"-m\", \"pip\", \"uninstall\", \"-y\", \"risk-model-pipeline\"], capture_output=True)\n",
    "\n",
    "# Install fresh from GitHub (will install all requirements automatically)\n",
    "print(\"2. Installing from GitHub (with all requirements)...\")\n",
    "result = subprocess.run(\n",
    "    [sys.executable, \"-m\", \"pip\", \"install\", \"git+https://github.com/selimoksuz/risk-model-pipeline.git\"],\n",
    "    capture_output=True, text=True\n",
    ")\n",
    "\n",
    "if result.returncode == 0:\n",
    "    print(\"‚úì Package installed successfully!\")\n",
    "else:\n",
    "    print(f\"‚úó Installation failed: {result.stderr}\")\n",
    "\n",
    "# Clear import cache to ensure fresh import\n",
    "import sys\n",
    "modules_to_clear = ['risk_pipeline', 'risk_pipeline.pipeline', 'risk_pipeline.core']\n",
    "for module in modules_to_clear:\n",
    "    if module in sys.modules:\n",
    "        del sys.modules[module]\n",
    "\n",
    "print(\"‚úì Ready to import pipeline\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úì Pipeline imported successfully!\n"
     ]
    }
   ],
   "source": [
    "# Import pipeline components\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from risk_pipeline.pipeline import Config, RiskModelPipeline\n",
    "\n",
    "print(\"‚úì Pipeline imported successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Generate Sample Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset created:\n",
      "  Shape: (10000, 16)\n",
      "  Default rate: 30.00%\n",
      "  Date range: 2022-01-01 to 2023-02-21\n",
      "  Missing values: 800\n",
      "\n",
      "Feature characteristics:\n",
      "  Strong predictors: risk_score, payment_score, debt_ratio\n",
      "  PSI shift features: income_level, credit_history_months, region\n",
      "  Noise features: noise_feature1, noise_feature2\n",
      "  Correlated pairs: (debt_ratio, utilization_rate)\n",
      "\n",
      "‚úì Data generated successfully!\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>app_id</th>\n",
       "      <th>app_dt</th>\n",
       "      <th>risk_score</th>\n",
       "      <th>payment_score</th>\n",
       "      <th>debt_ratio</th>\n",
       "      <th>income_level</th>\n",
       "      <th>credit_history_months</th>\n",
       "      <th>noise_feature1</th>\n",
       "      <th>noise_feature2</th>\n",
       "      <th>employment_type</th>\n",
       "      <th>region</th>\n",
       "      <th>product_type</th>\n",
       "      <th>utilization_rate</th>\n",
       "      <th>num_credit_lines</th>\n",
       "      <th>num_inquiries</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2022-01-01 00:00:00</td>\n",
       "      <td>0.353677</td>\n",
       "      <td>0.576435</td>\n",
       "      <td>0.604789</td>\n",
       "      <td>66096.391145</td>\n",
       "      <td>7.454650</td>\n",
       "      <td>0.162789</td>\n",
       "      <td>0.210952</td>\n",
       "      <td>Full-time</td>\n",
       "      <td>South</td>\n",
       "      <td>C</td>\n",
       "      <td>0.666422</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>2022-01-01 01:00:00</td>\n",
       "      <td>0.248558</td>\n",
       "      <td>0.935896</td>\n",
       "      <td>0.245044</td>\n",
       "      <td>13009.413385</td>\n",
       "      <td>26.725380</td>\n",
       "      <td>-2.072867</td>\n",
       "      <td>0.277412</td>\n",
       "      <td>Unemployed</td>\n",
       "      <td>North</td>\n",
       "      <td>B</td>\n",
       "      <td>0.308693</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>2022-01-01 02:00:00</td>\n",
       "      <td>0.415959</td>\n",
       "      <td>0.924080</td>\n",
       "      <td>0.405689</td>\n",
       "      <td>65966.324008</td>\n",
       "      <td>27.662485</td>\n",
       "      <td>0.282163</td>\n",
       "      <td>0.837427</td>\n",
       "      <td>Full-time</td>\n",
       "      <td>South</td>\n",
       "      <td>A</td>\n",
       "      <td>0.591985</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>2022-01-01 03:00:00</td>\n",
       "      <td>0.159968</td>\n",
       "      <td>0.626639</td>\n",
       "      <td>0.602617</td>\n",
       "      <td>46467.378787</td>\n",
       "      <td>44.511552</td>\n",
       "      <td>0.550439</td>\n",
       "      <td>0.929937</td>\n",
       "      <td>Full-time</td>\n",
       "      <td>East</td>\n",
       "      <td>B</td>\n",
       "      <td>0.439253</td>\n",
       "      <td>10</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>2022-01-01 04:00:00</td>\n",
       "      <td>0.550283</td>\n",
       "      <td>0.854347</td>\n",
       "      <td>0.577085</td>\n",
       "      <td>14137.477402</td>\n",
       "      <td>11.483100</td>\n",
       "      <td>0.385806</td>\n",
       "      <td>0.915711</td>\n",
       "      <td>Self-employed</td>\n",
       "      <td>North</td>\n",
       "      <td>A</td>\n",
       "      <td>0.421884</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   app_id              app_dt  risk_score  payment_score  debt_ratio  \\\n",
       "0       1 2022-01-01 00:00:00    0.353677       0.576435    0.604789   \n",
       "1       2 2022-01-01 01:00:00    0.248558       0.935896    0.245044   \n",
       "2       3 2022-01-01 02:00:00    0.415959       0.924080    0.405689   \n",
       "3       4 2022-01-01 03:00:00    0.159968       0.626639    0.602617   \n",
       "4       5 2022-01-01 04:00:00    0.550283       0.854347    0.577085   \n",
       "\n",
       "   income_level  credit_history_months  noise_feature1  noise_feature2  \\\n",
       "0  66096.391145               7.454650        0.162789        0.210952   \n",
       "1  13009.413385              26.725380       -2.072867        0.277412   \n",
       "2  65966.324008              27.662485        0.282163        0.837427   \n",
       "3  46467.378787              44.511552        0.550439        0.929937   \n",
       "4  14137.477402              11.483100        0.385806        0.915711   \n",
       "\n",
       "  employment_type region product_type  utilization_rate  num_credit_lines  \\\n",
       "0       Full-time  South            C          0.666422                 2   \n",
       "1      Unemployed  North            B          0.308693                 6   \n",
       "2       Full-time  South            A          0.591985                 2   \n",
       "3       Full-time   East            B          0.439253                10   \n",
       "4   Self-employed  North            A          0.421884                 4   \n",
       "\n",
       "   num_inquiries  target  \n",
       "0              0       1  \n",
       "1              1       1  \n",
       "2              6       1  \n",
       "3              4       0  \n",
       "4              1       1  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def create_sample_data(n_samples=10000, seed=42, oot_shift=True):\n",
    "    \"\"\"\n",
    "    Create synthetic credit risk data with controlled characteristics for testing\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    n_samples : int\n",
    "        Total number of samples\n",
    "    seed : int\n",
    "        Random seed for reproducibility\n",
    "    oot_shift : bool\n",
    "        If True, create distribution shift in OOT period for some features\n",
    "    \"\"\"\n",
    "    np.random.seed(seed)\n",
    "    import random\n",
    "    random.seed(seed)\n",
    "    \n",
    "    # Time periods (70% train+test, 30% OOT)\n",
    "    train_test_size = int(n_samples * 0.7)\n",
    "    oot_size = n_samples - train_test_size\n",
    "    \n",
    "    # === STRONG PREDICTIVE FEATURES (stable) ===\n",
    "    # These will have high IV and remain stable\n",
    "    risk_score = np.concatenate([\n",
    "        np.random.beta(2, 5, train_test_size),\n",
    "        np.random.beta(2, 5, oot_size)  # Same distribution in OOT\n",
    "    ])\n",
    "    \n",
    "    payment_score = np.concatenate([\n",
    "        np.random.beta(3, 2, train_test_size),\n",
    "        np.random.beta(3, 2, oot_size)  # Same distribution in OOT\n",
    "    ])\n",
    "    \n",
    "    debt_ratio = np.concatenate([\n",
    "        np.random.beta(2, 3, train_test_size),\n",
    "        np.random.beta(2, 3, oot_size)  # Same distribution in OOT\n",
    "    ])\n",
    "    \n",
    "    # === MODERATE PREDICTIVE FEATURES (with PSI shift) ===\n",
    "    # These will have decent IV but high PSI in OOT\n",
    "    income_level = np.concatenate([\n",
    "        np.random.lognormal(10, 1.5, train_test_size),\n",
    "        np.random.lognormal(10.5, 1.2, oot_size) if oot_shift else np.random.lognormal(10, 1.5, oot_size)\n",
    "    ])\n",
    "    \n",
    "    credit_history_months = np.concatenate([\n",
    "        np.random.gamma(3, 10, train_test_size),\n",
    "        np.random.gamma(4, 12, oot_size) if oot_shift else np.random.gamma(3, 10, oot_size)\n",
    "    ])\n",
    "    \n",
    "    # === WEAK/NOISY FEATURES ===\n",
    "    # These should be filtered out by feature selection\n",
    "    noise_feature1 = np.random.randn(n_samples)\n",
    "    noise_feature2 = np.random.uniform(0, 1, n_samples)\n",
    "    \n",
    "    # === CATEGORICAL FEATURES ===\n",
    "    employment_type = np.concatenate([\n",
    "        np.random.choice(['Full-time', 'Part-time', 'Self-employed', 'Unemployed'], \n",
    "                        train_test_size, p=[0.6, 0.2, 0.15, 0.05]),\n",
    "        np.random.choice(['Full-time', 'Part-time', 'Self-employed', 'Unemployed'], \n",
    "                        oot_size, p=[0.6, 0.2, 0.15, 0.05])\n",
    "    ])\n",
    "    \n",
    "    # Region (shifts in OOT - new categories appear)\n",
    "    region_train = np.random.choice(['North', 'South', 'East', 'West'], \n",
    "                                   train_test_size, p=[0.3, 0.3, 0.2, 0.2])\n",
    "    if oot_shift:\n",
    "        # Introduce new categories in OOT\n",
    "        region_oot = np.random.choice(['North', 'South', 'East', 'West', 'Central', 'International'], \n",
    "                                     oot_size, p=[0.2, 0.2, 0.15, 0.15, 0.2, 0.1])\n",
    "    else:\n",
    "        region_oot = np.random.choice(['North', 'South', 'East', 'West'], \n",
    "                                     oot_size, p=[0.3, 0.3, 0.2, 0.2])\n",
    "    region = np.concatenate([region_train, region_oot])\n",
    "    \n",
    "    product_type = np.random.choice(['A', 'B', 'C'], n_samples, p=[0.5, 0.3, 0.2])\n",
    "    \n",
    "    # === HIGHLY CORRELATED FEATURES (for correlation filtering) ===\n",
    "    utilization_rate = debt_ratio + np.random.normal(0, 0.1, n_samples)\n",
    "    utilization_rate = np.clip(utilization_rate, 0, 1)\n",
    "    \n",
    "    num_credit_lines = (credit_history_months / 10 + np.random.poisson(2, n_samples)).astype(int)\n",
    "    num_credit_lines = np.clip(num_credit_lines, 0, 20)\n",
    "    \n",
    "    num_inquiries = np.random.poisson(2, n_samples)\n",
    "    \n",
    "    # === TARGET VARIABLE ===\n",
    "    # Create target with strong signal from stable features\n",
    "    risk_factor = (\n",
    "        3.0 * risk_score +                    # Strong positive (bad is high)\n",
    "        2.5 * payment_score +                  # Strong positive\n",
    "        2.0 * debt_ratio +                     # Strong positive\n",
    "        1.0 * utilization_rate +               # Moderate positive\n",
    "        0.5 * (income_level < np.median(income_level)).astype(float) +\n",
    "        0.3 * (credit_history_months < 24).astype(float) +\n",
    "        0.5 * (employment_type == 'Unemployed').astype(float) +\n",
    "        0.2 * (employment_type == 'Part-time').astype(float) +\n",
    "        0.1 * noise_feature1 + 0.1 * noise_feature2\n",
    "    )\n",
    "    \n",
    "    # Convert to probability\n",
    "    default_prob = 1 / (1 + np.exp(-2 * (risk_factor - np.median(risk_factor))))\n",
    "    target = np.random.binomial(1, default_prob)\n",
    "    \n",
    "    # Adjust to get ~20-30% default rate\n",
    "    if target.mean() > 0.30:\n",
    "        threshold = np.percentile(default_prob, 70)\n",
    "        target = (default_prob > threshold).astype(int)\n",
    "    elif target.mean() < 0.20:\n",
    "        threshold = np.percentile(default_prob, 80)\n",
    "        target = (default_prob > threshold).astype(int)\n",
    "    \n",
    "    # === ADD MISSING VALUES ===\n",
    "    missing_idx = np.random.choice(n_samples, size=int(0.05 * n_samples), replace=False)\n",
    "    income_level[missing_idx] = np.nan\n",
    "    \n",
    "    missing_idx = np.random.choice(n_samples, size=int(0.03 * n_samples), replace=False)\n",
    "    credit_history_months[missing_idx] = np.nan\n",
    "    \n",
    "    # === CREATE DATAFRAME ===\n",
    "    df = pd.DataFrame({\n",
    "        'app_id': range(1, n_samples + 1),\n",
    "        'app_dt': pd.date_range(start='2022-01-01', periods=n_samples, freq='H')[:n_samples],\n",
    "        'risk_score': risk_score,\n",
    "        'payment_score': payment_score,\n",
    "        'debt_ratio': debt_ratio,\n",
    "        'income_level': income_level,\n",
    "        'credit_history_months': credit_history_months,\n",
    "        'noise_feature1': noise_feature1,\n",
    "        'noise_feature2': noise_feature2,\n",
    "        'employment_type': employment_type,\n",
    "        'region': region,\n",
    "        'product_type': product_type,\n",
    "        'utilization_rate': utilization_rate,\n",
    "        'num_credit_lines': num_credit_lines,\n",
    "        'num_inquiries': num_inquiries,\n",
    "        'target': target\n",
    "    })\n",
    "    \n",
    "    print(f\"Dataset created:\")\n",
    "    print(f\"  Shape: {df.shape}\")\n",
    "    print(f\"  Default rate: {df['target'].mean():.2%}\")\n",
    "    print(f\"  Date range: {df['app_dt'].min().date()} to {df['app_dt'].max().date()}\")\n",
    "    print(f\"  Missing values: {df.isnull().sum().sum()}\")\n",
    "    \n",
    "    # Show feature characteristics\n",
    "    print(f\"\\nFeature characteristics:\")\n",
    "    print(f\"  Strong predictors: risk_score, payment_score, debt_ratio\")\n",
    "    print(f\"  PSI shift features: income_level, credit_history_months, region\")\n",
    "    print(f\"  Noise features: noise_feature1, noise_feature2\")\n",
    "    print(f\"  Correlated pairs: (debt_ratio, utilization_rate)\")\n",
    "    \n",
    "    return df\n",
    "\n",
    "# Generate data with fixed seed\n",
    "try:\n",
    "    df = create_sample_data(n_samples=10000, seed=42, oot_shift=True)\n",
    "    print(\"\\n‚úì Data generated successfully!\")\n",
    "    display(df.head())\n",
    "except Exception as e:\n",
    "    print(f\"‚úó Error generating data: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Configure Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úì Configuration created successfully!\n",
      "\n",
      "============================================================\n",
      "CONFIGURATION SUMMARY\n",
      "============================================================\n",
      "\n",
      "üìä Feature Selection Thresholds:\n",
      "  ‚Ä¢ PSI Threshold: 0.25 (stability check)\n",
      "  ‚Ä¢ IV Minimum: 0.02 (importance filter)\n",
      "  ‚Ä¢ Correlation Threshold: 0.9 (redundancy removal)\n",
      "  ‚Ä¢ VIF Threshold: 5.0 (multicollinearity)\n",
      "  ‚Ä¢ Rare Category Threshold: 0.01 (1% minimum)\n",
      "\n",
      "üéØ Model Selection Strategy:\n",
      "  ‚Ä¢ Method: balanced\n",
      "  ‚Ä¢ Stability Weight: 0.3 (30% stability, 70% performance)\n",
      "  ‚Ä¢ Max Train-OOT Gap: 0.15 (stability constraint)\n",
      "\n",
      "üîß Pipeline Settings:\n",
      "  ‚Ä¢ Dual Pipeline: True\n",
      "  ‚Ä¢ RAW Imputation: multiple\n",
      "  ‚Ä¢ HPO Trials: 10 trials in 30s\n",
      "  ‚Ä¢ Output: outputs_dual_example\n"
     ]
    }
   ],
   "source": [
    "# Advanced Configuration with All Feature Selection Options\n",
    "try:\n",
    "    config = Config(\n",
    "        # ========== CORE COLUMNS ==========\n",
    "        id_col='app_id',\n",
    "        time_col='app_dt',\n",
    "        target_col='target',\n",
    "        \n",
    "        # ========== DUAL PIPELINE ==========\n",
    "        enable_dual_pipeline=True,  # Enable both WOE and RAW pipelines\n",
    "        \n",
    "        # ========== RAW PIPELINE SETTINGS ==========\n",
    "        # Imputation strategies: 'median', 'mean', 'mode', 'multiple', 'target_mean', 'forward_fill', 'interpolate'\n",
    "        raw_imputation_strategy='multiple',  # Use multiple imputation (creates ensemble features)\n",
    "        raw_outlier_method='iqr',           # Outlier detection: 'iqr', 'zscore', 'percentile', 'none'\n",
    "        raw_outlier_threshold=1.5,          # IQR multiplier for outlier detection\n",
    "        \n",
    "        # ========== DATA SPLITTING ==========\n",
    "        use_test_split=True,         # Create train/test/OOT splits\n",
    "        test_size_row_frac=0.2,      # 20% for test set\n",
    "        oot_window_months=3,         # Last 3 months as OOT (~30% of data)\n",
    "        \n",
    "        # ========== FEATURE ENGINEERING THRESHOLDS ==========\n",
    "        \n",
    "        # 1. PSI (Population Stability Index) - Feature stability monitoring\n",
    "        psi_threshold=0.25,          # Features with PSI > 0.25 are dropped (unstable)\n",
    "        # PSI < 0.10: No significant change\n",
    "        # 0.10 <= PSI < 0.25: Some change, monitor\n",
    "        # PSI >= 0.25: Significant change, drop feature\n",
    "        \n",
    "        # 2. IV (Information Value) - Feature importance\n",
    "        iv_min=0.02,                 # Minimum IV to keep feature (filters weak predictors)\n",
    "        # IV < 0.02: Not useful\n",
    "        # 0.02 <= IV < 0.1: Weak predictor\n",
    "        # 0.1 <= IV < 0.3: Medium predictor\n",
    "        # 0.3 <= IV < 0.5: Strong predictor\n",
    "        # IV >= 0.5: Very strong (check for overfitting)\n",
    "        \n",
    "        # 3. Correlation & Multicollinearity\n",
    "        rho_threshold=0.90,          # Max correlation between features (drops redundant)\n",
    "        vif_threshold=5.0,           # Variance Inflation Factor threshold\n",
    "        cluster_top_k=2,             # Keep top K features from each correlation cluster\n",
    "        \n",
    "        # 4. Rare Categories\n",
    "        rare_threshold=0.01,         # Categories with < 1% frequency are grouped as \"RARE\"\n",
    "        \n",
    "        # ========== FEATURE SELECTION METHODS ==========\n",
    "        # The pipeline uses multiple methods in sequence:\n",
    "        # 1. PSI filtering (stability check)\n",
    "        # 2. IV filtering (importance check)\n",
    "        # 3. Correlation clustering (redundancy removal)\n",
    "        # 4. Boruta algorithm (all-relevant features)\n",
    "        # 5. Forward selection with 1SE rule\n",
    "        # 6. Noise sentinel (final sanity check)\n",
    "        \n",
    "        # ========== MODEL SELECTION CRITERIA ==========\n",
    "        # How to select the best model from all trained models\n",
    "        model_selection_method='balanced',   # Options: 'gini_oot', 'stable', 'balanced', 'conservative'\n",
    "        \n",
    "        # For 'balanced' method: weighted score = (1-weight)*performance + weight*stability\n",
    "        model_stability_weight=0.3,          # 30% weight on stability, 70% on performance\n",
    "        \n",
    "        # For 'conservative' method: max allowed Train-OOT gap\n",
    "        max_train_oot_gap=0.15,              # Models with gap > 15% are excluded\n",
    "        \n",
    "        # For 'stable' method: minimum acceptable performance\n",
    "        min_gini_threshold=0.5,              # Only consider models with Gini >= 0.5\n",
    "        \n",
    "        # ========== MODEL TRAINING ==========\n",
    "        cv_folds=3,                  # Cross-validation folds\n",
    "        hpo_method='random',         # Hyperparameter optimization: 'random', 'optuna', 'grid'\n",
    "        hpo_timeout_sec=30,          # Time limit for HPO per model\n",
    "        hpo_trials=10,               # Number of HPO trials\n",
    "        \n",
    "        # ========== OUTPUT SETTINGS ==========\n",
    "        output_folder='outputs_dual_example',\n",
    "        output_excel_path='dual_pipeline_results.xlsx',\n",
    "        write_parquet=True,          # Also save data in Parquet format\n",
    "        \n",
    "        # ========== OTHER SETTINGS ==========\n",
    "        random_state=42,             # For reproducibility\n",
    "        n_jobs=-1,                   # Use all CPU cores\n",
    "        use_noise_sentinel=True,     # Final check to remove noise features\n",
    "        use_benchmarks=True,         # Compare with benchmark models\n",
    "    )\n",
    "    \n",
    "    print(\"‚úì Configuration created successfully!\")\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"CONFIGURATION SUMMARY\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    print(\"\\nüìä Feature Selection Thresholds:\")\n",
    "    print(f\"  ‚Ä¢ PSI Threshold: {config.psi_threshold} (stability check)\")\n",
    "    print(f\"  ‚Ä¢ IV Minimum: {config.iv_min} (importance filter)\")\n",
    "    print(f\"  ‚Ä¢ Correlation Threshold: {config.rho_threshold} (redundancy removal)\")\n",
    "    print(f\"  ‚Ä¢ VIF Threshold: {config.vif_threshold} (multicollinearity)\")\n",
    "    print(f\"  ‚Ä¢ Rare Category Threshold: {config.rare_threshold} (1% minimum)\")\n",
    "    \n",
    "    print(\"\\nüéØ Model Selection Strategy:\")\n",
    "    print(f\"  ‚Ä¢ Method: {config.model_selection_method}\")\n",
    "    if config.model_selection_method == 'balanced':\n",
    "        print(f\"  ‚Ä¢ Stability Weight: {config.model_stability_weight} ({int(config.model_stability_weight*100)}% stability, {int((1-config.model_stability_weight)*100)}% performance)\")\n",
    "    if config.max_train_oot_gap:\n",
    "        print(f\"  ‚Ä¢ Max Train-OOT Gap: {config.max_train_oot_gap} (stability constraint)\")\n",
    "    \n",
    "    print(\"\\nüîß Pipeline Settings:\")\n",
    "    print(f\"  ‚Ä¢ Dual Pipeline: {config.enable_dual_pipeline}\")\n",
    "    print(f\"  ‚Ä¢ RAW Imputation: {config.raw_imputation_strategy}\")\n",
    "    print(f\"  ‚Ä¢ HPO Trials: {config.hpo_trials} trials in {config.hpo_timeout_sec}s\")\n",
    "    print(f\"  ‚Ä¢ Output: {config.output_folder}\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"‚úó Error creating configuration: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Run Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preparing to run pipeline...\n",
      "‚úì Pipeline instance created\n",
      "\n",
      "============================================================\n",
      "STARTING DUAL PIPELINE EXECUTION\n",
      "============================================================\n",
      "\n",
      "[21:57:50] >> 1) Veri yukleme & hazirlik basliyor | CPU=1% RAM=23%\n",
      "   - Veri boyutu: 10,000 satir x 16 sutun\n",
      "   - Target orani: 30.00%\n",
      "   - Random seed: 42\n",
      "[21:57:50] √¢--  1) Veri yukleme & hazirlik bitti (0.10s) ‚Äî OK | CPU=1% RAM=23%\n",
      "[21:57:50] >> 2) Giris dogrulama & sabitleme basliyor | CPU=0% RAM=23%\n",
      "[21:57:50] √¢--  2) Giris dogrulama & sabitleme bitti (0.13s) ‚Äî OK | CPU=5% RAM=23%\n",
      "[21:57:50] >> 3) Degisken siniflamasi basliyor | CPU=5% RAM=23%\n",
      "   - numeric=10, categorical=4\n",
      "[21:57:50] √¢--  3) Degisken siniflamasi bitti (0.11s) ‚Äî OK | CPU=0% RAM=23%\n",
      "[21:57:50] >> 4) Eksik & Nadir deger politikasi basliyor | CPU=0% RAM=23%\n",
      "[21:57:50] √¢--  4) Eksik & Nadir deger politikasi bitti (0.11s) ‚Äî OK | CPU=0% RAM=23%\n",
      "[21:57:50] >> 5) Zaman bolmesi (Train/Test/OOT) basliyor | CPU=2% RAM=23%\n",
      "   - Train=6233, Test=1558, OOT=2209\n",
      "[21:57:51] √¢--  5) Zaman bolmesi (Train/Test/OOT) bitti (0.12s) ‚Äî OK | CPU=4% RAM=23%\n",
      "[21:57:51] >> 6) WOE binleme (yalniz Train; adaptif) basliyor | CPU=0% RAM=23%\n",
      "   - WOE hazir: 14 degisken\n",
      "   - Not: WOE haritasi SADECE TRAIN'de ogrenildi\n",
      "[21:57:51] √¢--  6) WOE binleme (yalniz Train; adaptif) bitti (0.15s) ‚Äî OK | CPU=3% RAM=23%\n",
      "[21:57:51] >> 7) PSI (vektorize) basliyor | CPU=2% RAM=23%\n",
      "   * PSI √∂zet: KEEP=10 | DROP=4 | WARN=0\n",
      "   - PSI sonrasi kalan: 10\n",
      "[21:57:51] √¢--  7) PSI (vektorize) bitti (0.36s) ‚Äî OK | CPU=0% RAM=23%\n",
      "   - High IV flags: risk_score,payment_score,debt_ratio,income_level,noise_feature1,noise_feature2,employment_type,product_type,utilization_rate,num_inquiries\n",
      "[21:57:51] >> 8) WOE transform (Train/Test/OOT) basliyor | CPU=2% RAM=23%\n",
      "   - X_train=(6233, 10), X_test=(1558, 10), X_oot=(2209, 10)\n",
      "[21:57:52] √¢--  8) WOE transform (Train/Test/OOT) bitti (0.37s) ‚Äî OK | CPU=5% RAM=23%\n",
      "[21:57:52] >> 9) Korelasyon & cluster basliyor | CPU=6% RAM=23%\n",
      "   - cluster temsilcisi=10\n",
      "[21:57:52] √¢--  9) Korelasyon & cluster bitti (0.12s) ‚Äî OK | CPU=1% RAM=23%\n",
      "[21:57:52] >> 10) Feature selection (Forward+1SE) basliyor | CPU=2% RAM=23%\n",
      "   - Boruta: 7/10 kaldi\n",
      "   - Forward+1SE secti: 6\n",
      "   - baseline degisken=6\n",
      "[21:58:00] √¢--  10) Feature selection (Forward+1SE) bitti (8.13s) ‚Äî OK | CPU=6% RAM=23%\n",
      "[21:58:00] >> 11) Nihai korelasyon filtresi basliyor | CPU=7% RAM=23%\n",
      "   - corr sonrasi=6\n",
      "[21:58:00] √¢--  11) Nihai korelasyon filtresi bitti (0.11s) ‚Äî OK | CPU=3% RAM=23%\n",
      "[21:58:01] >> 12) Gurultu (noise) sentineli basliyor | CPU=3% RAM=23%\n",
      "   - final degisken=6\n",
      "[21:58:03] √¢--  12) Gurultu (noise) sentineli bitti (2.84s) ‚Äî OK | CPU=3% RAM=23%\n",
      "[21:58:03] >> 13) Modelleme & degerlendirme (WOE) basliyor | CPU=2% RAM=23%\n",
      "[21:58:04]   - WOE_Logit_L2 tuning | CPU=2% RAM=23%\n",
      "[21:58:06]   - WOE_Logit_L2 CV basliyor | CPU=1% RAM=23%\n",
      "[21:58:06]   - WOE_RandomForest tuning | CPU=1% RAM=23%\n",
      "[21:58:36]   - WOE_RandomForest CV basliyor | CPU=0% RAM=23%\n",
      "[21:58:52]   - WOE_ExtraTrees tuning | CPU=0% RAM=23%\n",
      "[21:59:22]   - WOE_ExtraTrees CV basliyor | CPU=3% RAM=23%\n",
      "[21:59:25]   - WOE_XGBoost tuning | CPU=0% RAM=23%\n",
      "[21:59:44]   - WOE_XGBoost CV basliyor | CPU=52% RAM=24%\n",
      "[21:59:45]   - WOE_LightGBM tuning | CPU=46% RAM=24%\n",
      "[22:00:16]   - WOE_LightGBM CV basliyor | CPU=78% RAM=24%\n",
      "[22:00:22]   - WOE_GAM tuning | CPU=50% RAM=24%\n",
      "[22:00:45]   - WOE_GAM CV basliyor | CPU=0% RAM=24%\n",
      "[22:00:50] √¢--  13) Modelleme & degerlendirme (WOE) bitti (166.17s) ‚Äî OK | CPU=3% RAM=24%\n",
      "\n",
      "================================================================================\n",
      "DUAL PIPELINE: RAW VARIABLES (Ham Degiskenler)\n",
      "================================================================================\n",
      "[22:00:50] >> 8b) Raw transform (Train/Test/OOT) basliyor | CPU=1% RAM=24%\n",
      "   - X_train_raw=(6233, 16), X_test_raw=(1558, 16), X_oot_raw=(2209, 16)\n",
      "[22:00:50] √¢--  8b) Raw transform (Train/Test/OOT) bitti (0.14s) ‚Äî OK | CPU=5% RAM=24%\n",
      "[22:00:50] >> 10b) Feature selection RAW (Forward+1SE) basliyor | CPU=5% RAM=24%\n",
      "   - Boruta: 10/16 kaldi\n",
      "   - Forward+1SE secti: 8\n",
      "   - raw baseline degisken=8\n",
      "[22:00:59] √¢--  10b) Feature selection RAW (Forward+1SE) bitti (8.70s) ‚Äî OK | CPU=0% RAM=24%\n",
      "[22:00:59] >> 11b) Nihai korelasyon filtresi RAW basliyor | CPU=2% RAM=24%\n",
      "   - raw corr sonrasi=8\n",
      "[22:00:59] √¢--  11b) Nihai korelasyon filtresi RAW bitti (0.11s) ‚Äî OK | CPU=1% RAM=24%\n",
      "[22:00:59] >> 12b) Gurultu sentineli RAW basliyor | CPU=1% RAM=24%\n",
      "   - raw final degisken=8\n",
      "[22:01:02] √¢--  12b) Gurultu sentineli RAW bitti (2.72s) ‚Äî OK | CPU=12% RAM=24%\n",
      "[22:01:02] >> 13b) Modelleme & degerlendirme (RAW) basliyor | CPU=4% RAM=24%\n",
      "[22:01:02]   - RAW_Logit_L2 tuning | CPU=2% RAM=24%\n",
      "[22:01:03]   - RAW_Logit_L2 CV basliyor | CPU=4% RAM=24%\n",
      "[22:01:03]   - RAW_RandomForest tuning | CPU=3% RAM=24%\n",
      "[22:01:36]   - RAW_RandomForest CV basliyor | CPU=1% RAM=24%\n",
      "[22:01:53]   - RAW_ExtraTrees tuning | CPU=0% RAM=24%\n",
      "[22:02:23]   - RAW_ExtraTrees CV basliyor | CPU=6% RAM=24%\n",
      "[22:02:36]   - RAW_XGBoost tuning | CPU=4% RAM=25%\n",
      "[22:02:58]   - RAW_XGBoost CV basliyor | CPU=53% RAM=25%\n",
      "[22:03:03]   - RAW_LightGBM tuning | CPU=41% RAM=24%\n",
      "[22:03:34]   - RAW_LightGBM CV basliyor | CPU=44% RAM=24%\n",
      "[22:03:43]   - RAW_GAM tuning | CPU=46% RAM=24%\n",
      "[22:04:14]   - RAW_GAM CV basliyor | CPU=3% RAM=25%\n",
      "[22:04:21] √¢--  13b) Modelleme & degerlendirme (RAW) bitti (199.57s) ‚Äî OK | CPU=0% RAM=25%\n",
      "\n",
      "================================================================================\n",
      "DUAL PIPELINE SUMMARY\n",
      "================================================================================\n",
      "WOE Pipeline: 6 variables, 6 models\n",
      "RAW Pipeline: 8 variables, 12 models\n",
      "Best WOE Model: WOE_GAM - Gini OOT: 0.9293\n",
      "Best RAW Model: RAW_GAM - Gini OOT: 0.9816\n",
      "[22:04:22] >> 14) En iyi model secimi basliyor | CPU=0% RAM=25%\n",
      "   - Selection method: balanced\n",
      "   - Selected: RAW_GAM\n",
      "     Gini_OOT=0.9816, Train-OOT Gap=0.0045\n",
      "   - best=RAW_GAM\n",
      "[22:04:22] √¢--  14) En iyi model secimi bitti (0.11s) ‚Äî OK | CPU=2% RAM=25%\n",
      "[22:04:22] >> 15) Rapor tablolari basliyor | CPU=2% RAM=25%\n",
      "[22:04:22] √¢--  15) Rapor tablolari bitti (0.12s) ‚Äî OK | CPU=2% RAM=25%\n",
      "[22:04:22] >> 15b) Export (Excel/Parquet) basliyor | CPU=0% RAM=25%\n",
      "[22:04:23] √¢--  15b) Export (Excel/Parquet) bitti (0.67s) ‚Äî OK | CPU=1% RAM=25%\n",
      "[22:04:23] >> RUN tamam - run_id=20250904_215720_0300ba8a | CPU=2% RAM=25%\n",
      "\n",
      "‚úì Pipeline completed in 393.35 seconds\n"
     ]
    }
   ],
   "source": [
    "# Run pipeline with error handling\n",
    "print(\"Preparing to run pipeline...\")\n",
    "\n",
    "try:\n",
    "    # Import time for elapsed time calculation\n",
    "    import time\n",
    "    import numpy as np\n",
    "    import random\n",
    "    \n",
    "    # Set random seed before pipeline run for consistency\n",
    "    np.random.seed(42)\n",
    "    random.seed(42)\n",
    "    \n",
    "    # Create pipeline instance\n",
    "    pipeline = RiskModelPipeline(config)\n",
    "    print(\"‚úì Pipeline instance created\")\n",
    "    \n",
    "    # Run pipeline\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"STARTING DUAL PIPELINE EXECUTION\")\n",
    "    print(\"=\"*60 + \"\\n\")\n",
    "    \n",
    "    start_time = time.time()\n",
    "    pipeline.run(df)\n",
    "    elapsed = time.time() - start_time\n",
    "    \n",
    "    print(f\"\\n‚úì Pipeline completed in {elapsed:.2f} seconds\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"\\n‚úó Pipeline error: {e}\")\n",
    "    print(\"\\nPossible solutions:\")\n",
    "    print(\"  1. Check if all required packages are installed\")\n",
    "    print(\"  2. Verify numpy/pandas compatibility\")\n",
    "    print(\"  3. Run: pip install git+https://github.com/selimoksuz/risk-model-pipeline.git\")\n",
    "    print(\"\\nDetailed error:\")\n",
    "    import traceback\n",
    "    traceback.print_exc()\n",
    "\n",
    "# Note: Pipeline output will appear here when cell is run"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Review Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "COMPLETE MODEL PERFORMANCE SUMMARY\n",
      "================================================================================\n",
      "\n",
      "üìä ALL MODELS TRAINED:\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Model: RAW_GAM\n",
      "  Pipeline: RAW\n",
      "  Gini_Train: 0.9861\n",
      "  Gini_Test: 0.9865\n",
      "  Gini_OOT: 0.9816\n",
      "  AUC_Train: 0.9931\n",
      "  AUC_Test: 0.9933\n",
      "  AUC_OOT: 0.9908\n",
      "  Train-OOT Gap: 0.0045\n",
      "  KS_OOT: 0.9021\n",
      "\n",
      "Model: RAW_XGBoost\n",
      "  Pipeline: RAW\n",
      "  Gini_Train: 1.0000\n",
      "  Gini_Test: 0.9821\n",
      "  Gini_OOT: 0.9779\n",
      "  AUC_Train: 1.0000\n",
      "  AUC_Test: 0.9911\n",
      "  AUC_OOT: 0.9890\n",
      "  Train-OOT Gap: 0.0221\n",
      "  KS_OOT: 0.8978\n",
      "\n",
      "Model: RAW_LightGBM\n",
      "  Pipeline: RAW\n",
      "  Gini_Train: 1.0000\n",
      "  Gini_Test: 0.9809\n",
      "  Gini_OOT: 0.9753\n",
      "  AUC_Train: 1.0000\n",
      "  AUC_Test: 0.9905\n",
      "  AUC_OOT: 0.9877\n",
      "  Train-OOT Gap: 0.0247\n",
      "  KS_OOT: 0.8839\n",
      "\n",
      "Model: RAW_RandomForest\n",
      "  Pipeline: RAW\n",
      "  Gini_Train: 1.0000\n",
      "  Gini_Test: 0.9758\n",
      "  Gini_OOT: 0.9721\n",
      "  AUC_Train: 1.0000\n",
      "  AUC_Test: 0.9879\n",
      "  AUC_OOT: 0.9861\n",
      "  Train-OOT Gap: 0.0279\n",
      "  KS_OOT: 0.8735\n",
      "\n",
      "Model: RAW_ExtraTrees\n",
      "  Pipeline: RAW\n",
      "  Gini_Train: 1.0000\n",
      "  Gini_Test: 0.9747\n",
      "  Gini_OOT: 0.9691\n",
      "  AUC_Train: 1.0000\n",
      "  AUC_Test: 0.9873\n",
      "  AUC_OOT: 0.9846\n",
      "  Train-OOT Gap: 0.0309\n",
      "  KS_OOT: 0.8642\n",
      "\n",
      "Model: RAW_Logit_L2\n",
      "  Pipeline: RAW\n",
      "  Gini_Train: 0.9704\n",
      "  Gini_Test: 0.9753\n",
      "  Gini_OOT: 0.9678\n",
      "  AUC_Train: 0.9852\n",
      "  AUC_Test: 0.9876\n",
      "  AUC_OOT: 0.9839\n",
      "  Train-OOT Gap: 0.0026\n",
      "  KS_OOT: 0.8752\n",
      "\n",
      "Model: WOE_GAM\n",
      "  Pipeline: WOE\n",
      "  Gini_Train: 0.9321\n",
      "  Gini_Test: 0.9193\n",
      "  Gini_OOT: 0.9293\n",
      "  AUC_Train: 0.9660\n",
      "  AUC_Test: 0.9596\n",
      "  AUC_OOT: 0.9647\n",
      "  Train-OOT Gap: 0.0028\n",
      "  KS_OOT: 0.7874\n",
      "\n",
      "Model: WOE_XGBoost\n",
      "  Pipeline: WOE\n",
      "  Gini_Train: 0.9461\n",
      "  Gini_Test: 0.9125\n",
      "  Gini_OOT: 0.9256\n",
      "  AUC_Train: 0.9731\n",
      "  AUC_Test: 0.9563\n",
      "  AUC_OOT: 0.9628\n",
      "  Train-OOT Gap: 0.0205\n",
      "  KS_OOT: 0.7844\n",
      "\n",
      "Model: WOE_ExtraTrees\n",
      "  Pipeline: WOE\n",
      "  Gini_Train: 0.9465\n",
      "  Gini_Test: 0.9059\n",
      "  Gini_OOT: 0.9213\n",
      "  AUC_Train: 0.9732\n",
      "  AUC_Test: 0.9530\n",
      "  AUC_OOT: 0.9606\n",
      "  Train-OOT Gap: 0.0252\n",
      "  KS_OOT: 0.7825\n",
      "\n",
      "Model: WOE_LightGBM\n",
      "  Pipeline: WOE\n",
      "  Gini_Train: 0.9474\n",
      "  Gini_Test: 0.9049\n",
      "  Gini_OOT: 0.9193\n",
      "  AUC_Train: 0.9737\n",
      "  AUC_Test: 0.9525\n",
      "  AUC_OOT: 0.9596\n",
      "  Train-OOT Gap: 0.0281\n",
      "  KS_OOT: 0.7769\n",
      "\n",
      "Model: WOE_RandomForest\n",
      "  Pipeline: WOE\n",
      "  Gini_Train: 0.9384\n",
      "  Gini_Test: 0.9042\n",
      "  Gini_OOT: 0.9134\n",
      "  AUC_Train: 0.9692\n",
      "  AUC_Test: 0.9521\n",
      "  AUC_OOT: 0.9567\n",
      "  Train-OOT Gap: 0.0250\n",
      "  KS_OOT: 0.7736\n",
      "\n",
      "Model: WOE_Logit_L2\n",
      "  Pipeline: WOE\n",
      "  Gini_Train: 0.9073\n",
      "  Gini_Test: 0.8905\n",
      "  Gini_OOT: 0.9079\n",
      "  AUC_Train: 0.9537\n",
      "  AUC_Test: 0.9452\n",
      "  AUC_OOT: 0.9539\n",
      "  Train-OOT Gap: 0.0005\n",
      "  KS_OOT: 0.7588\n",
      "\n",
      "================================================================================\n",
      "PIPELINE COMPARISON ANALYSIS\n",
      "================================================================================\n",
      "\n",
      "WOE Pipeline Performance:\n",
      "  Total Models: 6\n",
      "  Best Gini_OOT: 0.9293\n",
      "  Mean Gini_OOT: 0.9194\n",
      "  Std Gini_OOT: 0.0079\n",
      "  Most Stable Model: WOE_Logit_L2\n",
      "    - Train-OOT Gap: 0.0005\n",
      "\n",
      "RAW Pipeline Performance:\n",
      "  Total Models: 6\n",
      "  Best Gini_OOT: 0.9816\n",
      "  Mean Gini_OOT: 0.9740\n",
      "  Std Gini_OOT: 0.0053\n",
      "  Most Stable Model: RAW_Logit_L2\n",
      "    - Train-OOT Gap: 0.0026\n",
      "\n",
      "================================================================================\n",
      "FEATURE SELECTION DETAILED ANALYSIS\n",
      "================================================================================\n",
      "\n",
      "================================================================================\n",
      "PSI (POPULATION STABILITY INDEX) ANALYSIS\n",
      "================================================================================\n",
      "\n",
      "================================================================================\n",
      "INFORMATION VALUE (IV) ANALYSIS\n",
      "================================================================================\n",
      "\n",
      "Top Features by IV:\n",
      "  1. credit_history_months: IV=2.9489 (Very Strong)\n",
      "  2. risk_score: IV=2.9437 (Very Strong)\n",
      "  3. payment_score: IV=2.9437 (Very Strong)\n",
      "  4. utilization_rate: IV=2.9437 (Very Strong)\n",
      "  5. debt_ratio: IV=2.9437 (Very Strong)\n",
      "  6. noise_feature1: IV=2.9437 (Very Strong)\n",
      "  7. noise_feature2: IV=2.9437 (Very Strong)\n",
      "  8. snapshot_month: IV=2.9436 (Very Strong)\n",
      "  9. num_credit_lines: IV=2.9433 (Very Strong)\n",
      "  10. num_inquiries: IV=2.9431 (Very Strong)\n",
      "\n",
      "================================================================================\n",
      "BEST MODEL SELECTION ANALYSIS\n",
      "================================================================================\n",
      "\n",
      "================================================================================\n",
      "OVERALL PIPELINE STATISTICS\n",
      "================================================================================\n",
      "\n",
      "Total Models Trained: 12\n",
      "WOE Models: 6\n",
      "RAW Models: 6\n",
      "\n",
      "Performance Range:\n",
      "  Gini_OOT: 0.9079 - 0.9816\n",
      "  Mean Gini_OOT: 0.9467\n",
      "  Std Gini_OOT: 0.0292\n"
     ]
    }
   ],
   "source": [
    "# Complete Results Display - Full Output\n",
    "try:\n",
    "    print(\"=\"*80)\n",
    "    print(\"COMPLETE MODEL PERFORMANCE SUMMARY\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    if hasattr(pipeline, 'models_summary_') and pipeline.models_summary_ is not None:\n",
    "        summary = pipeline.models_summary_\n",
    "        \n",
    "        # Display full model summary\n",
    "        print(\"\\nüìä ALL MODELS TRAINED:\")\n",
    "        print(\"-\"*80)\n",
    "        \n",
    "        # Show all columns for complete information\n",
    "        pd.set_option('display.max_columns', None)\n",
    "        pd.set_option('display.width', None)\n",
    "        pd.set_option('display.max_rows', None)\n",
    "        \n",
    "        # Sort by Gini_OOT for better readability\n",
    "        summary_sorted = summary.sort_values('Gini_OOT', ascending=False)\n",
    "        \n",
    "        # Display all models with all metrics\n",
    "        for idx, row in summary_sorted.iterrows():\n",
    "            print(f\"\\nModel: {row['model_name']}\")\n",
    "            print(f\"  Pipeline: {row.get('pipeline', 'N/A')}\")\n",
    "            print(f\"  Gini_Train: {row.get('Gini_Train', 'N/A'):.4f}\")\n",
    "            print(f\"  Gini_Test: {row.get('Gini_Test', 'N/A'):.4f}\")\n",
    "            print(f\"  Gini_OOT: {row.get('Gini_OOT', 'N/A'):.4f}\")\n",
    "            print(f\"  AUC_Train: {row.get('AUC_Train', 'N/A'):.4f}\")\n",
    "            print(f\"  AUC_Test: {row.get('AUC_Test', 'N/A'):.4f}\")\n",
    "            print(f\"  AUC_OOT: {row.get('AUC_OOT', 'N/A'):.4f}\")\n",
    "            \n",
    "            # Calculate stability metrics\n",
    "            if 'Gini_Train' in row and 'Gini_OOT' in row:\n",
    "                train_oot_gap = abs(row['Gini_Train'] - row['Gini_OOT'])\n",
    "                print(f\"  Train-OOT Gap: {train_oot_gap:.4f}\")\n",
    "                \n",
    "            if 'KS_OOT' in row:\n",
    "                print(f\"  KS_OOT: {row['KS_OOT']:.4f}\")\n",
    "        \n",
    "        # Pipeline Comparison\n",
    "        print(\"\\n\" + \"=\"*80)\n",
    "        print(\"PIPELINE COMPARISON ANALYSIS\")\n",
    "        print(\"=\"*80)\n",
    "        \n",
    "        for pipeline_type in ['WOE', 'RAW']:\n",
    "            pipeline_models = summary[summary['model_name'].str.contains(pipeline_type)]\n",
    "            if not pipeline_models.empty:\n",
    "                print(f\"\\n{pipeline_type} Pipeline Performance:\")\n",
    "                print(f\"  Total Models: {len(pipeline_models)}\")\n",
    "                print(f\"  Best Gini_OOT: {pipeline_models['Gini_OOT'].max():.4f}\")\n",
    "                print(f\"  Mean Gini_OOT: {pipeline_models['Gini_OOT'].mean():.4f}\")\n",
    "                print(f\"  Std Gini_OOT: {pipeline_models['Gini_OOT'].std():.4f}\")\n",
    "                \n",
    "                # Find most stable model (smallest Train-OOT gap)\n",
    "                pipeline_models['train_oot_gap'] = abs(\n",
    "                    pipeline_models['Gini_Train'] - pipeline_models['Gini_OOT']\n",
    "                )\n",
    "                most_stable = pipeline_models.nsmallest(1, 'train_oot_gap').iloc[0]\n",
    "                print(f\"  Most Stable Model: {most_stable['model_name']}\")\n",
    "                print(f\"    - Train-OOT Gap: {most_stable['train_oot_gap']:.4f}\")\n",
    "                \n",
    "        # Feature Analysis\n",
    "        print(\"\\n\" + \"=\"*80)\n",
    "        print(\"FEATURE SELECTION DETAILED ANALYSIS\")\n",
    "        print(\"=\"*80)\n",
    "        \n",
    "        if hasattr(pipeline, 'final_vars'):\n",
    "            print(f\"\\n‚úÖ Final Variables Selected ({len(pipeline.final_vars)}):\")\n",
    "            for i, var in enumerate(pipeline.final_vars, 1):\n",
    "                print(f\"  {i}. {var}\")\n",
    "        \n",
    "        if hasattr(pipeline, 'raw_final_vars'):\n",
    "            print(f\"\\n‚úÖ RAW Final Variables ({len(pipeline.raw_final_vars)}):\")\n",
    "            for i, var in enumerate(pipeline.raw_final_vars, 1):\n",
    "                print(f\"  {i}. {var}\")\n",
    "                \n",
    "        # PSI Analysis\n",
    "        print(\"\\n\" + \"=\"*80)\n",
    "        print(\"PSI (POPULATION STABILITY INDEX) ANALYSIS\")\n",
    "        print(\"=\"*80)\n",
    "        \n",
    "        if hasattr(pipeline, 'psi_summary'):\n",
    "            psi_df = pipeline.psi_summary\n",
    "            if not psi_df.empty:\n",
    "                print(f\"\\nTotal Features Analyzed: {len(psi_df)}\")\n",
    "                \n",
    "                # Group by status\n",
    "                status_counts = psi_df['status'].value_counts()\n",
    "                for status, count in status_counts.items():\n",
    "                    print(f\"  {status}: {count} features\")\n",
    "                \n",
    "                # Show all features with their PSI values\n",
    "                print(\"\\nDetailed PSI Values:\")\n",
    "                for _, row in psi_df.iterrows():\n",
    "                    psi_val = row['psi']\n",
    "                    status_icon = \"‚úÖ\" if row['status'] == \"KEEP\" else \"‚ùå\"\n",
    "                    print(f\"  {status_icon} {row['variable']}: PSI={psi_val:.4f} [{row['status']}]\")\n",
    "        \n",
    "        # IV Analysis\n",
    "        print(\"\\n\" + \"=\"*80)\n",
    "        print(\"INFORMATION VALUE (IV) ANALYSIS\")\n",
    "        print(\"=\"*80)\n",
    "        \n",
    "        if hasattr(pipeline, 'woe_map'):\n",
    "            iv_values = []\n",
    "            for var, woe_obj in pipeline.woe_map.items():\n",
    "                if hasattr(woe_obj, 'iv'):\n",
    "                    iv_values.append((var, woe_obj.iv))\n",
    "            \n",
    "            if iv_values:\n",
    "                iv_values.sort(key=lambda x: x[1], reverse=True)\n",
    "                print(f\"\\nTop Features by IV:\")\n",
    "                for i, (var, iv) in enumerate(iv_values[:10], 1):\n",
    "                    strength = \"Very Strong\" if iv > 0.5 else \"Strong\" if iv > 0.3 else \"Medium\" if iv > 0.1 else \"Weak\"\n",
    "                    print(f\"  {i}. {var}: IV={iv:.4f} ({strength})\")\n",
    "        \n",
    "        # Model Selection Criteria\n",
    "        print(\"\\n\" + \"=\"*80)\n",
    "        print(\"BEST MODEL SELECTION ANALYSIS\")\n",
    "        print(\"=\"*80)\n",
    "        \n",
    "        if hasattr(pipeline, 'best_model_name'):\n",
    "            best_model_row = summary[summary['model_name'] == pipeline.best_model_name].iloc[0]\n",
    "            print(f\"\\nüèÜ Selected Best Model: {pipeline.best_model_name}\")\n",
    "            print(f\"  Gini_OOT: {best_model_row['Gini_OOT']:.4f}\")\n",
    "            print(f\"  Gini_Train: {best_model_row['Gini_Train']:.4f}\")\n",
    "            print(f\"  Train-OOT Gap: {abs(best_model_row['Gini_Train'] - best_model_row['Gini_OOT']):.4f}\")\n",
    "            \n",
    "            # Alternative selection criteria\n",
    "            print(\"\\nüìà Alternative Best Models:\")\n",
    "            \n",
    "            # By pure performance\n",
    "            best_perf = summary.nlargest(1, 'Gini_OOT').iloc[0]\n",
    "            print(f\"\\n1. By Highest OOT Performance:\")\n",
    "            print(f\"   Model: {best_perf['model_name']}\")\n",
    "            print(f\"   Gini_OOT: {best_perf['Gini_OOT']:.4f}\")\n",
    "            \n",
    "            # By stability\n",
    "            summary['stability_gap'] = abs(summary['Gini_Train'] - summary['Gini_OOT'])\n",
    "            best_stable = summary.nsmallest(1, 'stability_gap').iloc[0]\n",
    "            print(f\"\\n2. By Best Stability (Smallest Train-OOT Gap):\")\n",
    "            print(f\"   Model: {best_stable['model_name']}\")\n",
    "            print(f\"   Train-OOT Gap: {best_stable['stability_gap']:.4f}\")\n",
    "            print(f\"   Gini_OOT: {best_stable['Gini_OOT']:.4f}\")\n",
    "            \n",
    "            # By balanced criteria\n",
    "            summary['balanced_score'] = (\n",
    "                0.7 * summary['Gini_OOT'] - 0.3 * summary['stability_gap']\n",
    "            )\n",
    "            best_balanced = summary.nlargest(1, 'balanced_score').iloc[0]\n",
    "            print(f\"\\n3. By Balanced Criteria (70% Performance + 30% Stability):\")\n",
    "            print(f\"   Model: {best_balanced['model_name']}\")\n",
    "            print(f\"   Gini_OOT: {best_balanced['Gini_OOT']:.4f}\")\n",
    "            print(f\"   Train-OOT Gap: {best_balanced['stability_gap']:.4f}\")\n",
    "        \n",
    "        # Summary Statistics\n",
    "        print(\"\\n\" + \"=\"*80)\n",
    "        print(\"OVERALL PIPELINE STATISTICS\")\n",
    "        print(\"=\"*80)\n",
    "        \n",
    "        print(f\"\\nTotal Models Trained: {len(summary)}\")\n",
    "        print(f\"WOE Models: {len(summary[summary['model_name'].str.contains('WOE')])}\")\n",
    "        print(f\"RAW Models: {len(summary[summary['model_name'].str.contains('RAW')])}\")\n",
    "        \n",
    "        print(f\"\\nPerformance Range:\")\n",
    "        print(f\"  Gini_OOT: {summary['Gini_OOT'].min():.4f} - {summary['Gini_OOT'].max():.4f}\")\n",
    "        print(f\"  Mean Gini_OOT: {summary['Gini_OOT'].mean():.4f}\")\n",
    "        print(f\"  Std Gini_OOT: {summary['Gini_OOT'].std():.4f}\")\n",
    "        \n",
    "        # Reset display options\n",
    "        pd.reset_option('display.max_columns')\n",
    "        pd.reset_option('display.width')\n",
    "        pd.reset_option('display.max_rows')\n",
    "        \n",
    "    else:\n",
    "        print(\"‚ùå No model summary available\")\n",
    "        print(\"\\nPossible reasons:\")\n",
    "        print(\"  1. Pipeline execution failed\")\n",
    "        print(\"  2. All features were filtered out\")\n",
    "        print(\"  3. Check error logs above\")\n",
    "        \n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Error displaying results: {e}\")\n",
    "    import traceback\n",
    "    traceback.print_exc()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Export Reports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úì Reports exported successfully!\n",
      "\n",
      "Generated 4 files in 'outputs_dual_example':\n",
      "  - best_model_20250904_215720_0300ba8a.joblib (210.1 KB)\n",
      "  - dual_pipeline_results.xlsx (28.8 KB)\n",
      "  - final_vars_20250904_215720_0300ba8a.json (0.2 KB)\n",
      "  - woe_mapping_20250904_215720_0300ba8a.json (32.9 KB)\n"
     ]
    }
   ],
   "source": [
    "# Export reports\n",
    "try:\n",
    "    pipeline.export_reports()\n",
    "    print(\"‚úì Reports exported successfully!\")\n",
    "    \n",
    "    # List generated files\n",
    "    import os\n",
    "    if os.path.exists(config.output_folder):\n",
    "        files = os.listdir(config.output_folder)\n",
    "        print(f\"\\nGenerated {len(files)} files in '{config.output_folder}':\")\n",
    "        for f in sorted(files)[:10]:\n",
    "            size = os.path.getsize(os.path.join(config.output_folder, f)) / 1024\n",
    "            print(f\"  - {f} ({size:.1f} KB)\")\n",
    "        if len(files) > 10:\n",
    "            print(f\"  ... and {len(files)-10} more files\")\n",
    "            \n",
    "except Exception as e:\n",
    "    print(f\"Error exporting reports: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Troubleshooting\n",
    "\n",
    "If you encounter any errors:\n",
    "\n",
    "1. **numpy.dtype size changed error**:\n",
    "   ```bash\n",
    "   pip install git+https://github.com/selimoksuz/risk-model-pipeline.git\n",
    "   ```\n",
    "\n",
    "2. **Import errors**:\n",
    "   ```bash\n",
    "   pip install --force-reinstall git+https://github.com/selimoksuz/risk-model-pipeline.git\n",
    "   ```\n",
    "\n",
    "3. **Memory issues**:\n",
    "   - Reduce n_samples in create_sample_data()\n",
    "   - Reduce hpo_trials in config\n",
    "\n",
    "4. **Create fresh environment**:\n",
    "   ```bash\n",
    "   python -m venv fresh_env\n",
    "   fresh_env\\Scripts\\activate  # Windows\n",
    "   pip install git+https://github.com/selimoksuz/risk-model-pipeline.git\n",
    "   ```"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (Anaconda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
