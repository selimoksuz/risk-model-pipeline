{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Risk Model Pipeline - Dual Pipeline Example\n",
    "\n",
    "## ⚠️ IMPORTANT: Environment Setup\n",
    "\n",
    "If you encounter `numpy.dtype size changed` error, please follow these steps:\n",
    "\n",
    "### Option 1: Use Fixed Requirements (Recommended)\n",
    "```bash\n",
    "# From project root directory\n",
    "pip install -r requirements_fixed.txt\n",
    "```\n",
    "\n",
    "### Option 2: Create Clean Environment\n",
    "```bash\n",
    "# Windows\n",
    "setup_environment.bat\n",
    "\n",
    "# Linux/Mac\n",
    "bash setup_environment.sh\n",
    "```\n",
    "\n",
    "### Option 3: Manual Fix\n",
    "```bash\n",
    "pip uninstall -y numpy pandas scikit-learn\n",
    "pip install numpy==1.24.3 pandas==1.5.3 scikit-learn==1.3.0\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Environment Check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting numpy==1.24.3\n",
      "  Downloading numpy-1.24.3-cp39-cp39-win_amd64.whl (14.9 MB)\n",
      "     --------------------------------------- 14.9/14.9 MB 13.6 MB/s eta 0:00:00\n",
      "Collecting pandas==1.5.3\n",
      "  Downloading pandas-1.5.3-cp39-cp39-win_amd64.whl (10.9 MB)\n",
      "     --------------------------------------- 10.9/10.9 MB 13.6 MB/s eta 0:00:00\n",
      "Collecting scikit-learn==1.3.0\n",
      "  Downloading scikit_learn-1.3.0-cp39-cp39-win_amd64.whl (9.3 MB)\n",
      "     ---------------------------------------- 9.3/9.3 MB 13.5 MB/s eta 0:00:00\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\acer\\anaconda3\\lib\\site-packages (from pandas==1.5.3) (2022.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in c:\\users\\acer\\anaconda3\\lib\\site-packages (from pandas==1.5.3) (2.8.2)\n",
      "Collecting joblib>=1.1.1\n",
      "  Using cached joblib-1.5.2-py3-none-any.whl (308 kB)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\acer\\anaconda3\\lib\\site-packages (from scikit-learn==1.3.0) (2.2.0)\n",
      "Requirement already satisfied: scipy>=1.5.0 in c:\\users\\acer\\anaconda3\\lib\\site-packages (from scikit-learn==1.3.0) (1.13.1)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\acer\\anaconda3\\lib\\site-packages (from python-dateutil>=2.8.1->pandas==1.5.3) (1.16.0)\n",
      "Installing collected packages: numpy, joblib, pandas, scikit-learn\n",
      "  Attempting uninstall: joblib\n",
      "    Found existing installation: joblib 1.1.0\n",
      "    Uninstalling joblib-1.1.0:\n",
      "      Successfully uninstalled joblib-1.1.0\n",
      "Successfully installed joblib-1.5.2 numpy-1.24.3 pandas-1.5.3 scikit-learn-1.3.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "daal4py 2021.6.0 requires daal==2021.4.0, which is not installed.\n",
      "numba 0.55.1 requires numpy<1.22,>=1.18, but you have numpy 1.24.3 which is incompatible.\n"
     ]
    }
   ],
   "source": [
    "pip install numpy==1.24.3 pandas==1.5.3 scikit-learn==1.3.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python: 3.9.13 (main, Aug 25 2022, 23:51:50) [MSC v.1916 64 bit (AMD64)]\n",
      "Python executable: C:\\Users\\Acer\\anaconda3\\python.exe\n",
      "--------------------------------------------------\n",
      "✓ numpy: 1.24.3\n",
      "✓ pandas: 1.5.3\n",
      "✓ sklearn: 1.3.0\n",
      "\n",
      "✓ All packages imported successfully!\n"
     ]
    }
   ],
   "source": [
    "# Check Python and package versions\n",
    "import sys\n",
    "print(f\"Python: {sys.version}\")\n",
    "print(f\"Python executable: {sys.executable}\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "# Try importing packages and show versions\n",
    "packages = [\n",
    "    ('numpy', 'np'),\n",
    "    ('pandas', 'pd'),\n",
    "    ('sklearn', 'sklearn')\n",
    "]\n",
    "\n",
    "import_success = True\n",
    "for package_name, import_name in packages:\n",
    "    try:\n",
    "        module = __import__(package_name)\n",
    "        print(f\"✓ {package_name}: {module.__version__}\")\n",
    "    except ImportError as e:\n",
    "        print(f\"✗ {package_name}: Not installed\")\n",
    "        import_success = False\n",
    "    except Exception as e:\n",
    "        print(f\"✗ {package_name}: Error - {e}\")\n",
    "        import_success = False\n",
    "\n",
    "if not import_success:\n",
    "    print(\"\\n⚠️ Please install missing packages or fix version conflicts.\")\n",
    "    print(\"Run: pip install -r ../requirements_fixed.txt\")\n",
    "else:\n",
    "    print(\"\\n✓ All packages imported successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Setup and Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added to path:\n",
      "  - C:\\Users\\Acer\\risk-model-pipeline\n",
      "  - C:\\Users\\Acer\\risk-model-pipeline\\src\n",
      "\n",
      "✓ Core packages imported successfully!\n",
      "  NumPy: 1.24.3\n",
      "  Pandas: 1.5.3\n"
     ]
    }
   ],
   "source": [
    "# Add parent directory to path\n",
    "import sys\n",
    "import os\n",
    "\n",
    "# Get the parent directory\n",
    "parent_dir = os.path.dirname(os.getcwd())\n",
    "if parent_dir not in sys.path:\n",
    "    sys.path.insert(0, parent_dir)\n",
    "\n",
    "# Also add src directory explicitly\n",
    "src_dir = os.path.join(parent_dir, 'src')\n",
    "if src_dir not in sys.path:\n",
    "    sys.path.insert(0, src_dir)\n",
    "\n",
    "print(f\"Added to path:\")\n",
    "print(f\"  - {parent_dir}\")\n",
    "print(f\"  - {src_dir}\")\n",
    "\n",
    "# Suppress warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "warnings.simplefilter('ignore')\n",
    "\n",
    "# Now import packages\n",
    "try:\n",
    "    import numpy as np\n",
    "    import pandas as pd\n",
    "    import time\n",
    "    from datetime import datetime, timedelta\n",
    "    \n",
    "    print(\"\\n✓ Core packages imported successfully!\")\n",
    "    print(f\"  NumPy: {np.__version__}\")\n",
    "    print(f\"  Pandas: {pd.__version__}\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"\\n✗ Error importing packages: {e}\")\n",
    "    print(\"\\nPlease run: pip install -r ../requirements_fixed.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Pipeline imported successfully!\n"
     ]
    }
   ],
   "source": [
    "# Import pipeline - with better error handling\n",
    "try:\n",
    "    from risk_pipeline.pipeline16 import Config, RiskModelPipeline\n",
    "    print(\"✓ Pipeline imported successfully!\")\n",
    "except ImportError as e:\n",
    "    print(f\"✗ Cannot import pipeline: {e}\")\n",
    "    print(\"\\nTrying alternative import...\")\n",
    "    try:\n",
    "        # Try direct import if package not installed\n",
    "        sys.path.insert(0, os.path.join(parent_dir, 'src'))\n",
    "        from risk_pipeline.pipeline16 import Config, RiskModelPipeline\n",
    "        print(\"✓ Pipeline imported via direct path!\")\n",
    "    except Exception as e2:\n",
    "        print(f\"✗ Failed to import pipeline: {e2}\")\n",
    "        print(\"\\nPlease ensure you're in the correct directory and the package is installed.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Generate Sample Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset created:\n",
      "  Shape: (10000, 14)\n",
      "  Default rate: 25.00%\n",
      "  Date range: 2022-01-01 to 2023-02-21\n",
      "  Missing values: 1000\n",
      "\n",
      "✓ Data generated successfully!\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>app_id</th>\n",
       "      <th>app_dt</th>\n",
       "      <th>risk_score</th>\n",
       "      <th>payment_score</th>\n",
       "      <th>debt_ratio</th>\n",
       "      <th>income_level</th>\n",
       "      <th>credit_history_months</th>\n",
       "      <th>num_credit_lines</th>\n",
       "      <th>utilization_rate</th>\n",
       "      <th>num_inquiries</th>\n",
       "      <th>employment_type</th>\n",
       "      <th>region</th>\n",
       "      <th>product_type</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2022-01-01 00:00:00</td>\n",
       "      <td>0.353677</td>\n",
       "      <td>0.576435</td>\n",
       "      <td>0.604789</td>\n",
       "      <td>66096.391145</td>\n",
       "      <td>7.454650</td>\n",
       "      <td>5</td>\n",
       "      <td>0.720952</td>\n",
       "      <td>3</td>\n",
       "      <td>Full-time</td>\n",
       "      <td>East</td>\n",
       "      <td>A</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>2022-01-01 01:00:00</td>\n",
       "      <td>0.248558</td>\n",
       "      <td>0.935896</td>\n",
       "      <td>0.245044</td>\n",
       "      <td>13009.413385</td>\n",
       "      <td>26.725380</td>\n",
       "      <td>3</td>\n",
       "      <td>0.319858</td>\n",
       "      <td>3</td>\n",
       "      <td>Part-time</td>\n",
       "      <td>North</td>\n",
       "      <td>A</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>2022-01-01 02:00:00</td>\n",
       "      <td>0.415959</td>\n",
       "      <td>0.924080</td>\n",
       "      <td>0.405689</td>\n",
       "      <td>65966.324008</td>\n",
       "      <td>27.662485</td>\n",
       "      <td>5</td>\n",
       "      <td>0.657510</td>\n",
       "      <td>1</td>\n",
       "      <td>Self-employed</td>\n",
       "      <td>West</td>\n",
       "      <td>A</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>2022-01-01 03:00:00</td>\n",
       "      <td>0.159968</td>\n",
       "      <td>0.626639</td>\n",
       "      <td>0.602617</td>\n",
       "      <td>46467.378787</td>\n",
       "      <td>44.511552</td>\n",
       "      <td>3</td>\n",
       "      <td>0.702942</td>\n",
       "      <td>0</td>\n",
       "      <td>Full-time</td>\n",
       "      <td>East</td>\n",
       "      <td>A</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>2022-01-01 04:00:00</td>\n",
       "      <td>0.550283</td>\n",
       "      <td>0.854347</td>\n",
       "      <td>0.577085</td>\n",
       "      <td>14137.477402</td>\n",
       "      <td>11.483100</td>\n",
       "      <td>3</td>\n",
       "      <td>0.282394</td>\n",
       "      <td>1</td>\n",
       "      <td>Unemployed</td>\n",
       "      <td>East</td>\n",
       "      <td>A</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   app_id              app_dt  risk_score  payment_score  debt_ratio  \\\n",
       "0       1 2022-01-01 00:00:00    0.353677       0.576435    0.604789   \n",
       "1       2 2022-01-01 01:00:00    0.248558       0.935896    0.245044   \n",
       "2       3 2022-01-01 02:00:00    0.415959       0.924080    0.405689   \n",
       "3       4 2022-01-01 03:00:00    0.159968       0.626639    0.602617   \n",
       "4       5 2022-01-01 04:00:00    0.550283       0.854347    0.577085   \n",
       "\n",
       "   income_level  credit_history_months  num_credit_lines  utilization_rate  \\\n",
       "0  66096.391145               7.454650                 5          0.720952   \n",
       "1  13009.413385              26.725380                 3          0.319858   \n",
       "2  65966.324008              27.662485                 5          0.657510   \n",
       "3  46467.378787              44.511552                 3          0.702942   \n",
       "4  14137.477402              11.483100                 3          0.282394   \n",
       "\n",
       "   num_inquiries employment_type region product_type  target  \n",
       "0              3       Full-time   East            A       0  \n",
       "1              3       Part-time  North            A       0  \n",
       "2              1   Self-employed   West            A       1  \n",
       "3              0       Full-time   East            A       0  \n",
       "4              1      Unemployed   East            A       1  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def create_sample_data(n_samples=10000, seed=42):\n",
    "    \"\"\"Create sample credit risk data\"\"\"\n",
    "    np.random.seed(seed)\n",
    "    \n",
    "    # Generate features\n",
    "    data = {\n",
    "        'app_id': range(1, n_samples + 1),\n",
    "        'app_dt': pd.date_range(start='2022-01-01', periods=n_samples, freq='H')[:n_samples],\n",
    "    }\n",
    "    \n",
    "    # Risk features (numeric)\n",
    "    data['risk_score'] = np.random.beta(2, 5, n_samples)\n",
    "    data['payment_score'] = np.random.beta(3, 2, n_samples)\n",
    "    data['debt_ratio'] = np.random.beta(2, 3, n_samples)\n",
    "    data['income_level'] = np.random.lognormal(10, 1.5, n_samples)\n",
    "    data['credit_history_months'] = np.random.gamma(3, 10, n_samples)\n",
    "    data['num_credit_lines'] = np.random.poisson(3, n_samples)\n",
    "    data['utilization_rate'] = np.random.beta(3, 2, n_samples)\n",
    "    data['num_inquiries'] = np.random.poisson(2, n_samples)\n",
    "    \n",
    "    # Categorical features\n",
    "    data['employment_type'] = np.random.choice(\n",
    "        ['Full-time', 'Part-time', 'Self-employed', 'Unemployed'], \n",
    "        n_samples, \n",
    "        p=[0.6, 0.2, 0.15, 0.05]\n",
    "    )\n",
    "    data['region'] = np.random.choice(['North', 'South', 'East', 'West'], n_samples)\n",
    "    data['product_type'] = np.random.choice(['A', 'B', 'C'], n_samples, p=[0.5, 0.3, 0.2])\n",
    "    \n",
    "    # Create target\n",
    "    risk_factor = (\n",
    "        3.0 * data['risk_score'] + \n",
    "        2.5 * data['payment_score'] + \n",
    "        2.0 * data['debt_ratio'] + \n",
    "        1.5 * data['utilization_rate'] +\n",
    "        0.5 * (data['num_inquiries'] / 10) +\n",
    "        -0.3 * np.log1p(data['income_level'] / 10000) +\n",
    "        -0.2 * np.log1p(data['credit_history_months'] / 12) +\n",
    "        np.random.normal(0, 0.5, n_samples)\n",
    "    )\n",
    "    \n",
    "    default_prob = 1 / (1 + np.exp(-2 * (risk_factor - np.median(risk_factor))))\n",
    "    data['target'] = np.random.binomial(1, default_prob)\n",
    "    \n",
    "    # Adjust default rate\n",
    "    if data['target'].mean() > 0.25:\n",
    "        threshold = np.percentile(default_prob, 75)\n",
    "        data['target'] = (default_prob > threshold).astype(int)\n",
    "    elif data['target'].mean() < 0.10:\n",
    "        threshold = np.percentile(default_prob, 90)\n",
    "        data['target'] = (default_prob > threshold).astype(int)\n",
    "    \n",
    "    # Add missing values\n",
    "    missing_cols = ['income_level', 'credit_history_months']\n",
    "    for col in missing_cols:\n",
    "        missing_idx = np.random.choice(n_samples, size=int(0.05 * n_samples), replace=False)\n",
    "        data[col][missing_idx] = np.nan\n",
    "    \n",
    "    df = pd.DataFrame(data)\n",
    "    \n",
    "    print(f\"Dataset created:\")\n",
    "    print(f\"  Shape: {df.shape}\")\n",
    "    print(f\"  Default rate: {df['target'].mean():.2%}\")\n",
    "    print(f\"  Date range: {df['app_dt'].min().date()} to {df['app_dt'].max().date()}\")\n",
    "    print(f\"  Missing values: {df.isnull().sum().sum()}\")\n",
    "    \n",
    "    return df\n",
    "\n",
    "# Generate data\n",
    "try:\n",
    "    df = create_sample_data(n_samples=10000, seed=42)\n",
    "    print(\"\\n✓ Data generated successfully!\")\n",
    "    display(df.head())\n",
    "except Exception as e:\n",
    "    print(f\"✗ Error generating data: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Configure Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Configuration created successfully!\n",
      "\n",
      "Settings:\n",
      "  Dual Pipeline: True\n",
      "  Raw Imputation: median\n",
      "  Raw Outlier Method: iqr\n",
      "  Output: outputs_dual_example\n"
     ]
    }
   ],
   "source": [
    "# Create configuration\n",
    "try:\n",
    "    config = Config(\n",
    "        # Core columns\n",
    "        id_col='app_id',\n",
    "        time_col='app_dt',\n",
    "        target_col='target',\n",
    "        \n",
    "        # Enable DUAL PIPELINE\n",
    "        enable_dual_pipeline=True,\n",
    "        \n",
    "        # Raw pipeline settings\n",
    "        raw_imputation_strategy='median',\n",
    "        raw_outlier_method='iqr',\n",
    "        raw_outlier_threshold=1.5,\n",
    "        \n",
    "        # Data split\n",
    "        use_test_split=True,\n",
    "        test_size_row_frac=0.2,\n",
    "        oot_window_months=2,\n",
    "        \n",
    "        # Feature engineering\n",
    "        rare_threshold=0.01,\n",
    "        psi_threshold=0.30,\n",
    "        iv_min=0.01,\n",
    "        rho_threshold=0.95,\n",
    "        \n",
    "        # Model settings (reduced for speed)\n",
    "        cv_folds=3,\n",
    "        hpo_timeout_sec=30,\n",
    "        hpo_trials=5,\n",
    "        \n",
    "        # Output\n",
    "        output_folder='outputs_dual_example',\n",
    "        output_excel_path='dual_pipeline_results.xlsx',\n",
    "        \n",
    "        random_state=42\n",
    "    )\n",
    "    \n",
    "    print(\"✓ Configuration created successfully!\")\n",
    "    print(f\"\\nSettings:\")\n",
    "    print(f\"  Dual Pipeline: {config.enable_dual_pipeline}\")\n",
    "    print(f\"  Raw Imputation: {config.raw_imputation_strategy}\")\n",
    "    print(f\"  Raw Outlier Method: {config.raw_outlier_method}\")\n",
    "    print(f\"  Output: {config.output_folder}\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"✗ Error creating configuration: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Run Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Pipeline instance created\n",
      "\n",
      "============================================================\n",
      "STARTING DUAL PIPELINE EXECUTION\n",
      "============================================================\n",
      "\n",
      "[22:14:21] >> 2) Giris dogrulama & sabitleme basliyor | CPU=2% RAM=46%\n",
      "[22:14:21] â--  2) Giris dogrulama & sabitleme bitti (0.13s) â€” OK | CPU=12% RAM=46%\n",
      "[22:14:21] >> 3) Degisken siniflamasi basliyor | CPU=6% RAM=46%\n",
      "   - numeric=8, categorical=4\n",
      "[22:14:21] â--  3) Degisken siniflamasi bitti (0.11s) â€” OK | CPU=5% RAM=46%\n",
      "[22:14:21] >> 4) Eksik & Nadir deger politikasi basliyor | CPU=2% RAM=46%\n",
      "[22:14:21] â--  4) Eksik & Nadir deger politikasi bitti (0.11s) â€” OK | CPU=2% RAM=46%\n",
      "[22:14:22] >> 5) Zaman bolmesi (Train/Test/OOT) basliyor | CPU=0% RAM=46%\n",
      "   - Train=7008, Test=1752, OOT=1240\n",
      "[22:14:22] â--  5) Zaman bolmesi (Train/Test/OOT) bitti (0.79s) â€” OK | CPU=2% RAM=46%\n",
      "[22:14:22] >> 6) WOE binleme (yalniz Train; adaptif) basliyor | CPU=10% RAM=46%\n",
      "   - WOE hazir: 12 degisken\n",
      "   - Not: WOE haritasi SADECE TRAIN'de ogrenildi; TEST/OOT icin ayni harita uygulanir (leakage yok)\n",
      "[22:14:23] â--  6) WOE binleme (yalniz Train; adaptif) bitti (0.17s) â€” OK | CPU=2% RAM=46%\n",
      "[22:14:23] >> 7) PSI (vektorize) basliyor | CPU=1% RAM=46%\n",
      "   * PSI özet: KEEP=11 | DROP=1 | WARN=0\n",
      "   - PSI sonrasi kalan: 11\n",
      "[22:14:23] â--  7) PSI (vektorize) bitti (0.55s) â€” OK | CPU=3% RAM=46%\n",
      "   - High IV flags: payment_score,risk_score\n",
      "[22:14:23] >> 8) WOE transform (Train/Test/OOT) basliyor | CPU=1% RAM=46%\n",
      "   - X_train=(7008, 6), X_test=(1752, 6), X_oot=(1240, 6)\n",
      "[22:14:24] â--  8) WOE transform (Train/Test/OOT) bitti (0.14s) â€” OK | CPU=3% RAM=46%\n",
      "[22:14:24] >> 9) Korelasyon & cluster basliyor | CPU=2% RAM=46%\n",
      "   - cluster temsilcisi=6\n",
      "[22:14:24] â--  9) Korelasyon & cluster bitti (0.16s) â€” OK | CPU=4% RAM=46%\n",
      "[22:14:24] >> 10) Feature selection (Forward+1SE) basliyor | CPU=2% RAM=46%\n",
      "   - Boruta: 5/6 kaldi\n",
      "   - Minimum 5 değişken için eklendi\n",
      "   - Forward+1SE secti: 5\n",
      "   - baseline degisken=5\n",
      "[22:14:26] â--  10) Feature selection (Forward+1SE) bitti (2.33s) â€” OK | CPU=7% RAM=46%\n",
      "[22:14:26] >> 11) Nihai korelasyon filtresi basliyor | CPU=8% RAM=46%\n",
      "   - corr sonrasi=5\n",
      "[22:14:26] â--  11) Nihai korelasyon filtresi bitti (0.12s) â€” OK | CPU=7% RAM=46%\n",
      "[22:14:27] >> 12) Gurultu (noise) sentineli basliyor | CPU=6% RAM=46%\n",
      "   - final degisken=3\n",
      "[22:14:28] â--  12) Gurultu (noise) sentineli bitti (1.25s) â€” OK | CPU=1% RAM=46%\n",
      "[22:14:28] >> 13) Modelleme & degerlendirme (WOE) basliyor | CPU=1% RAM=46%\n",
      "[22:14:28]   - Logit_L2 tuning | CPU=1% RAM=46%\n",
      "[22:14:28]   - Logit_L2 CV basliyor | CPU=3% RAM=46%\n",
      "[22:14:29]   - RandomForest tuning | CPU=3% RAM=46%\n",
      "[22:14:52]   - RandomForest CV basliyor | CPU=1% RAM=45%\n",
      "[22:14:57]   - ExtraTrees tuning | CPU=3% RAM=45%\n",
      "[22:15:12]   - ExtraTrees CV basliyor | CPU=2% RAM=45%\n",
      "[22:15:14]   - XGBoost tuning | CPU=3% RAM=46%\n",
      "[22:15:19]   - XGBoost CV basliyor | CPU=31% RAM=46%\n",
      "[22:15:20]   - LightGBM tuning | CPU=37% RAM=46%\n",
      "[22:15:33]   - LightGBM CV basliyor | CPU=37% RAM=46%\n",
      "[22:15:35]   - GAM tuning | CPU=25% RAM=46%\n",
      "[22:15:38]   - GAM CV basliyor | CPU=6% RAM=46%\n",
      "[22:15:39] â--  13) Modelleme & degerlendirme (WOE) bitti (70.82s) â€” OK | CPU=5% RAM=46%\n",
      "\n",
      "================================================================================\n",
      "DUAL PIPELINE: RAW VARIABLES (Ham Degiskenler)\n",
      "================================================================================\n",
      "[22:15:39] >> 8b) Raw transform (Train/Test/OOT) basliyor | CPU=0% RAM=46%\n",
      "   - X_train_raw=(7008, 6), X_test_raw=(1752, 6), X_oot_raw=(1240, 6)\n",
      "[22:15:39] â--  8b) Raw transform (Train/Test/OOT) bitti (0.14s) â€” OK | CPU=3% RAM=46%\n",
      "[22:15:39] >> 10b) Feature selection RAW (Forward+1SE) basliyor | CPU=0% RAM=46%\n",
      "   - Boruta: 5/6 kaldi\n",
      "   - Minimum 5 değişken için eklendi\n",
      "   - Forward+1SE secti: 5\n",
      "   - raw baseline degisken=5\n",
      "[22:15:43] â--  10b) Feature selection RAW (Forward+1SE) bitti (3.46s) â€” OK | CPU=2% RAM=46%\n",
      "[22:15:43] >> 11b) Nihai korelasyon filtresi RAW basliyor | CPU=1% RAM=46%\n",
      "   - raw corr sonrasi=5\n",
      "[22:15:43] â--  11b) Nihai korelasyon filtresi RAW bitti (0.12s) â€” OK | CPU=1% RAM=46%\n",
      "[22:15:43] >> 12b) Gurultu sentineli RAW basliyor | CPU=2% RAM=46%\n",
      "   - raw final degisken=2\n",
      "[22:15:44] â--  12b) Gurultu sentineli RAW bitti (1.15s) â€” OK | CPU=2% RAM=46%\n",
      "[22:15:44] >> 13b) Modelleme & degerlendirme (RAW) basliyor | CPU=2% RAM=46%\n",
      "[22:15:44]   - Logit_L2 tuning | CPU=2% RAM=46%\n",
      "[22:15:45]   - Logit_L2 CV basliyor | CPU=3% RAM=46%\n",
      "[22:15:45]   - RandomForest tuning | CPU=5% RAM=46%\n",
      "[22:16:17]   - RandomForest CV basliyor | CPU=1% RAM=46%\n",
      "[22:16:23]   - ExtraTrees tuning | CPU=1% RAM=46%\n",
      "[22:16:37]   - ExtraTrees CV basliyor | CPU=3% RAM=46%\n",
      "[22:16:41]   - XGBoost tuning | CPU=3% RAM=46%\n",
      "[22:16:46]   - XGBoost CV basliyor | CPU=45% RAM=46%\n",
      "[22:16:47]   - LightGBM tuning | CPU=38% RAM=46%\n",
      "[22:16:57]   - LightGBM CV basliyor | CPU=53% RAM=46%\n",
      "[22:16:59]   - GAM tuning | CPU=32% RAM=46%\n",
      "[22:17:01]   - GAM CV basliyor | CPU=0% RAM=46%\n",
      "[22:17:01] â--  13b) Modelleme & degerlendirme (RAW) bitti (77.20s) â€” OK | CPU=1% RAM=46%\n",
      "\n",
      "================================================================================\n",
      "DUAL PIPELINE SUMMARY\n",
      "================================================================================\n",
      "WOE Pipeline: 3 variables, 6 models\n",
      "RAW Pipeline: 2 variables, 6 models\n",
      "Best WOE Model: GAM - Gini OOT: 0.7655\n",
      "Best RAW Model: Logit_L2 - Gini OOT: 0.6926\n",
      "[22:17:02] >> 14) En iyi model secimi basliyor | CPU=2% RAM=46%\n",
      "   - best=WOE_GAM\n",
      "[22:17:02] â--  14) En iyi model secimi bitti (0.12s) â€” OK | CPU=0% RAM=46%\n",
      "[22:17:02] >> 15) Rapor tablolari basliyor | CPU=1% RAM=46%\n",
      "[22:17:02] â--  15) Rapor tablolari bitti (0.14s) â€” FAIL: X data must have 3 features, but found 2 | CPU=2% RAM=46%\n",
      "\n",
      "✗ Pipeline error: X data must have 3 features, but found 2\n",
      "\n",
      "Possible solutions:\n",
      "  1. Check if all required packages are installed\n",
      "  2. Verify numpy/pandas compatibility\n",
      "  3. Run: pip install -r ../requirements_fixed.txt\n"
     ]
    }
   ],
   "source": [
    "# Run pipeline with error handling\n",
    "try:\n",
    "    # Create pipeline instance\n",
    "    pipeline = RiskModelPipeline(config)\n",
    "    print(\"✓ Pipeline instance created\")\n",
    "    \n",
    "    # Run pipeline\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"STARTING DUAL PIPELINE EXECUTION\")\n",
    "    print(\"=\"*60 + \"\\n\")\n",
    "    \n",
    "    start_time = time.time()\n",
    "    pipeline.run(df)\n",
    "    elapsed = time.time() - start_time\n",
    "    \n",
    "    print(f\"\\n✓ Pipeline completed in {elapsed:.2f} seconds\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"\\n✗ Pipeline error: {e}\")\n",
    "    print(\"\\nPossible solutions:\")\n",
    "    print(\"  1. Check if all required packages are installed\")\n",
    "    print(\"  2. Verify numpy/pandas compatibility\")\n",
    "    print(\"  3. Run: pip install -r ../requirements_fixed.txt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Review Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "MODEL PERFORMANCE SUMMARY\n",
      "============================================================\n",
      "\n",
      "Top 5 Models by Gini_OOT:\n",
      "         model_name  Gini_OOT\n",
      "0           WOE_GAM  0.765516\n",
      "1      WOE_Logit_L2  0.764973\n",
      "2  WOE_RandomForest  0.759740\n",
      "4      WOE_LightGBM  0.758458\n",
      "3       WOE_XGBoost  0.757852\n",
      "\n",
      "============================================================\n",
      "PIPELINE COMPARISON\n",
      "============================================================\n",
      "\n",
      "WOE Pipeline:\n",
      "  Models: 6\n",
      "  Best Gini_OOT: 0.7655\n",
      "  Mean Gini_OOT: 0.7599\n",
      "\n",
      "RAW Pipeline:\n",
      "  Models: 6\n",
      "  Best Gini_OOT: 0.6926\n",
      "  Mean Gini_OOT: 0.6880\n"
     ]
    }
   ],
   "source": [
    "# Review results with error handling\n",
    "try:\n",
    "    if hasattr(pipeline, 'models_summary_') and pipeline.models_summary_ is not None:\n",
    "        print(\"=\"*60)\n",
    "        print(\"MODEL PERFORMANCE SUMMARY\")\n",
    "        print(\"=\"*60)\n",
    "        \n",
    "        summary = pipeline.models_summary_\n",
    "        \n",
    "        # Check for Gini column\n",
    "        gini_col = None\n",
    "        for col in ['Gini_OOT', 'gini_oot', 'Gini_Test', 'gini_test']:\n",
    "            if col in summary.columns:\n",
    "                gini_col = col\n",
    "                break\n",
    "        \n",
    "        if gini_col:\n",
    "            print(f\"\\nTop 5 Models by {gini_col}:\")\n",
    "            top_models = summary.nlargest(5, gini_col)\n",
    "            print(top_models[['model_name', gini_col]].to_string())\n",
    "        else:\n",
    "            print(\"\\nModel Summary:\")\n",
    "            print(summary.head().to_string())\n",
    "        \n",
    "        # Check for pipeline comparison\n",
    "        if 'pipeline' in summary.columns:\n",
    "            print(\"\\n\" + \"=\"*60)\n",
    "            print(\"PIPELINE COMPARISON\")\n",
    "            print(\"=\"*60)\n",
    "            \n",
    "            for pipeline_type in ['WOE', 'RAW']:\n",
    "                pipeline_models = summary[summary['pipeline'] == pipeline_type]\n",
    "                if not pipeline_models.empty:\n",
    "                    print(f\"\\n{pipeline_type} Pipeline:\")\n",
    "                    print(f\"  Models: {len(pipeline_models)}\")\n",
    "                    if gini_col and gini_col in pipeline_models.columns:\n",
    "                        print(f\"  Best {gini_col}: {pipeline_models[gini_col].max():.4f}\")\n",
    "                        print(f\"  Mean {gini_col}: {pipeline_models[gini_col].mean():.4f}\")\n",
    "    else:\n",
    "        print(\"No model summary available.\")\n",
    "        \n",
    "except Exception as e:\n",
    "    print(f\"Error reviewing results: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Export Reports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export reports\n",
    "try:\n",
    "    pipeline.export_reports()\n",
    "    print(\"✓ Reports exported successfully!\")\n",
    "    \n",
    "    # List generated files\n",
    "    import os\n",
    "    if os.path.exists(config.output_folder):\n",
    "        files = os.listdir(config.output_folder)\n",
    "        print(f\"\\nGenerated {len(files)} files in '{config.output_folder}':\")\n",
    "        for f in sorted(files)[:10]:\n",
    "            size = os.path.getsize(os.path.join(config.output_folder, f)) / 1024\n",
    "            print(f\"  - {f} ({size:.1f} KB)\")\n",
    "        if len(files) > 10:\n",
    "            print(f\"  ... and {len(files)-10} more files\")\n",
    "            \n",
    "except Exception as e:\n",
    "    print(f\"Error exporting reports: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Troubleshooting\n",
    "\n",
    "If you encounter any errors:\n",
    "\n",
    "1. **numpy.dtype size changed error**:\n",
    "   ```bash\n",
    "   pip install -r ../requirements_fixed.txt\n",
    "   ```\n",
    "\n",
    "2. **Import errors**:\n",
    "   ```bash\n",
    "   cd ..\n",
    "   pip install -e .\n",
    "   ```\n",
    "\n",
    "3. **Memory issues**:\n",
    "   - Reduce n_samples in create_sample_data()\n",
    "   - Reduce hpo_trials in config\n",
    "\n",
    "4. **Create fresh environment**:\n",
    "   ```bash\n",
    "   python -m venv fresh_env\n",
    "   fresh_env\\Scripts\\activate  # Windows\n",
    "   pip install -r requirements_fixed.txt\n",
    "   ```"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
