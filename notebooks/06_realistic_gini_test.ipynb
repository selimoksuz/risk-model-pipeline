{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Risk Model Pipeline - GerÃ§ekÃ§i Gini Testi (%70-80)\n",
    "\n",
    "Bu notebook:\n",
    "- GerÃ§ekÃ§i %70-80 Gini aralÄ±ÄŸÄ±nda sentetik veri oluÅŸturur\n",
    "- Pipeline'Ä±n tÃ¼m adÄ±mlarÄ±nÄ± test eder\n",
    "- Filtreleme mekanizmalarÄ±nÄ±n Ã§alÄ±ÅŸtÄ±ÄŸÄ±nÄ± gÃ¶sterir"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup ve Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pygam\n",
      "  Using cached pygam-0.10.1-py3-none-any.whl (80 kB)\n",
      "Requirement already satisfied: numpy>=1.5.0 in c:\\users\\acer\\anaconda3\\lib\\site-packages (from pygam) (1.21.5)\n",
      "Collecting progressbar2<5,>=4.2.0\n",
      "  Using cached progressbar2-4.5.0-py3-none-any.whl (57 kB)\n",
      "Collecting scipy<1.17,>=1.11.1\n",
      "  Downloading scipy-1.13.1-cp39-cp39-win_amd64.whl (46.2 MB)\n",
      "     --------------------------------------- 46.2/46.2 MB 12.3 MB/s eta 0:00:00\n",
      "Collecting python-utils>=3.8.1\n",
      "  Using cached python_utils-3.9.1-py2.py3-none-any.whl (32 kB)\n",
      "Collecting numpy>=1.5.0\n",
      "  Downloading numpy-2.0.2-cp39-cp39-win_amd64.whl (15.9 MB)\n",
      "     --------------------------------------- 15.9/15.9 MB 13.4 MB/s eta 0:00:00\n",
      "Requirement already satisfied: typing_extensions>3.10.0.2 in c:\\users\\acer\\anaconda3\\lib\\site-packages (from python-utils>=3.8.1->progressbar2<5,>=4.2.0->pygam) (4.14.1)\n",
      "Installing collected packages: python-utils, numpy, scipy, progressbar2, pygam\n",
      "  Attempting uninstall: numpy\n",
      "    Found existing installation: numpy 1.21.5\n",
      "    Uninstalling numpy-1.21.5:\n",
      "      Successfully uninstalled numpy-1.21.5\n",
      "  Attempting uninstall: scipy\n",
      "    Found existing installation: scipy 1.9.1\n",
      "    Uninstalling scipy-1.9.1:\n",
      "      Successfully uninstalled scipy-1.9.1\n",
      "Successfully installed numpy-2.0.2 progressbar2-4.5.0 pygam-0.10.1 python-utils-3.9.1 scipy-1.13.1\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "daal4py 2021.6.0 requires daal==2021.4.0, which is not installed.\n",
      "numba 0.55.1 requires numpy<1.22,>=1.18, but you have numpy 2.0.2 which is incompatible.\n"
     ]
    }
   ],
   "source": [
    "pip install pygam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Setup complete!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "import sys\n",
    "import os\n",
    "from datetime import datetime\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Add parent directory to path\n",
    "sys.path.append('..')\n",
    "from src.risk_pipeline.pipeline16 import RiskModelPipeline, Config\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "np.random.seed(2024)\n",
    "\n",
    "print(\"âœ… Setup complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "# Pipeline konfigÃ¼rasyonu\nprint(\"âš™ï¸ Pipeline konfigÃ¼rasyonu...\")\n\ncfg = Config(\n    # Temel ayarlar\n    id_col='app_id',\n    time_col='app_dt',\n    target_col='target',\n    \n    # Veri bÃ¶lme\n    use_test_split=True,\n    test_size_row_frac=0.2,\n    oot_window_months=4,  # Son 4 ay OOT\n    \n    # Veri sÃ¶zlÃ¼ÄŸÃ¼ ve kalibrasyon\n    data_dictionary_df=data_dict,\n    calibration_df=cal_df,\n    calibration_method='isotonic',\n    \n    # Model ayarlarÄ±\n    cv_folds=5,\n    random_state=2024,\n    n_jobs=2,\n    \n    # HPO ayarlarÄ± (hÄ±zlÄ± demo iÃ§in)\n    hpo_timeout_sec=20,\n    hpo_trials=10,\n    \n    # Feature engineering eÅŸikleri (DAHA AZ AGRESÄ°F)\n    rare_threshold=0.005,     # %0.5'ten az (sadece Ã§ok nadir kategoriler)\n    psi_threshold=0.30,       # PSI > 0.30 (daha toleranslÄ±)\n    iv_min=0.01,             # IV < 0.01 (sadece Ã§ok dÃ¼ÅŸÃ¼k IV elenecek)\n    rho_threshold=0.98,      # Korelasyon > 0.98 (neredeyse aynÄ± deÄŸiÅŸkenler)\n    \n    # Ã‡Ä±ktÄ±lar\n    output_folder='outputs_realistic_gini',\n    output_excel_path='realistic_gini_report.xlsx',\n    log_file='outputs_realistic_gini/pipeline.log',\n    write_parquet=False,\n    write_csv=False\n)\n\nprint(\"âœ… KonfigÃ¼rasyon hazÄ±r!\")\nprint(f\"\\nðŸ“‹ Filtreleme EÅŸikleri (DAHA AZ AGRESÄ°F):\")\nprint(f\"   PSI eÅŸiÄŸi: {cfg.psi_threshold} (Ã¶nceki: 0.20)\")\nprint(f\"   IV minimum: {cfg.iv_min} (Ã¶nceki: 0.02)\")\nprint(f\"   Korelasyon eÅŸiÄŸi: {cfg.rho_threshold} (Ã¶nceki: 0.95)\")\nprint(f\"   Nadir kategori eÅŸiÄŸi: %{cfg.rare_threshold*100} (Ã¶nceki: %1)\")"
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ“Š GerÃ§ekÃ§i sentetik veri oluÅŸturuluyor...\n",
      "âœ… Veri oluÅŸturuldu: (5000, 19)\n",
      "   Target oranÄ±: 50.0%\n",
      "   DeÄŸiÅŸken sayÄ±sÄ±: 16\n"
     ]
    }
   ],
   "source": [
    "def create_realistic_credit_data(n_samples=5000):\n",
    "    \"\"\"\n",
    "    GerÃ§ekÃ§i kredi riski verisi - %70-80 Gini hedefli\n",
    "    \n",
    "    Ã–zellikler:\n",
    "    - GÃ¼Ã§lÃ¼ tahmin ediciler (risk_score, payment_score, vb.)\n",
    "    - Korele deÄŸiÅŸkenler (korelasyon testi iÃ§in)\n",
    "    - Drift eden deÄŸiÅŸkenler (PSI testi iÃ§in)\n",
    "    - DÃ¼ÅŸÃ¼k bilgi deÄŸerli deÄŸiÅŸkenler (IV testi iÃ§in)\n",
    "    - Nadir kategoriler (rare threshold testi iÃ§in)\n",
    "    \"\"\"\n",
    "    \n",
    "    # 1. GÃœÃ‡LÃœ TAHMÄ°N EDÄ°CÄ°LER (YÃ¼ksek IV)\n",
    "    risk_score = np.random.beta(2, 5, n_samples)  # Ana risk skoru\n",
    "    payment_score = np.random.beta(3, 7, n_samples)  # Ã–deme geÃ§miÅŸi\n",
    "    debt_burden = np.random.beta(2, 8, n_samples)  # BorÃ§ yÃ¼kÃ¼\n",
    "    income_stability = np.random.beta(4, 6, n_samples)  # Gelir istikrarÄ±\n",
    "    employment_score = np.random.beta(5, 5, n_samples)  # Ä°stihdam skoru\n",
    "    \n",
    "    # 2. KORELE DEÄžÄ°ÅžKENLER (Korelasyon testi iÃ§in)\n",
    "    # risk_score ile yÃ¼ksek korele (>0.95)\n",
    "    risk_score_v2 = risk_score + np.random.normal(0, 0.05, n_samples)\n",
    "    risk_score_v2 = np.clip(risk_score_v2, 0, 1)\n",
    "    \n",
    "    # payment_score ile korele (>0.90)\n",
    "    payment_behavior = payment_score * 0.9 + np.random.normal(0, 0.05, n_samples)\n",
    "    payment_behavior = np.clip(payment_behavior, 0, 1)\n",
    "    \n",
    "    # 3. DRIFT EDEN DEÄžÄ°ÅžKEN (PSI testi iÃ§in)\n",
    "    time_index = np.arange(n_samples) / n_samples\n",
    "    drift_feature = np.random.normal(0.3 + 0.4 * time_index, 0.1, n_samples)\n",
    "    \n",
    "    # 4. STABIL DEÄžÄ°ÅžKEN (PSI geÃ§ecek)\n",
    "    stable_feature = np.random.normal(0.5, 0.15, n_samples)\n",
    "    \n",
    "    # 5. DÃœÅžÃœK BÄ°LGÄ° DEÄžERLÄ° DEÄžÄ°ÅžKENLER (IV < 0.02, elenecek)\n",
    "    noise_feature1 = np.random.randn(n_samples)\n",
    "    noise_feature2 = np.random.uniform(0, 1, n_samples)\n",
    "    \n",
    "    # 6. KATEGORÄ°K DEÄžÄ°ÅžKENLER\n",
    "    # GÃ¼Ã§lÃ¼ kategorik (risk_score ile iliÅŸkili)\n",
    "    risk_category = pd.cut(risk_score, bins=4, \n",
    "                           labels=['Very_Low', 'Low', 'Medium', 'High'])\n",
    "    \n",
    "    # Nadir kategoriler iÃ§eren (rare threshold testi iÃ§in)\n",
    "    product_type = np.random.choice(\n",
    "        ['Standard', 'Premium', 'Basic', 'Rare1', 'Rare2'], \n",
    "        n_samples,\n",
    "        p=[0.4, 0.3, 0.28, 0.015, 0.005]  # Rare1 ve Rare2 %1'den az\n",
    "    )\n",
    "    \n",
    "    region = np.random.choice(['North', 'South', 'East', 'West'], \n",
    "                              n_samples, p=[0.25, 0.25, 0.25, 0.25])\n",
    "    \n",
    "    # 7. TARGET OLUÅžTURMA (GerÃ§ekÃ§i %70-80 Gini iÃ§in)\n",
    "    default_score = (\n",
    "        3.5 * risk_score +           # En gÃ¼Ã§lÃ¼ tahmin edici\n",
    "        3.0 * payment_score +         # Ä°kinci gÃ¼Ã§lÃ¼\n",
    "        2.0 * debt_burden +           # Orta gÃ¼Ã§lÃ¼\n",
    "        1.2 * (1 - income_stability) + # Orta etki\n",
    "        1.0 * (1 - employment_score) + # Orta etki\n",
    "        np.random.normal(0, 0.6, n_samples)  # Optimal gÃ¼rÃ¼ltÃ¼\n",
    "    )\n",
    "    \n",
    "    # Target (threshold ile binary)\n",
    "    threshold = np.percentile(default_score, 50)  # %50 default rate\n",
    "    target = (default_score > threshold).astype(int)\n",
    "    \n",
    "    # 8. DEMOGRAFÄ°K Ã–ZELLÄ°KLER\n",
    "    age = np.random.normal(40, 12, n_samples).clip(18, 70)\n",
    "    tenure = np.random.exponential(5, n_samples).clip(0, 30)\n",
    "    \n",
    "    # DataFrame oluÅŸtur\n",
    "    df = pd.DataFrame({\n",
    "        'app_id': [f'APP_{i:08d}' for i in range(n_samples)],\n",
    "        'app_dt': pd.date_range('2022-01-01', periods=n_samples, freq='6H'),\n",
    "        'target': target,\n",
    "        \n",
    "        # GÃ¼Ã§lÃ¼ tahmin ediciler\n",
    "        'risk_score': risk_score,\n",
    "        'payment_score': payment_score,\n",
    "        'debt_burden': debt_burden,\n",
    "        'income_stability': income_stability,\n",
    "        'employment_score': employment_score,\n",
    "        \n",
    "        # Korele deÄŸiÅŸkenler\n",
    "        'risk_score_v2': risk_score_v2,\n",
    "        'payment_behavior': payment_behavior,\n",
    "        \n",
    "        # PSI test deÄŸiÅŸkenleri\n",
    "        'drift_feature': drift_feature,\n",
    "        'stable_feature': stable_feature,\n",
    "        \n",
    "        # DÃ¼ÅŸÃ¼k IV deÄŸiÅŸkenler\n",
    "        'noise_feature1': noise_feature1,\n",
    "        'noise_feature2': noise_feature2,\n",
    "        \n",
    "        # Kategorik deÄŸiÅŸkenler\n",
    "        'risk_category': risk_category,\n",
    "        'product_type': product_type,\n",
    "        'region': region,\n",
    "        \n",
    "        # Demografik\n",
    "        'age': age,\n",
    "        'tenure': tenure\n",
    "    })\n",
    "    \n",
    "    # Eksik deÄŸerler ekle (gerÃ§ekÃ§ilik iÃ§in, %2-3)\n",
    "    missing_cols = ['employment_score', 'tenure']\n",
    "    for col in missing_cols:\n",
    "        missing_idx = np.random.choice(df.index, size=int(0.02 * len(df)), replace=False)\n",
    "        df.loc[missing_idx, col] = np.nan\n",
    "    \n",
    "    return df\n",
    "\n",
    "# Veri oluÅŸtur\n",
    "print(\"ðŸ“Š GerÃ§ekÃ§i sentetik veri oluÅŸturuluyor...\")\n",
    "df = create_realistic_credit_data(5000)\n",
    "print(f\"âœ… Veri oluÅŸturuldu: {df.shape}\")\n",
    "print(f\"   Target oranÄ±: {df['target'].mean():.1%}\")\n",
    "print(f\"   DeÄŸiÅŸken sayÄ±sÄ±: {df.shape[1] - 3}\")  # id, date, target hariÃ§"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Baseline Performans Testi (Logistic Regression)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ”¬ Baseline Logistic Regression ile Gini testi...\n",
      "\n",
      "ðŸ“Š BASELINE PERFORMANS:\n",
      "   AUC: 0.876\n",
      "   GINI: 0.752 (75.2%)\n",
      "\n",
      "âœ… MÃœKEMMEL: Gini hedef aralÄ±kta (%70-80)\n",
      "\n",
      "ðŸ“Š DeÄŸiÅŸken Ã–nemleri (Logistic Regression Coefficients):\n",
      "         feature  coefficient\n",
      "      risk_score     8.663711\n",
      "   payment_score     7.743205\n",
      "     debt_burden     4.594925\n",
      "employment_score    -2.212899\n",
      "income_stability    -2.909652\n"
     ]
    }
   ],
   "source": [
    "# Baseline performans testi\n",
    "print(\"ðŸ”¬ Baseline Logistic Regression ile Gini testi...\")\n",
    "\n",
    "# GÃ¼Ã§lÃ¼ deÄŸiÅŸkenlerle model\n",
    "strong_features = ['risk_score', 'payment_score', 'debt_burden', \n",
    "                  'income_stability', 'employment_score']\n",
    "\n",
    "# Train/test split\n",
    "X = df[strong_features].fillna(df[strong_features].median())\n",
    "y = df['target']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.3, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "# Logistic Regression\n",
    "lr = LogisticRegression(random_state=42, max_iter=1000)\n",
    "lr.fit(X_train, y_train)\n",
    "\n",
    "# Predictions\n",
    "y_pred_proba = lr.predict_proba(X_test)[:, 1]\n",
    "\n",
    "# Performance\n",
    "auc = roc_auc_score(y_test, y_pred_proba)\n",
    "gini = 2 * auc - 1\n",
    "\n",
    "print(f\"\\nðŸ“Š BASELINE PERFORMANS:\")\n",
    "print(f\"   AUC: {auc:.3f}\")\n",
    "print(f\"   GINI: {gini:.3f} ({gini*100:.1f}%)\")\n",
    "\n",
    "if 0.70 <= gini <= 0.80:\n",
    "    print(f\"\\nâœ… MÃœKEMMEL: Gini hedef aralÄ±kta (%70-80)\")\n",
    "elif gini >= 0.70:\n",
    "    print(f\"\\nâœ… Ä°YÄ°: Gini %70+ ({gini*100:.1f}%)\")\n",
    "else:\n",
    "    print(f\"\\nâš ï¸ Gini hedefin altÄ±nda: {gini*100:.1f}%\")\n",
    "\n",
    "# Feature importance\n",
    "print(\"\\nðŸ“Š DeÄŸiÅŸken Ã–nemleri (Logistic Regression Coefficients):\")\n",
    "feature_importance = pd.DataFrame({\n",
    "    'feature': strong_features,\n",
    "    'coefficient': lr.coef_[0]\n",
    "}).sort_values('coefficient', ascending=False)\n",
    "print(feature_importance.to_string(index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Kalibrasyon Verisi ve Veri SÃ¶zlÃ¼ÄŸÃ¼"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ“Š Kalibrasyon verisi hazÄ±rlanÄ±yor...\n",
      "   Kalibrasyon boyutu: (1000, 19)\n",
      "   Kalibrasyon target oranÄ±: 50.0%\n",
      "\n",
      "ðŸ“š Veri sÃ¶zlÃ¼ÄŸÃ¼ hazÄ±rlanÄ±yor...\n",
      "   TanÄ±mlanan deÄŸiÅŸken: 16\n",
      "\n",
      "ðŸ“‹ Veri SÃ¶zlÃ¼ÄŸÃ¼:\n",
      "        alan_adi                           alan_aciklamasi\n",
      "      risk_score       Ana risk skoru (0-1, yÃ¼ksek=riskli)\n",
      "   payment_score     Ã–deme geÃ§miÅŸi skoru (0-1, yÃ¼ksek=iyi)\n",
      "     debt_burden BorÃ§ yÃ¼kÃ¼ gÃ¶stergesi (0-1, yÃ¼ksek=borÃ§lu)\n",
      "income_stability  Gelir istikrarÄ± (0-1, yÃ¼ksek=istikrarlÄ±)\n",
      "employment_score      Ä°stihdam skoru (0-1, yÃ¼ksek=gÃ¼venli)\n"
     ]
    }
   ],
   "source": [
    "# Kalibrasyon verisi\n",
    "print(\"ðŸ“Š Kalibrasyon verisi hazÄ±rlanÄ±yor...\")\n",
    "cal_df = create_realistic_credit_data(1000)\n",
    "print(f\"   Kalibrasyon boyutu: {cal_df.shape}\")\n",
    "print(f\"   Kalibrasyon target oranÄ±: {cal_df['target'].mean():.1%}\")\n",
    "\n",
    "# Veri sÃ¶zlÃ¼ÄŸÃ¼\n",
    "print(\"\\nðŸ“š Veri sÃ¶zlÃ¼ÄŸÃ¼ hazÄ±rlanÄ±yor...\")\n",
    "data_dict = pd.DataFrame({\n",
    "    'alan_adi': [\n",
    "        'risk_score', 'payment_score', 'debt_burden', 'income_stability', \n",
    "        'employment_score', 'risk_score_v2', 'payment_behavior',\n",
    "        'drift_feature', 'stable_feature', 'noise_feature1', 'noise_feature2',\n",
    "        'risk_category', 'product_type', 'region', 'age', 'tenure'\n",
    "    ],\n",
    "    'alan_aciklamasi': [\n",
    "        'Ana risk skoru (0-1, yÃ¼ksek=riskli)',\n",
    "        'Ã–deme geÃ§miÅŸi skoru (0-1, yÃ¼ksek=iyi)',\n",
    "        'BorÃ§ yÃ¼kÃ¼ gÃ¶stergesi (0-1, yÃ¼ksek=borÃ§lu)',\n",
    "        'Gelir istikrarÄ± (0-1, yÃ¼ksek=istikrarlÄ±)',\n",
    "        'Ä°stihdam skoru (0-1, yÃ¼ksek=gÃ¼venli)',\n",
    "        'Risk skoru v2 (risk_score ile korele, elenecek)',\n",
    "        'Ã–deme davranÄ±ÅŸÄ± (payment_score ile korele)',\n",
    "        'Zamanla deÄŸiÅŸen Ã¶zellik (PSI ile elenecek)',\n",
    "        'Sabit Ã¶zellik (PSI testini geÃ§ecek)',\n",
    "        'GÃ¼rÃ¼ltÃ¼ deÄŸiÅŸkeni 1 (dÃ¼ÅŸÃ¼k IV, elenecek)',\n",
    "        'GÃ¼rÃ¼ltÃ¼ deÄŸiÅŸkeni 2 (dÃ¼ÅŸÃ¼k IV, elenecek)',\n",
    "        'Risk kategorisi (risk_score ile tÃ¼retilmiÅŸ)',\n",
    "        'ÃœrÃ¼n tipi (nadir kategoriler iÃ§erir)',\n",
    "        'BÃ¶lge',\n",
    "        'MÃ¼ÅŸteri yaÅŸÄ±',\n",
    "        'MÃ¼ÅŸteri kÄ±demi (yÄ±l)'\n",
    "    ]\n",
    "})\n",
    "print(f\"   TanÄ±mlanan deÄŸiÅŸken: {len(data_dict)}\")\n",
    "print(\"\\nðŸ“‹ Veri SÃ¶zlÃ¼ÄŸÃ¼:\")\n",
    "print(data_dict.head(5).to_string(index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Pipeline KonfigÃ¼rasyonu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš™ï¸ Pipeline konfigÃ¼rasyonu...\n",
      "âœ… KonfigÃ¼rasyon hazÄ±r!\n",
      "\n",
      "ðŸ“‹ Filtreleme EÅŸikleri:\n",
      "   PSI eÅŸiÄŸi: 0.2\n",
      "   IV minimum: 0.02\n",
      "   Korelasyon eÅŸiÄŸi: 0.95\n",
      "   Nadir kategori eÅŸiÄŸi: %1.0\n"
     ]
    }
   ],
   "source": [
    "# Pipeline konfigÃ¼rasyonu\n",
    "print(\"âš™ï¸ Pipeline konfigÃ¼rasyonu...\")\n",
    "\n",
    "cfg = Config(\n",
    "    # Temel ayarlar\n",
    "    id_col='app_id',\n",
    "    time_col='app_dt',\n",
    "    target_col='target',\n",
    "    \n",
    "    # Veri bÃ¶lme\n",
    "    use_test_split=True,\n",
    "    test_size_row_frac=0.2,\n",
    "    oot_window_months=4,  # Son 4 ay OOT\n",
    "    \n",
    "    # Veri sÃ¶zlÃ¼ÄŸÃ¼ ve kalibrasyon\n",
    "    data_dictionary_df=data_dict,\n",
    "    calibration_df=cal_df,\n",
    "    calibration_method='isotonic',\n",
    "    \n",
    "    # Model ayarlarÄ±\n",
    "    cv_folds=5,\n",
    "    random_state=2024,\n",
    "    n_jobs=2,\n",
    "    \n",
    "    # HPO ayarlarÄ± (hÄ±zlÄ± demo iÃ§in)\n",
    "    hpo_timeout_sec=20,\n",
    "    hpo_trials=10,\n",
    "    \n",
    "    # Feature engineering eÅŸikleri\n",
    "    rare_threshold=0.01,      # %1'den az (Rare1, Rare2 elenecek)\n",
    "    psi_threshold=0.20,       # PSI > 0.20 (drift_feature elenecek)\n",
    "    iv_min=0.02,             # IV < 0.02 (noise deÄŸiÅŸkenler elenecek)\n",
    "    rho_threshold=0.95,      # Korelasyon > 0.95 (risk_score_v2 elenecek)\n",
    "    \n",
    "    # Ã‡Ä±ktÄ±lar\n",
    "    output_folder='outputs_realistic_gini',\n",
    "    output_excel_path='realistic_gini_report.xlsx',\n",
    "    log_file='outputs_realistic_gini/pipeline.log',\n",
    "    write_parquet=False,\n",
    "    write_csv=False\n",
    ")\n",
    "\n",
    "print(\"âœ… KonfigÃ¼rasyon hazÄ±r!\")\n",
    "print(f\"\\nðŸ“‹ Filtreleme EÅŸikleri:\")\n",
    "print(f\"   PSI eÅŸiÄŸi: {cfg.psi_threshold}\")\n",
    "print(f\"   IV minimum: {cfg.iv_min}\")\n",
    "print(f\"   Korelasyon eÅŸiÄŸi: {cfg.rho_threshold}\")\n",
    "print(f\"   Nadir kategori eÅŸiÄŸi: %{cfg.rare_threshold*100}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Pipeline Ã‡alÄ±ÅŸtÄ±rma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "ðŸš€ PIPELINE Ã‡ALIÅžTIRILIYOR...\n",
      "============================================================\n",
      "[20:35:51] >> 2) Giris dogrulama & sabitleme basliyor | CPU=6% RAM=44%\n",
      "[20:35:51] Ã¢--Â  2) Giris dogrulama & sabitleme bitti (0.13s) Ã¢â‚¬â€ OK | CPU=2% RAM=44%\n",
      "[20:35:51] >> 3) Degisken siniflamasi basliyor | CPU=1% RAM=44%\n",
      "   - numeric=13, categorical=4\n",
      "[20:35:51] Ã¢--Â  3) Degisken siniflamasi bitti (0.11s) Ã¢â‚¬â€ OK | CPU=5% RAM=44%\n",
      "[20:35:51] >> 4) Eksik & Nadir deger politikasi basliyor | CPU=1% RAM=44%\n",
      "[20:35:51] Ã¢--Â  4) Eksik & Nadir deger politikasi bitti (0.11s) Ã¢â‚¬â€ OK | CPU=1% RAM=44%\n",
      "[20:35:51] >> 5) Zaman bolmesi (Train/Test/OOT) basliyor | CPU=0% RAM=44%\n",
      "   - Train=3696, Test=924, OOT=380\n",
      "[20:35:52] Ã¢--Â  5) Zaman bolmesi (Train/Test/OOT) bitti (0.54s) Ã¢â‚¬â€ OK | CPU=1% RAM=44%\n",
      "[20:35:52] >> 6) WOE binleme (yalniz Train; adaptif) basliyor | CPU=4% RAM=44%\n",
      "   - WOE hazir: 17 degisken\n",
      "   - Not: WOE haritasi SADECE TRAIN'de ogrenildi; TEST/OOT icin ayni harita uygulanir (leakage yok)\n",
      "[20:35:52] Ã¢--Â  6) WOE binleme (yalniz Train; adaptif) bitti (0.20s) Ã¢â‚¬â€ OK | CPU=2% RAM=44%\n",
      "[20:35:52] >> 7) PSI (vektorize) basliyor | CPU=2% RAM=44%\n",
      "   * PSI Ã¶zet: KEEP=15 | DROP=2 | WARN=0\n",
      "   - PSI sonrasi kalan: 15\n",
      "[20:35:53] Ã¢--Â  7) PSI (vektorize) bitti (0.71s) Ã¢â‚¬â€ OK | CPU=1% RAM=44%\n",
      "   - High IV flags: risk_category,risk_score,risk_score_v2\n",
      "[20:35:53] >> 8) WOE transform (Train/Test/OOT) basliyor | CPU=7% RAM=44%\n",
      "   - X_train=(3696, 8), X_test=(924, 8), X_oot=(380, 8)\n",
      "[20:35:53] Ã¢--Â  8) WOE transform (Train/Test/OOT) bitti (0.14s) Ã¢â‚¬â€ OK | CPU=2% RAM=44%\n",
      "[20:35:53] >> 9) Korelasyon & cluster basliyor | CPU=3% RAM=44%\n",
      "   - cluster temsilcisi=7\n",
      "[20:35:53] Ã¢--Â  9) Korelasyon & cluster bitti (0.17s) Ã¢â‚¬â€ OK | CPU=3% RAM=44%\n",
      "[20:35:54] >> 10) Feature selection (Forward+1SE) basliyor | CPU=2% RAM=44%\n",
      "   - Boruta: 8/8 kaldi\n",
      "   - Forward+1SE secti: 3\n",
      "   - baseline degisken=3\n",
      "[20:35:57] Ã¢--Â  10) Feature selection (Forward+1SE) bitti (3.07s) Ã¢â‚¬â€ OK | CPU=8% RAM=44%\n",
      "[20:35:57] >> 11) Nihai korelasyon filtresi basliyor | CPU=4% RAM=44%\n",
      "   - corr sonrasi=3\n",
      "[20:35:57] Ã¢--Â  11) Nihai korelasyon filtresi bitti (0.16s) Ã¢â‚¬â€ OK | CPU=1% RAM=44%\n",
      "[20:35:57] >> 12) Gurultu (noise) sentineli basliyor | CPU=0% RAM=44%\n",
      "   - final degisken=2\n",
      "[20:35:58] Ã¢--Â  12) Gurultu (noise) sentineli bitti (0.58s) Ã¢â‚¬â€ OK | CPU=1% RAM=44%\n",
      "[20:35:58] >> 13) Modelleme & degerlendirme basliyor | CPU=0% RAM=44%\n",
      "[20:35:58]   - Logit_L2 tuning | CPU=1% RAM=44%\n",
      "[20:35:58]   - Logit_L2 CV basliyor | CPU=4% RAM=44%\n",
      "[20:35:58]   - RandomForest tuning | CPU=2% RAM=44%\n",
      "[20:36:23]   - RandomForest CV basliyor | CPU=0% RAM=44%\n",
      "[20:36:37]   - ExtraTrees tuning | CPU=1% RAM=44%\n",
      "[20:36:58]   - ExtraTrees CV basliyor | CPU=2% RAM=44%\n",
      "[20:37:07]   - XGBoost tuning | CPU=9% RAM=44%\n",
      "[20:37:14]   - XGBoost CV basliyor | CPU=57% RAM=45%\n",
      "[20:37:15]   - LightGBM tuning | CPU=7% RAM=45%\n",
      "[20:37:27]   - LightGBM CV basliyor | CPU=5% RAM=45%\n",
      "[20:37:29]   - GAM tuning | CPU=6% RAM=45%\n",
      "[20:37:31]   - GAM CV basliyor | CPU=4% RAM=45%\n",
      "[20:37:31] Ã¢--Â  13) Modelleme & degerlendirme bitti (93.70s) Ã¢â‚¬â€ OK | CPU=2% RAM=45%\n",
      "[20:37:31] >> 14) En iyi model secimi basliyor | CPU=2% RAM=45%\n",
      "   - best=ExtraTrees\n",
      "[20:37:32] Ã¢--Â  14) En iyi model secimi bitti (0.11s) Ã¢â‚¬â€ OK | CPU=2% RAM=45%\n",
      "[20:37:32] >> 14b) Kalibrasyon basliyor | CPU=2% RAM=45%\n",
      "   - Using calibration DataFrame: (1000, 19)\n",
      "   - calibration data overlaps with train/test/oot; skipping calibration\n",
      "[20:37:32] Ã¢--Â  14b) Kalibrasyon bitti (0.12s) Ã¢â‚¬â€ OK | CPU=1% RAM=45%\n",
      "[20:37:32] >> 15) Rapor tablolari basliyor | CPU=1% RAM=45%\n",
      "   - Data dictionary loaded from DataFrame: 16 variables\n",
      "   - Data dictionary loaded from DataFrame: 16 variables\n",
      "[20:37:33] Ã¢--Â  15) Rapor tablolari bitti (0.73s) Ã¢â‚¬â€ OK | CPU=3% RAM=45%\n",
      "[20:37:33] >> 15b) Export (Excel/Parquet) basliyor | CPU=2% RAM=45%\n",
      "[20:37:33] Ã¢--Â  15b) Export (Excel/Parquet) bitti (0.60s) Ã¢â‚¬â€ OK | CPU=1% RAM=45%\n",
      "[20:37:33] >> RUN tamam - run_id=20250903_203538_54e787bb | CPU=1% RAM=45%\n",
      "\n",
      "============================================================\n",
      "âœ… PIPELINE TAMAMLANDI!\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "# Pipeline Ã§alÄ±ÅŸtÄ±r\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"ðŸš€ PIPELINE Ã‡ALIÅžTIRILIYOR...\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "pipeline = RiskModelPipeline(cfg)\n",
    "pipeline.run(df)\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"âœ… PIPELINE TAMAMLANDI!\")\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Pipeline SonuÃ§larÄ± ve Analiz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ“Š PIPELINE SONUÃ‡LARI\n",
      "============================================================\n",
      "\n",
      "âœ… EN Ä°YÄ° MODEL: ExtraTrees\n",
      "âœ… FÄ°NAL DEÄžÄ°ÅžKEN SAYISI: 2\n",
      "\n",
      "ðŸ“‹ Final DeÄŸiÅŸkenler:\n",
      "  1. risk_score: Ana risk skoru (0-1, yÃ¼ksek=riskli)\n",
      "  2. payment_score: Ã–deme geÃ§miÅŸi skoru (0-1, yÃ¼ksek=iyi)\n",
      "\n",
      "ðŸ“ˆ MODEL PERFORMANSI:\n",
      "\n",
      "  OUT-OF-TIME (OOT):\n",
      "    AUC: 0.794\n",
      "    GINI: 0.588 (58.8%)\n",
      "    KS: 0.460\n",
      "\n",
      "    âš ï¸ OOT Gini hedefin altÄ±nda: 58.8%\n"
     ]
    }
   ],
   "source": [
    "# SonuÃ§larÄ± analiz et\n",
    "print(\"\\nðŸ“Š PIPELINE SONUÃ‡LARI\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "if pipeline.best_model_name_:\n",
    "    print(f\"\\nâœ… EN Ä°YÄ° MODEL: {pipeline.best_model_name_}\")\n",
    "    print(f\"âœ… FÄ°NAL DEÄžÄ°ÅžKEN SAYISI: {len(pipeline.final_vars_)}\")\n",
    "    \n",
    "    # Final deÄŸiÅŸkenler\n",
    "    if pipeline.final_vars_:\n",
    "        print(f\"\\nðŸ“‹ Final DeÄŸiÅŸkenler:\")\n",
    "        for i, var in enumerate(pipeline.final_vars_, 1):\n",
    "            desc = data_dict[data_dict['alan_adi'] == var]['alan_aciklamasi'].values\n",
    "            desc_str = desc[0] if len(desc) > 0 else \"AÃ§Ä±klama yok\"\n",
    "            print(f\"  {i}. {var}: {desc_str}\")\n",
    "    \n",
    "    # Model performansÄ±\n",
    "    if pipeline.models_summary_ is not None and not pipeline.models_summary_.empty:\n",
    "        best = pipeline.models_summary_[pipeline.models_summary_['model_name'] == pipeline.best_model_name_].iloc[0]\n",
    "        \n",
    "        print(f\"\\nðŸ“ˆ MODEL PERFORMANSI:\")\n",
    "        \n",
    "        # OOT Performans (en Ã¶nemli)\n",
    "        if 'AUC_OOT' in best and best.get('AUC_OOT'):\n",
    "            auc_oot = best.get('AUC_OOT')\n",
    "            gini_oot = best.get('Gini_OOT')\n",
    "            ks_oot = best.get('KS_OOT')\n",
    "            \n",
    "            print(f\"\\n  OUT-OF-TIME (OOT):\")\n",
    "            print(f\"    AUC: {auc_oot:.3f}\")\n",
    "            print(f\"    GINI: {gini_oot:.3f} ({gini_oot*100:.1f}%)\")\n",
    "            print(f\"    KS: {ks_oot:.3f}\")\n",
    "            \n",
    "            if 0.70 <= gini_oot <= 0.80:\n",
    "                print(f\"\\n    ðŸŽ¯ HEDEF BAÅžARILI: OOT Gini %70-80 aralÄ±ÄŸÄ±nda ({gini_oot*100:.1f}%)\")\n",
    "            elif gini_oot >= 0.70:\n",
    "                print(f\"\\n    âœ… Ä°YÄ°: OOT Gini %70+ ({gini_oot*100:.1f}%)\")\n",
    "            else:\n",
    "                print(f\"\\n    âš ï¸ OOT Gini hedefin altÄ±nda: {gini_oot*100:.1f}%\")\n",
    "else:\n",
    "    print(\"âš ï¸ UYARI: Model seÃ§ilemedi!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ“Š FÄ°LTRELEME DETAYLARI\n",
      "============================================================\n",
      "\n",
      "ðŸ·ï¸ NADÄ°R KATEGORÄ° FÄ°LTRESÄ°:\n",
      "  EÅŸik: %1.0\n",
      "  Muhtemel elenen kategoriler: Rare1, Rare2 (product_type deÄŸiÅŸkeninde)\n"
     ]
    }
   ],
   "source": [
    "# Filtreleme detaylarÄ±\n",
    "print(\"\\nðŸ“Š FÄ°LTRELEME DETAYLARI\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# PSI analizi\n",
    "if hasattr(pipeline, 'psi_df_') and pipeline.psi_df_ is not None:\n",
    "    print(\"\\nðŸ”„ PSI FÄ°LTRESÄ°:\")\n",
    "    high_psi = pipeline.psi_df_[pipeline.psi_df_['PSI'] > cfg.psi_threshold]\n",
    "    if not high_psi.empty:\n",
    "        print(f\"  Elenen deÄŸiÅŸkenler (PSI > {cfg.psi_threshold}):\")\n",
    "        for _, row in high_psi.iterrows():\n",
    "            print(f\"    - {row['variable']}: PSI={row['PSI']:.3f}\")\n",
    "    else:\n",
    "        print(f\"  TÃ¼m deÄŸiÅŸkenler PSI < {cfg.psi_threshold}\")\n",
    "\n",
    "# Korelasyon analizi\n",
    "if hasattr(pipeline, 'corr_dropped_') and pipeline.corr_dropped_:\n",
    "    print(\"\\nðŸ”— KORELASYON FÄ°LTRESÄ°:\")\n",
    "    print(f\"  Elenen deÄŸiÅŸkenler (corr > {cfg.rho_threshold}):\")\n",
    "    for item in pipeline.corr_dropped_:\n",
    "        dropped = item.get('dropped', 'N/A')\n",
    "        kept = item.get('kept', 'N/A')\n",
    "        corr = item.get('corr', 0)\n",
    "        print(f\"    - {dropped} elendi (corr={corr:.3f} with {kept})\")\n",
    "\n",
    "# IV analizi\n",
    "if hasattr(pipeline, 'iv_filter_log_') and pipeline.iv_filter_log_:\n",
    "    low_iv_vars = [item for item in pipeline.iv_filter_log_ \n",
    "                   if item.get('reason', '').startswith('Low IV')]\n",
    "    if low_iv_vars:\n",
    "        print(\"\\nðŸ“Š IV FÄ°LTRESÄ°:\")\n",
    "        print(f\"  Elenen deÄŸiÅŸkenler (IV < {cfg.iv_min}):\")\n",
    "        for item in low_iv_vars:\n",
    "            var = item.get('variable', 'N/A')\n",
    "            iv = item.get('iv', 0)\n",
    "            print(f\"    - {var}: IV={iv:.4f}\")\n",
    "\n",
    "print(\"\\nðŸ·ï¸ NADÄ°R KATEGORÄ° FÄ°LTRESÄ°:\")\n",
    "print(f\"  EÅŸik: %{cfg.rare_threshold*100}\")\n",
    "print(f\"  Muhtemel elenen kategoriler: Rare1, Rare2 (product_type deÄŸiÅŸkeninde)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Excel Raporu KontrolÃ¼"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ“ Excel raporu oluÅŸturuldu: outputs_realistic_gini\\realistic_gini_report.xlsx\n",
      "\n",
      "ðŸ“‹ Sheets (16 adet):\n",
      "   1. final_vars\n",
      "   2. best_name\n",
      "   3. models_summary\n",
      "   4. best_model\n",
      "   5. best_model_vars_df\n",
      "   6. best_model_woe_df\n",
      "   7. top20_iv_df\n",
      "   8. top50_univariate\n",
      "   9. ks_info_traincv\n",
      "  10. ks_info_test\n",
      "\n",
      "ðŸ“Š MODEL KARÅžILAÅžTIRMASI:\n",
      "  model_name  Gini_OOT\n",
      "  ExtraTrees  0.588250\n",
      "    Logit_L2  0.593798\n",
      "RandomForest  0.586364\n",
      "     XGBoost  0.586364\n",
      "    LightGBM  0.586364\n",
      "         GAM  0.593798\n"
     ]
    }
   ],
   "source": [
    "# Excel raporu kontrolÃ¼\n",
    "import os\n",
    "\n",
    "excel_path = os.path.join(cfg.output_folder, cfg.output_excel_path)\n",
    "if os.path.exists(excel_path):\n",
    "    print(f\"ðŸ“ Excel raporu oluÅŸturuldu: {excel_path}\")\n",
    "    \n",
    "    excel_file = pd.ExcelFile(excel_path)\n",
    "    print(f\"\\nðŸ“‹ Sheets ({len(excel_file.sheet_names)} adet):\")\n",
    "    for i, sheet in enumerate(excel_file.sheet_names[:10], 1):  # Ä°lk 10 sheet\n",
    "        print(f\"  {i:2}. {sheet}\")\n",
    "    \n",
    "    # Model summary\n",
    "    if 'models_summary' in excel_file.sheet_names:\n",
    "        models_df = pd.read_excel(excel_path, sheet_name='models_summary')\n",
    "        print(f\"\\nðŸ“Š MODEL KARÅžILAÅžTIRMASI:\")\n",
    "        \n",
    "        # Select available columns\n",
    "        display_cols = ['model_name', 'Gini_train', 'Gini_test', 'Gini_OOT']\n",
    "        available_cols = [col for col in display_cols if col in models_df.columns]\n",
    "        \n",
    "        if available_cols:\n",
    "            print(models_df[available_cols].to_string(index=False))\n",
    "else:\n",
    "    print(f\"âš ï¸ Excel raporu bulunamadÄ±: {excel_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Ã–zet ve SonuÃ§lar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "ðŸ“Š TEST Ã–ZET\n",
      "================================================================================\n",
      "\n",
      "âœ… TEST EDÄ°LEN PIPELINE ADIMLARI:\n",
      "  1. Veri validasyon ve hazÄ±rlama\n",
      "  2. WOE binning ve transformation\n",
      "  3. PSI hesaplama ve filtreleme\n",
      "  4. IV hesaplama ve dÃ¼ÅŸÃ¼k bilgili deÄŸiÅŸkenleri eleme\n",
      "  5. Korelasyon analizi ve yÃ¼ksek koreleli deÄŸiÅŸkenleri eleme\n",
      "  6. Nadir kategorileri birleÅŸtirme\n",
      "  7. Feature selection (Boruta + Forward Selection)\n",
      "  8. Model training (6 algoritma)\n",
      "  9. Model evaluation ve en iyi model seÃ§imi\n",
      " 10. Kalibrasyon (isotonic)\n",
      " 11. Raporlama ve Excel export\n",
      "\n",
      "ðŸ“ˆ HEDEF PERFORMANS:\n",
      "  Hedef Gini aralÄ±ÄŸÄ±: %70-80\n",
      "  Baseline Gini (Logistic Regression): 75.2%\n",
      "  Pipeline OOT Gini: 58.8%\n",
      "\n",
      "================================================================================\n",
      "âœ… TEST TAMAMLANDI!\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"ðŸ“Š TEST Ã–ZET\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "print(\"\\nâœ… TEST EDÄ°LEN PIPELINE ADIMLARI:\")\n",
    "print(\"  1. Veri validasyon ve hazÄ±rlama\")\n",
    "print(\"  2. WOE binning ve transformation\")\n",
    "print(\"  3. PSI hesaplama ve filtreleme\")\n",
    "print(\"  4. IV hesaplama ve dÃ¼ÅŸÃ¼k bilgili deÄŸiÅŸkenleri eleme\")\n",
    "print(\"  5. Korelasyon analizi ve yÃ¼ksek koreleli deÄŸiÅŸkenleri eleme\")\n",
    "print(\"  6. Nadir kategorileri birleÅŸtirme\")\n",
    "print(\"  7. Feature selection (Boruta + Forward Selection)\")\n",
    "print(\"  8. Model training (6 algoritma)\")\n",
    "print(\"  9. Model evaluation ve en iyi model seÃ§imi\")\n",
    "print(\" 10. Kalibrasyon (isotonic)\")\n",
    "print(\" 11. Raporlama ve Excel export\")\n",
    "\n",
    "print(\"\\nðŸ“ˆ HEDEF PERFORMANS:\")\n",
    "print(f\"  Hedef Gini aralÄ±ÄŸÄ±: %70-80\")\n",
    "print(f\"  Baseline Gini (Logistic Regression): {gini*100:.1f}%\")\n",
    "\n",
    "if pipeline.best_model_name_ and pipeline.models_summary_ is not None:\n",
    "    best = pipeline.models_summary_[pipeline.models_summary_['model_name'] == pipeline.best_model_name_].iloc[0]\n",
    "    if 'Gini_OOT' in best and best.get('Gini_OOT'):\n",
    "        gini_oot = best.get('Gini_OOT')\n",
    "        print(f\"  Pipeline OOT Gini: {gini_oot*100:.1f}%\")\n",
    "        \n",
    "        if 0.70 <= gini_oot <= 0.80:\n",
    "            print(\"\\nðŸŽ¯ BAÅžARILI: GerÃ§ekÃ§i Gini hedefi saÄŸlandÄ± (%70-80)\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"âœ… TEST TAMAMLANDI!\")\n",
    "print(\"=\"*80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}