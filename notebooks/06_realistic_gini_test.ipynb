{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Risk Model Pipeline - GerÃ§ekÃ§i Gini Testi (%70-80)\n",
    "\n",
    "Bu notebook:\n",
    "- GerÃ§ekÃ§i %70-80 Gini aralÄ±ÄŸÄ±nda sentetik veri oluÅŸturur\n",
    "- Pipeline'Ä±n tÃ¼m adÄ±mlarÄ±nÄ± test eder\n",
    "- Filtreleme mekanizmalarÄ±nÄ±n Ã§alÄ±ÅŸtÄ±ÄŸÄ±nÄ± gÃ¶sterir"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup ve Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "import sys\n",
    "import os\n",
    "from datetime import datetime\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Add parent directory to path\n",
    "sys.path.append('..')\n",
    "from src.risk_pipeline.pipeline16 import RiskModelPipeline, Config\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "np.random.seed(2024)\n",
    "\n",
    "print(\"âœ… Setup complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. GerÃ§ekÃ§i Sentetik Veri OluÅŸturma (%70-80 Gini)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_realistic_credit_data(n_samples=5000):\n",
    "    \"\"\"\n",
    "    GerÃ§ekÃ§i kredi riski verisi - %70-80 Gini hedefli\n",
    "    \n",
    "    Ã–zellikler:\n",
    "    - GÃ¼Ã§lÃ¼ tahmin ediciler (risk_score, payment_score, vb.)\n",
    "    - Korele deÄŸiÅŸkenler (korelasyon testi iÃ§in)\n",
    "    - Drift eden deÄŸiÅŸkenler (PSI testi iÃ§in)\n",
    "    - DÃ¼ÅŸÃ¼k bilgi deÄŸerli deÄŸiÅŸkenler (IV testi iÃ§in)\n",
    "    - Nadir kategoriler (rare threshold testi iÃ§in)\n",
    "    \"\"\"\n",
    "    \n",
    "    # 1. GÃœÃ‡LÃœ TAHMÄ°N EDÄ°CÄ°LER (YÃ¼ksek IV)\n",
    "    risk_score = np.random.beta(2, 5, n_samples)  # Ana risk skoru\n",
    "    payment_score = np.random.beta(3, 7, n_samples)  # Ã–deme geÃ§miÅŸi\n",
    "    debt_burden = np.random.beta(2, 8, n_samples)  # BorÃ§ yÃ¼kÃ¼\n",
    "    income_stability = np.random.beta(4, 6, n_samples)  # Gelir istikrarÄ±\n",
    "    employment_score = np.random.beta(5, 5, n_samples)  # Ä°stihdam skoru\n",
    "    \n",
    "    # 2. KORELE DEÄžÄ°ÅžKENLER (Korelasyon testi iÃ§in)\n",
    "    # risk_score ile yÃ¼ksek korele (>0.95)\n",
    "    risk_score_v2 = risk_score + np.random.normal(0, 0.05, n_samples)\n",
    "    risk_score_v2 = np.clip(risk_score_v2, 0, 1)\n",
    "    \n",
    "    # payment_score ile korele (>0.90)\n",
    "    payment_behavior = payment_score * 0.9 + np.random.normal(0, 0.05, n_samples)\n",
    "    payment_behavior = np.clip(payment_behavior, 0, 1)\n",
    "    \n",
    "    # 3. DRIFT EDEN DEÄžÄ°ÅžKEN (PSI testi iÃ§in)\n",
    "    time_index = np.arange(n_samples) / n_samples\n",
    "    drift_feature = np.random.normal(0.3 + 0.4 * time_index, 0.1, n_samples)\n",
    "    \n",
    "    # 4. STABIL DEÄžÄ°ÅžKEN (PSI geÃ§ecek)\n",
    "    stable_feature = np.random.normal(0.5, 0.15, n_samples)\n",
    "    \n",
    "    # 5. DÃœÅžÃœK BÄ°LGÄ° DEÄžERLÄ° DEÄžÄ°ÅžKENLER (IV < 0.02, elenecek)\n",
    "    noise_feature1 = np.random.randn(n_samples)\n",
    "    noise_feature2 = np.random.uniform(0, 1, n_samples)\n",
    "    \n",
    "    # 6. KATEGORÄ°K DEÄžÄ°ÅžKENLER\n",
    "    # GÃ¼Ã§lÃ¼ kategorik (risk_score ile iliÅŸkili)\n",
    "    risk_category = pd.cut(risk_score, bins=4, \n",
    "                           labels=['Very_Low', 'Low', 'Medium', 'High'])\n",
    "    \n",
    "    # Nadir kategoriler iÃ§eren (rare threshold testi iÃ§in)\n",
    "    product_type = np.random.choice(\n",
    "        ['Standard', 'Premium', 'Basic', 'Rare1', 'Rare2'], \n",
    "        n_samples,\n",
    "        p=[0.4, 0.3, 0.28, 0.015, 0.005]  # Rare1 ve Rare2 %1'den az\n",
    "    )\n",
    "    \n",
    "    region = np.random.choice(['North', 'South', 'East', 'West'], \n",
    "                              n_samples, p=[0.25, 0.25, 0.25, 0.25])\n",
    "    \n",
    "    # 7. TARGET OLUÅžTURMA (GerÃ§ekÃ§i %70-80 Gini iÃ§in)\n",
    "    default_score = (\n",
    "        3.5 * risk_score +           # En gÃ¼Ã§lÃ¼ tahmin edici\n",
    "        3.0 * payment_score +         # Ä°kinci gÃ¼Ã§lÃ¼\n",
    "        2.0 * debt_burden +           # Orta gÃ¼Ã§lÃ¼\n",
    "        1.2 * (1 - income_stability) + # Orta etki\n",
    "        1.0 * (1 - employment_score) + # Orta etki\n",
    "        np.random.normal(0, 0.6, n_samples)  # Optimal gÃ¼rÃ¼ltÃ¼\n",
    "    )\n",
    "    \n",
    "    # Target (threshold ile binary)\n",
    "    threshold = np.percentile(default_score, 50)  # %50 default rate\n",
    "    target = (default_score > threshold).astype(int)\n",
    "    \n",
    "    # 8. DEMOGRAFÄ°K Ã–ZELLÄ°KLER\n",
    "    age = np.random.normal(40, 12, n_samples).clip(18, 70)\n",
    "    tenure = np.random.exponential(5, n_samples).clip(0, 30)\n",
    "    \n",
    "    # DataFrame oluÅŸtur\n",
    "    df = pd.DataFrame({\n",
    "        'app_id': [f'APP_{i:08d}' for i in range(n_samples)],\n",
    "        'app_dt': pd.date_range('2022-01-01', periods=n_samples, freq='6H'),\n",
    "        'target': target,\n",
    "        \n",
    "        # GÃ¼Ã§lÃ¼ tahmin ediciler\n",
    "        'risk_score': risk_score,\n",
    "        'payment_score': payment_score,\n",
    "        'debt_burden': debt_burden,\n",
    "        'income_stability': income_stability,\n",
    "        'employment_score': employment_score,\n",
    "        \n",
    "        # Korele deÄŸiÅŸkenler\n",
    "        'risk_score_v2': risk_score_v2,\n",
    "        'payment_behavior': payment_behavior,\n",
    "        \n",
    "        # PSI test deÄŸiÅŸkenleri\n",
    "        'drift_feature': drift_feature,\n",
    "        'stable_feature': stable_feature,\n",
    "        \n",
    "        # DÃ¼ÅŸÃ¼k IV deÄŸiÅŸkenler\n",
    "        'noise_feature1': noise_feature1,\n",
    "        'noise_feature2': noise_feature2,\n",
    "        \n",
    "        # Kategorik deÄŸiÅŸkenler\n",
    "        'risk_category': risk_category,\n",
    "        'product_type': product_type,\n",
    "        'region': region,\n",
    "        \n",
    "        # Demografik\n",
    "        'age': age,\n",
    "        'tenure': tenure\n",
    "    })\n",
    "    \n",
    "    # Eksik deÄŸerler ekle (gerÃ§ekÃ§ilik iÃ§in, %2-3)\n",
    "    missing_cols = ['employment_score', 'tenure']\n",
    "    for col in missing_cols:\n",
    "        missing_idx = np.random.choice(df.index, size=int(0.02 * len(df)), replace=False)\n",
    "        df.loc[missing_idx, col] = np.nan\n",
    "    \n",
    "    return df\n",
    "\n",
    "# Veri oluÅŸtur\n",
    "print(\"ðŸ“Š GerÃ§ekÃ§i sentetik veri oluÅŸturuluyor...\")\n",
    "df = create_realistic_credit_data(5000)\n",
    "print(f\"âœ… Veri oluÅŸturuldu: {df.shape}\")\n",
    "print(f\"   Target oranÄ±: {df['target'].mean():.1%}\")\n",
    "print(f\"   DeÄŸiÅŸken sayÄ±sÄ±: {df.shape[1] - 3}\")  # id, date, target hariÃ§"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Baseline Performans Testi (Logistic Regression)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Baseline performans testi\n",
    "print(\"ðŸ”¬ Baseline Logistic Regression ile Gini testi...\")\n",
    "\n",
    "# GÃ¼Ã§lÃ¼ deÄŸiÅŸkenlerle model\n",
    "strong_features = ['risk_score', 'payment_score', 'debt_burden', \n",
    "                  'income_stability', 'employment_score']\n",
    "\n",
    "# Train/test split\n",
    "X = df[strong_features].fillna(df[strong_features].median())\n",
    "y = df['target']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.3, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "# Logistic Regression\n",
    "lr = LogisticRegression(random_state=42, max_iter=1000)\n",
    "lr.fit(X_train, y_train)\n",
    "\n",
    "# Predictions\n",
    "y_pred_proba = lr.predict_proba(X_test)[:, 1]\n",
    "\n",
    "# Performance\n",
    "auc = roc_auc_score(y_test, y_pred_proba)\n",
    "gini = 2 * auc - 1\n",
    "\n",
    "print(f\"\\nðŸ“Š BASELINE PERFORMANS:\")\n",
    "print(f\"   AUC: {auc:.3f}\")\n",
    "print(f\"   GINI: {gini:.3f} ({gini*100:.1f}%)\")\n",
    "\n",
    "if 0.70 <= gini <= 0.80:\n",
    "    print(f\"\\nâœ… MÃœKEMMEL: Gini hedef aralÄ±kta (%70-80)\")\n",
    "elif gini >= 0.70:\n",
    "    print(f\"\\nâœ… Ä°YÄ°: Gini %70+ ({gini*100:.1f}%)\")\n",
    "else:\n",
    "    print(f\"\\nâš ï¸ Gini hedefin altÄ±nda: {gini*100:.1f}%\")\n",
    "\n",
    "# Feature importance\n",
    "print(\"\\nðŸ“Š DeÄŸiÅŸken Ã–nemleri (Logistic Regression Coefficients):\")\n",
    "feature_importance = pd.DataFrame({\n",
    "    'feature': strong_features,\n",
    "    'coefficient': lr.coef_[0]\n",
    "}).sort_values('coefficient', ascending=False)\n",
    "print(feature_importance.to_string(index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Kalibrasyon Verisi ve Veri SÃ¶zlÃ¼ÄŸÃ¼"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Kalibrasyon verisi\n",
    "print(\"ðŸ“Š Kalibrasyon verisi hazÄ±rlanÄ±yor...\")\n",
    "cal_df = create_realistic_credit_data(1000)\n",
    "print(f\"   Kalibrasyon boyutu: {cal_df.shape}\")\n",
    "print(f\"   Kalibrasyon target oranÄ±: {cal_df['target'].mean():.1%}\")\n",
    "\n",
    "# Veri sÃ¶zlÃ¼ÄŸÃ¼\n",
    "print(\"\\nðŸ“š Veri sÃ¶zlÃ¼ÄŸÃ¼ hazÄ±rlanÄ±yor...\")\n",
    "data_dict = pd.DataFrame({\n",
    "    'alan_adi': [\n",
    "        'risk_score', 'payment_score', 'debt_burden', 'income_stability', \n",
    "        'employment_score', 'risk_score_v2', 'payment_behavior',\n",
    "        'drift_feature', 'stable_feature', 'noise_feature1', 'noise_feature2',\n",
    "        'risk_category', 'product_type', 'region', 'age', 'tenure'\n",
    "    ],\n",
    "    'alan_aciklamasi': [\n",
    "        'Ana risk skoru (0-1, yÃ¼ksek=riskli)',\n",
    "        'Ã–deme geÃ§miÅŸi skoru (0-1, yÃ¼ksek=iyi)',\n",
    "        'BorÃ§ yÃ¼kÃ¼ gÃ¶stergesi (0-1, yÃ¼ksek=borÃ§lu)',\n",
    "        'Gelir istikrarÄ± (0-1, yÃ¼ksek=istikrarlÄ±)',\n",
    "        'Ä°stihdam skoru (0-1, yÃ¼ksek=gÃ¼venli)',\n",
    "        'Risk skoru v2 (risk_score ile korele, elenecek)',\n",
    "        'Ã–deme davranÄ±ÅŸÄ± (payment_score ile korele)',\n",
    "        'Zamanla deÄŸiÅŸen Ã¶zellik (PSI ile elenecek)',\n",
    "        'Sabit Ã¶zellik (PSI testini geÃ§ecek)',\n",
    "        'GÃ¼rÃ¼ltÃ¼ deÄŸiÅŸkeni 1 (dÃ¼ÅŸÃ¼k IV, elenecek)',\n",
    "        'GÃ¼rÃ¼ltÃ¼ deÄŸiÅŸkeni 2 (dÃ¼ÅŸÃ¼k IV, elenecek)',\n",
    "        'Risk kategorisi (risk_score ile tÃ¼retilmiÅŸ)',\n",
    "        'ÃœrÃ¼n tipi (nadir kategoriler iÃ§erir)',\n",
    "        'BÃ¶lge',\n",
    "        'MÃ¼ÅŸteri yaÅŸÄ±',\n",
    "        'MÃ¼ÅŸteri kÄ±demi (yÄ±l)'\n",
    "    ]\n",
    "})\n",
    "print(f\"   TanÄ±mlanan deÄŸiÅŸken: {len(data_dict)}\")\n",
    "print(\"\\nðŸ“‹ Veri SÃ¶zlÃ¼ÄŸÃ¼:\")\n",
    "print(data_dict.head(5).to_string(index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Pipeline KonfigÃ¼rasyonu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pipeline konfigÃ¼rasyonu\n",
    "print(\"âš™ï¸ Pipeline konfigÃ¼rasyonu...\")\n",
    "\n",
    "cfg = Config(\n",
    "    # Temel ayarlar\n",
    "    id_col='app_id',\n",
    "    time_col='app_dt',\n",
    "    target_col='target',\n",
    "    \n",
    "    # Veri bÃ¶lme\n",
    "    use_test_split=True,\n",
    "    test_size_row_frac=0.2,\n",
    "    oot_window_months=4,  # Son 4 ay OOT\n",
    "    \n",
    "    # Veri sÃ¶zlÃ¼ÄŸÃ¼ ve kalibrasyon\n",
    "    data_dictionary_df=data_dict,\n",
    "    calibration_df=cal_df,\n",
    "    calibration_method='isotonic',\n",
    "    \n",
    "    # Model ayarlarÄ±\n",
    "    cv_folds=5,\n",
    "    random_state=2024,\n",
    "    n_jobs=2,\n",
    "    \n",
    "    # HPO ayarlarÄ± (hÄ±zlÄ± demo iÃ§in)\n",
    "    hpo_timeout_sec=20,\n",
    "    hpo_trials=10,\n",
    "    \n",
    "    # Feature engineering eÅŸikleri\n",
    "    rare_threshold=0.01,      # %1'den az (Rare1, Rare2 elenecek)\n",
    "    psi_threshold=0.20,       # PSI > 0.20 (drift_feature elenecek)\n",
    "    iv_min=0.02,             # IV < 0.02 (noise deÄŸiÅŸkenler elenecek)\n",
    "    rho_threshold=0.95,      # Korelasyon > 0.95 (risk_score_v2 elenecek)\n",
    "    \n",
    "    # Ã‡Ä±ktÄ±lar\n",
    "    output_folder='outputs_realistic_gini',\n",
    "    output_excel_path='realistic_gini_report.xlsx',\n",
    "    log_file='outputs_realistic_gini/pipeline.log',\n",
    "    write_parquet=False,\n",
    "    write_csv=False\n",
    ")\n",
    "\n",
    "print(\"âœ… KonfigÃ¼rasyon hazÄ±r!\")\n",
    "print(f\"\\nðŸ“‹ Filtreleme EÅŸikleri:\")\n",
    "print(f\"   PSI eÅŸiÄŸi: {cfg.psi_threshold}\")\n",
    "print(f\"   IV minimum: {cfg.iv_min}\")\n",
    "print(f\"   Korelasyon eÅŸiÄŸi: {cfg.rho_threshold}\")\n",
    "print(f\"   Nadir kategori eÅŸiÄŸi: %{cfg.rare_threshold*100}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Pipeline Ã‡alÄ±ÅŸtÄ±rma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pipeline Ã§alÄ±ÅŸtÄ±r\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"ðŸš€ PIPELINE Ã‡ALIÅžTIRILIYOR...\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "pipeline = RiskModelPipeline(cfg)\n",
    "pipeline.run(df)\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"âœ… PIPELINE TAMAMLANDI!\")\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Pipeline SonuÃ§larÄ± ve Analiz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SonuÃ§larÄ± analiz et\n",
    "print(\"\\nðŸ“Š PIPELINE SONUÃ‡LARI\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "if pipeline.best_model_name_:\n",
    "    print(f\"\\nâœ… EN Ä°YÄ° MODEL: {pipeline.best_model_name_}\")\n",
    "    print(f\"âœ… FÄ°NAL DEÄžÄ°ÅžKEN SAYISI: {len(pipeline.final_vars_)}\")\n",
    "    \n",
    "    # Final deÄŸiÅŸkenler\n",
    "    if pipeline.final_vars_:\n",
    "        print(f\"\\nðŸ“‹ Final DeÄŸiÅŸkenler:\")\n",
    "        for i, var in enumerate(pipeline.final_vars_, 1):\n",
    "            desc = data_dict[data_dict['alan_adi'] == var]['alan_aciklamasi'].values\n",
    "            desc_str = desc[0] if len(desc) > 0 else \"AÃ§Ä±klama yok\"\n",
    "            print(f\"  {i}. {var}: {desc_str}\")\n",
    "    \n",
    "    # Model performansÄ±\n",
    "    if pipeline.models_summary_ is not None and not pipeline.models_summary_.empty:\n",
    "        best = pipeline.models_summary_[pipeline.models_summary_['model_name'] == pipeline.best_model_name_].iloc[0]\n",
    "        \n",
    "        print(f\"\\nðŸ“ˆ MODEL PERFORMANSI:\")\n",
    "        \n",
    "        # OOT Performans (en Ã¶nemli)\n",
    "        if 'AUC_OOT' in best and best.get('AUC_OOT'):\n",
    "            auc_oot = best.get('AUC_OOT')\n",
    "            gini_oot = best.get('Gini_OOT')\n",
    "            ks_oot = best.get('KS_OOT')\n",
    "            \n",
    "            print(f\"\\n  OUT-OF-TIME (OOT):\")\n",
    "            print(f\"    AUC: {auc_oot:.3f}\")\n",
    "            print(f\"    GINI: {gini_oot:.3f} ({gini_oot*100:.1f}%)\")\n",
    "            print(f\"    KS: {ks_oot:.3f}\")\n",
    "            \n",
    "            if 0.70 <= gini_oot <= 0.80:\n",
    "                print(f\"\\n    ðŸŽ¯ HEDEF BAÅžARILI: OOT Gini %70-80 aralÄ±ÄŸÄ±nda ({gini_oot*100:.1f}%)\")\n",
    "            elif gini_oot >= 0.70:\n",
    "                print(f\"\\n    âœ… Ä°YÄ°: OOT Gini %70+ ({gini_oot*100:.1f}%)\")\n",
    "            else:\n",
    "                print(f\"\\n    âš ï¸ OOT Gini hedefin altÄ±nda: {gini_oot*100:.1f}%\")\n",
    "else:\n",
    "    print(\"âš ï¸ UYARI: Model seÃ§ilemedi!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filtreleme detaylarÄ±\n",
    "print(\"\\nðŸ“Š FÄ°LTRELEME DETAYLARI\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# PSI analizi\n",
    "if hasattr(pipeline, 'psi_df_') and pipeline.psi_df_ is not None:\n",
    "    print(\"\\nðŸ”„ PSI FÄ°LTRESÄ°:\")\n",
    "    high_psi = pipeline.psi_df_[pipeline.psi_df_['PSI'] > cfg.psi_threshold]\n",
    "    if not high_psi.empty:\n",
    "        print(f\"  Elenen deÄŸiÅŸkenler (PSI > {cfg.psi_threshold}):\")\n",
    "        for _, row in high_psi.iterrows():\n",
    "            print(f\"    - {row['variable']}: PSI={row['PSI']:.3f}\")\n",
    "    else:\n",
    "        print(f\"  TÃ¼m deÄŸiÅŸkenler PSI < {cfg.psi_threshold}\")\n",
    "\n",
    "# Korelasyon analizi\n",
    "if hasattr(pipeline, 'corr_dropped_') and pipeline.corr_dropped_:\n",
    "    print(\"\\nðŸ”— KORELASYON FÄ°LTRESÄ°:\")\n",
    "    print(f\"  Elenen deÄŸiÅŸkenler (corr > {cfg.rho_threshold}):\")\n",
    "    for item in pipeline.corr_dropped_:\n",
    "        dropped = item.get('dropped', 'N/A')\n",
    "        kept = item.get('kept', 'N/A')\n",
    "        corr = item.get('corr', 0)\n",
    "        print(f\"    - {dropped} elendi (corr={corr:.3f} with {kept})\")\n",
    "\n",
    "# IV analizi\n",
    "if hasattr(pipeline, 'iv_filter_log_') and pipeline.iv_filter_log_:\n",
    "    low_iv_vars = [item for item in pipeline.iv_filter_log_ \n",
    "                   if item.get('reason', '').startswith('Low IV')]\n",
    "    if low_iv_vars:\n",
    "        print(\"\\nðŸ“Š IV FÄ°LTRESÄ°:\")\n",
    "        print(f\"  Elenen deÄŸiÅŸkenler (IV < {cfg.iv_min}):\")\n",
    "        for item in low_iv_vars:\n",
    "            var = item.get('variable', 'N/A')\n",
    "            iv = item.get('iv', 0)\n",
    "            print(f\"    - {var}: IV={iv:.4f}\")\n",
    "\n",
    "print(\"\\nðŸ·ï¸ NADÄ°R KATEGORÄ° FÄ°LTRESÄ°:\")\n",
    "print(f\"  EÅŸik: %{cfg.rare_threshold*100}\")\n",
    "print(f\"  Muhtemel elenen kategoriler: Rare1, Rare2 (product_type deÄŸiÅŸkeninde)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Excel Raporu KontrolÃ¼"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Excel raporu kontrolÃ¼\n",
    "import os\n",
    "\n",
    "excel_path = os.path.join(cfg.output_folder, cfg.output_excel_path)\n",
    "if os.path.exists(excel_path):\n",
    "    print(f\"ðŸ“ Excel raporu oluÅŸturuldu: {excel_path}\")\n",
    "    \n",
    "    excel_file = pd.ExcelFile(excel_path)\n",
    "    print(f\"\\nðŸ“‹ Sheets ({len(excel_file.sheet_names)} adet):\")\n",
    "    for i, sheet in enumerate(excel_file.sheet_names[:10], 1):  # Ä°lk 10 sheet\n",
    "        print(f\"  {i:2}. {sheet}\")\n",
    "    \n",
    "    # Model summary\n",
    "    if 'models_summary' in excel_file.sheet_names:\n",
    "        models_df = pd.read_excel(excel_path, sheet_name='models_summary')\n",
    "        print(f\"\\nðŸ“Š MODEL KARÅžILAÅžTIRMASI:\")\n",
    "        \n",
    "        # Select available columns\n",
    "        display_cols = ['model_name', 'Gini_train', 'Gini_test', 'Gini_OOT']\n",
    "        available_cols = [col for col in display_cols if col in models_df.columns]\n",
    "        \n",
    "        if available_cols:\n",
    "            print(models_df[available_cols].to_string(index=False))\n",
    "else:\n",
    "    print(f\"âš ï¸ Excel raporu bulunamadÄ±: {excel_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Ã–zet ve SonuÃ§lar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"ðŸ“Š TEST Ã–ZET\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "print(\"\\nâœ… TEST EDÄ°LEN PIPELINE ADIMLARI:\")\n",
    "print(\"  1. Veri validasyon ve hazÄ±rlama\")\n",
    "print(\"  2. WOE binning ve transformation\")\n",
    "print(\"  3. PSI hesaplama ve filtreleme\")\n",
    "print(\"  4. IV hesaplama ve dÃ¼ÅŸÃ¼k bilgili deÄŸiÅŸkenleri eleme\")\n",
    "print(\"  5. Korelasyon analizi ve yÃ¼ksek koreleli deÄŸiÅŸkenleri eleme\")\n",
    "print(\"  6. Nadir kategorileri birleÅŸtirme\")\n",
    "print(\"  7. Feature selection (Boruta + Forward Selection)\")\n",
    "print(\"  8. Model training (6 algoritma)\")\n",
    "print(\"  9. Model evaluation ve en iyi model seÃ§imi\")\n",
    "print(\" 10. Kalibrasyon (isotonic)\")\n",
    "print(\" 11. Raporlama ve Excel export\")\n",
    "\n",
    "print(\"\\nðŸ“ˆ HEDEF PERFORMANS:\")\n",
    "print(f\"  Hedef Gini aralÄ±ÄŸÄ±: %70-80\")\n",
    "print(f\"  Baseline Gini (Logistic Regression): {gini*100:.1f}%\")\n",
    "\n",
    "if pipeline.best_model_name_ and pipeline.models_summary_ is not None:\n",
    "    best = pipeline.models_summary_[pipeline.models_summary_['model_name'] == pipeline.best_model_name_].iloc[0]\n",
    "    if 'Gini_OOT' in best and best.get('Gini_OOT'):\n",
    "        gini_oot = best.get('Gini_OOT')\n",
    "        print(f\"  Pipeline OOT Gini: {gini_oot*100:.1f}%\")\n",
    "        \n",
    "        if 0.70 <= gini_oot <= 0.80:\n",
    "            print(\"\\nðŸŽ¯ BAÅžARILI: GerÃ§ekÃ§i Gini hedefi saÄŸlandÄ± (%70-80)\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"âœ… TEST TAMAMLANDI!\")\n",
    "print(\"=\"*80)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}