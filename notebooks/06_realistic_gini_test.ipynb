{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Risk Model Pipeline - Gerçekçi Gini Testi (%70-80)\n",
    "\n",
    "Bu notebook:\n",
    "- Gerçekçi %70-80 Gini aralığında sentetik veri oluşturur\n",
    "- Pipeline'ın tüm adımlarını test eder\n",
    "- Filtreleme mekanizmalarının çalıştığını gösterir"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup ve Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "import sys\n",
    "import os\n",
    "from datetime import datetime\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Add parent directory to path\n",
    "sys.path.append('..')\n",
    "from src.risk_pipeline.pipeline16 import RiskModelPipeline, Config\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "np.random.seed(2024)\n",
    "\n",
    "print(\"✅ Setup complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Gerçekçi Sentetik Veri Oluşturma (%70-80 Gini)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_realistic_credit_data(n_samples=5000):\n",
    "    \"\"\"\n",
    "    Gerçekçi kredi riski verisi - %70-80 Gini hedefli\n",
    "    \n",
    "    Özellikler:\n",
    "    - Güçlü tahmin ediciler (risk_score, payment_score, vb.)\n",
    "    - Korele değişkenler (korelasyon testi için)\n",
    "    - Drift eden değişkenler (PSI testi için)\n",
    "    - Düşük bilgi değerli değişkenler (IV testi için)\n",
    "    - Nadir kategoriler (rare threshold testi için)\n",
    "    \"\"\"\n",
    "    \n",
    "    # 1. GÜÇLÜ TAHMİN EDİCİLER (Yüksek IV)\n",
    "    risk_score = np.random.beta(2, 5, n_samples)  # Ana risk skoru\n",
    "    payment_score = np.random.beta(3, 7, n_samples)  # Ödeme geçmişi\n",
    "    debt_burden = np.random.beta(2, 8, n_samples)  # Borç yükü\n",
    "    income_stability = np.random.beta(4, 6, n_samples)  # Gelir istikrarı\n",
    "    employment_score = np.random.beta(5, 5, n_samples)  # İstihdam skoru\n",
    "    \n",
    "    # 2. KORELE DEĞİŞKENLER (Korelasyon testi için)\n",
    "    # risk_score ile yüksek korele (>0.95)\n",
    "    risk_score_v2 = risk_score + np.random.normal(0, 0.05, n_samples)\n",
    "    risk_score_v2 = np.clip(risk_score_v2, 0, 1)\n",
    "    \n",
    "    # payment_score ile korele (>0.90)\n",
    "    payment_behavior = payment_score * 0.9 + np.random.normal(0, 0.05, n_samples)\n",
    "    payment_behavior = np.clip(payment_behavior, 0, 1)\n",
    "    \n",
    "    # 3. DRIFT EDEN DEĞİŞKEN (PSI testi için)\n",
    "    time_index = np.arange(n_samples) / n_samples\n",
    "    drift_feature = np.random.normal(0.3 + 0.4 * time_index, 0.1, n_samples)\n",
    "    \n",
    "    # 4. STABIL DEĞİŞKEN (PSI geçecek)\n",
    "    stable_feature = np.random.normal(0.5, 0.15, n_samples)\n",
    "    \n",
    "    # 5. DÜŞÜK BİLGİ DEĞERLİ DEĞİŞKENLER (IV < 0.02, elenecek)\n",
    "    noise_feature1 = np.random.randn(n_samples)\n",
    "    noise_feature2 = np.random.uniform(0, 1, n_samples)\n",
    "    \n",
    "    # 6. KATEGORİK DEĞİŞKENLER\n",
    "    # Güçlü kategorik (risk_score ile ilişkili)\n",
    "    risk_category = pd.cut(risk_score, bins=4, \n",
    "                           labels=['Very_Low', 'Low', 'Medium', 'High'])\n",
    "    \n",
    "    # Nadir kategoriler içeren (rare threshold testi için)\n",
    "    product_type = np.random.choice(\n",
    "        ['Standard', 'Premium', 'Basic', 'Rare1', 'Rare2'], \n",
    "        n_samples,\n",
    "        p=[0.4, 0.3, 0.28, 0.015, 0.005]  # Rare1 ve Rare2 %1'den az\n",
    "    )\n",
    "    \n",
    "    region = np.random.choice(['North', 'South', 'East', 'West'], \n",
    "                              n_samples, p=[0.25, 0.25, 0.25, 0.25])\n",
    "    \n",
    "    # 7. TARGET OLUŞTURMA (Gerçekçi %70-80 Gini için)\n",
    "    default_score = (\n",
    "        3.5 * risk_score +           # En güçlü tahmin edici\n",
    "        3.0 * payment_score +         # İkinci güçlü\n",
    "        2.0 * debt_burden +           # Orta güçlü\n",
    "        1.2 * (1 - income_stability) + # Orta etki\n",
    "        1.0 * (1 - employment_score) + # Orta etki\n",
    "        np.random.normal(0, 0.6, n_samples)  # Optimal gürültü\n",
    "    )\n",
    "    \n",
    "    # Target (threshold ile binary)\n",
    "    threshold = np.percentile(default_score, 50)  # %50 default rate\n",
    "    target = (default_score > threshold).astype(int)\n",
    "    \n",
    "    # 8. DEMOGRAFİK ÖZELLİKLER\n",
    "    age = np.random.normal(40, 12, n_samples).clip(18, 70)\n",
    "    tenure = np.random.exponential(5, n_samples).clip(0, 30)\n",
    "    \n",
    "    # DataFrame oluştur\n",
    "    df = pd.DataFrame({\n",
    "        'app_id': [f'APP_{i:08d}' for i in range(n_samples)],\n",
    "        'app_dt': pd.date_range('2022-01-01', periods=n_samples, freq='6H'),\n",
    "        'target': target,\n",
    "        \n",
    "        # Güçlü tahmin ediciler\n",
    "        'risk_score': risk_score,\n",
    "        'payment_score': payment_score,\n",
    "        'debt_burden': debt_burden,\n",
    "        'income_stability': income_stability,\n",
    "        'employment_score': employment_score,\n",
    "        \n",
    "        # Korele değişkenler\n",
    "        'risk_score_v2': risk_score_v2,\n",
    "        'payment_behavior': payment_behavior,\n",
    "        \n",
    "        # PSI test değişkenleri\n",
    "        'drift_feature': drift_feature,\n",
    "        'stable_feature': stable_feature,\n",
    "        \n",
    "        # Düşük IV değişkenler\n",
    "        'noise_feature1': noise_feature1,\n",
    "        'noise_feature2': noise_feature2,\n",
    "        \n",
    "        # Kategorik değişkenler\n",
    "        'risk_category': risk_category,\n",
    "        'product_type': product_type,\n",
    "        'region': region,\n",
    "        \n",
    "        # Demografik\n",
    "        'age': age,\n",
    "        'tenure': tenure\n",
    "    })\n",
    "    \n",
    "    # Eksik değerler ekle (gerçekçilik için, %2-3)\n",
    "    missing_cols = ['employment_score', 'tenure']\n",
    "    for col in missing_cols:\n",
    "        missing_idx = np.random.choice(df.index, size=int(0.02 * len(df)), replace=False)\n",
    "        df.loc[missing_idx, col] = np.nan\n",
    "    \n",
    "    return df\n",
    "\n",
    "# Veri oluştur\n",
    "print(\"📊 Gerçekçi sentetik veri oluşturuluyor...\")\n",
    "df = create_realistic_credit_data(5000)\n",
    "print(f\"✅ Veri oluşturuldu: {df.shape}\")\n",
    "print(f\"   Target oranı: {df['target'].mean():.1%}\")\n",
    "print(f\"   Değişken sayısı: {df.shape[1] - 3}\")  # id, date, target hariç"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Baseline Performans Testi (Logistic Regression)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Baseline performans testi\n",
    "print(\"🔬 Baseline Logistic Regression ile Gini testi...\")\n",
    "\n",
    "# Güçlü değişkenlerle model\n",
    "strong_features = ['risk_score', 'payment_score', 'debt_burden', \n",
    "                  'income_stability', 'employment_score']\n",
    "\n",
    "# Train/test split\n",
    "X = df[strong_features].fillna(df[strong_features].median())\n",
    "y = df['target']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.3, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "# Logistic Regression\n",
    "lr = LogisticRegression(random_state=42, max_iter=1000)\n",
    "lr.fit(X_train, y_train)\n",
    "\n",
    "# Predictions\n",
    "y_pred_proba = lr.predict_proba(X_test)[:, 1]\n",
    "\n",
    "# Performance\n",
    "auc = roc_auc_score(y_test, y_pred_proba)\n",
    "gini = 2 * auc - 1\n",
    "\n",
    "print(f\"\\n📊 BASELINE PERFORMANS:\")\n",
    "print(f\"   AUC: {auc:.3f}\")\n",
    "print(f\"   GINI: {gini:.3f} ({gini*100:.1f}%)\")\n",
    "\n",
    "if 0.70 <= gini <= 0.80:\n",
    "    print(f\"\\n✅ MÜKEMMEL: Gini hedef aralıkta (%70-80)\")\n",
    "elif gini >= 0.70:\n",
    "    print(f\"\\n✅ İYİ: Gini %70+ ({gini*100:.1f}%)\")\n",
    "else:\n",
    "    print(f\"\\n⚠️ Gini hedefin altında: {gini*100:.1f}%\")\n",
    "\n",
    "# Feature importance\n",
    "print(\"\\n📊 Değişken Önemleri (Logistic Regression Coefficients):\")\n",
    "feature_importance = pd.DataFrame({\n",
    "    'feature': strong_features,\n",
    "    'coefficient': lr.coef_[0]\n",
    "}).sort_values('coefficient', ascending=False)\n",
    "print(feature_importance.to_string(index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Kalibrasyon Verisi ve Veri Sözlüğü"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Kalibrasyon verisi\n",
    "print(\"📊 Kalibrasyon verisi hazırlanıyor...\")\n",
    "cal_df = create_realistic_credit_data(1000)\n",
    "print(f\"   Kalibrasyon boyutu: {cal_df.shape}\")\n",
    "print(f\"   Kalibrasyon target oranı: {cal_df['target'].mean():.1%}\")\n",
    "\n",
    "# Veri sözlüğü\n",
    "print(\"\\n📚 Veri sözlüğü hazırlanıyor...\")\n",
    "data_dict = pd.DataFrame({\n",
    "    'alan_adi': [\n",
    "        'risk_score', 'payment_score', 'debt_burden', 'income_stability', \n",
    "        'employment_score', 'risk_score_v2', 'payment_behavior',\n",
    "        'drift_feature', 'stable_feature', 'noise_feature1', 'noise_feature2',\n",
    "        'risk_category', 'product_type', 'region', 'age', 'tenure'\n",
    "    ],\n",
    "    'alan_aciklamasi': [\n",
    "        'Ana risk skoru (0-1, yüksek=riskli)',\n",
    "        'Ödeme geçmişi skoru (0-1, yüksek=iyi)',\n",
    "        'Borç yükü göstergesi (0-1, yüksek=borçlu)',\n",
    "        'Gelir istikrarı (0-1, yüksek=istikrarlı)',\n",
    "        'İstihdam skoru (0-1, yüksek=güvenli)',\n",
    "        'Risk skoru v2 (risk_score ile korele, elenecek)',\n",
    "        'Ödeme davranışı (payment_score ile korele)',\n",
    "        'Zamanla değişen özellik (PSI ile elenecek)',\n",
    "        'Sabit özellik (PSI testini geçecek)',\n",
    "        'Gürültü değişkeni 1 (düşük IV, elenecek)',\n",
    "        'Gürültü değişkeni 2 (düşük IV, elenecek)',\n",
    "        'Risk kategorisi (risk_score ile türetilmiş)',\n",
    "        'Ürün tipi (nadir kategoriler içerir)',\n",
    "        'Bölge',\n",
    "        'Müşteri yaşı',\n",
    "        'Müşteri kıdemi (yıl)'\n",
    "    ]\n",
    "})\n",
    "print(f\"   Tanımlanan değişken: {len(data_dict)}\")\n",
    "print(\"\\n📋 Veri Sözlüğü:\")\n",
    "print(data_dict.head(5).to_string(index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Pipeline Konfigürasyonu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pipeline konfigürasyonu\n",
    "print(\"⚙️ Pipeline konfigürasyonu...\")\n",
    "\n",
    "cfg = Config(\n",
    "    # Temel ayarlar\n",
    "    id_col='app_id',\n",
    "    time_col='app_dt',\n",
    "    target_col='target',\n",
    "    \n",
    "    # Veri bölme\n",
    "    use_test_split=True,\n",
    "    test_size_row_frac=0.2,\n",
    "    oot_window_months=4,  # Son 4 ay OOT\n",
    "    \n",
    "    # Veri sözlüğü ve kalibrasyon\n",
    "    data_dictionary_df=data_dict,\n",
    "    calibration_df=cal_df,\n",
    "    calibration_method='isotonic',\n",
    "    \n",
    "    # Model ayarları\n",
    "    cv_folds=5,\n",
    "    random_state=2024,\n",
    "    n_jobs=2,\n",
    "    \n",
    "    # HPO ayarları (hızlı demo için)\n",
    "    hpo_timeout_sec=20,\n",
    "    hpo_trials=10,\n",
    "    \n",
    "    # Feature engineering eşikleri\n",
    "    rare_threshold=0.01,      # %1'den az (Rare1, Rare2 elenecek)\n",
    "    psi_threshold=0.20,       # PSI > 0.20 (drift_feature elenecek)\n",
    "    iv_min=0.02,             # IV < 0.02 (noise değişkenler elenecek)\n",
    "    rho_threshold=0.95,      # Korelasyon > 0.95 (risk_score_v2 elenecek)\n",
    "    \n",
    "    # Çıktılar\n",
    "    output_folder='outputs_realistic_gini',\n",
    "    output_excel_path='realistic_gini_report.xlsx',\n",
    "    log_file='outputs_realistic_gini/pipeline.log',\n",
    "    write_parquet=False,\n",
    "    write_csv=False\n",
    ")\n",
    "\n",
    "print(\"✅ Konfigürasyon hazır!\")\n",
    "print(f\"\\n📋 Filtreleme Eşikleri:\")\n",
    "print(f\"   PSI eşiği: {cfg.psi_threshold}\")\n",
    "print(f\"   IV minimum: {cfg.iv_min}\")\n",
    "print(f\"   Korelasyon eşiği: {cfg.rho_threshold}\")\n",
    "print(f\"   Nadir kategori eşiği: %{cfg.rare_threshold*100}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Pipeline Çalıştırma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pipeline çalıştır\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"🚀 PIPELINE ÇALIŞTIRILIYOR...\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "pipeline = RiskModelPipeline(cfg)\n",
    "pipeline.run(df)\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"✅ PIPELINE TAMAMLANDI!\")\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Pipeline Sonuçları ve Analiz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sonuçları analiz et\n",
    "print(\"\\n📊 PIPELINE SONUÇLARI\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "if pipeline.best_model_name_:\n",
    "    print(f\"\\n✅ EN İYİ MODEL: {pipeline.best_model_name_}\")\n",
    "    print(f\"✅ FİNAL DEĞİŞKEN SAYISI: {len(pipeline.final_vars_)}\")\n",
    "    \n",
    "    # Final değişkenler\n",
    "    if pipeline.final_vars_:\n",
    "        print(f\"\\n📋 Final Değişkenler:\")\n",
    "        for i, var in enumerate(pipeline.final_vars_, 1):\n",
    "            desc = data_dict[data_dict['alan_adi'] == var]['alan_aciklamasi'].values\n",
    "            desc_str = desc[0] if len(desc) > 0 else \"Açıklama yok\"\n",
    "            print(f\"  {i}. {var}: {desc_str}\")\n",
    "    \n",
    "    # Model performansı\n",
    "    if pipeline.models_summary_ is not None and not pipeline.models_summary_.empty:\n",
    "        best = pipeline.models_summary_[pipeline.models_summary_['model_name'] == pipeline.best_model_name_].iloc[0]\n",
    "        \n",
    "        print(f\"\\n📈 MODEL PERFORMANSI:\")\n",
    "        \n",
    "        # OOT Performans (en önemli)\n",
    "        if 'AUC_OOT' in best and best.get('AUC_OOT'):\n",
    "            auc_oot = best.get('AUC_OOT')\n",
    "            gini_oot = best.get('Gini_OOT')\n",
    "            ks_oot = best.get('KS_OOT')\n",
    "            \n",
    "            print(f\"\\n  OUT-OF-TIME (OOT):\")\n",
    "            print(f\"    AUC: {auc_oot:.3f}\")\n",
    "            print(f\"    GINI: {gini_oot:.3f} ({gini_oot*100:.1f}%)\")\n",
    "            print(f\"    KS: {ks_oot:.3f}\")\n",
    "            \n",
    "            if 0.70 <= gini_oot <= 0.80:\n",
    "                print(f\"\\n    🎯 HEDEF BAŞARILI: OOT Gini %70-80 aralığında ({gini_oot*100:.1f}%)\")\n",
    "            elif gini_oot >= 0.70:\n",
    "                print(f\"\\n    ✅ İYİ: OOT Gini %70+ ({gini_oot*100:.1f}%)\")\n",
    "            else:\n",
    "                print(f\"\\n    ⚠️ OOT Gini hedefin altında: {gini_oot*100:.1f}%\")\n",
    "else:\n",
    "    print(\"⚠️ UYARI: Model seçilemedi!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filtreleme detayları\n",
    "print(\"\\n📊 FİLTRELEME DETAYLARI\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# PSI analizi\n",
    "if hasattr(pipeline, 'psi_df_') and pipeline.psi_df_ is not None:\n",
    "    print(\"\\n🔄 PSI FİLTRESİ:\")\n",
    "    high_psi = pipeline.psi_df_[pipeline.psi_df_['PSI'] > cfg.psi_threshold]\n",
    "    if not high_psi.empty:\n",
    "        print(f\"  Elenen değişkenler (PSI > {cfg.psi_threshold}):\")\n",
    "        for _, row in high_psi.iterrows():\n",
    "            print(f\"    - {row['variable']}: PSI={row['PSI']:.3f}\")\n",
    "    else:\n",
    "        print(f\"  Tüm değişkenler PSI < {cfg.psi_threshold}\")\n",
    "\n",
    "# Korelasyon analizi\n",
    "if hasattr(pipeline, 'corr_dropped_') and pipeline.corr_dropped_:\n",
    "    print(\"\\n🔗 KORELASYON FİLTRESİ:\")\n",
    "    print(f\"  Elenen değişkenler (corr > {cfg.rho_threshold}):\")\n",
    "    for item in pipeline.corr_dropped_:\n",
    "        dropped = item.get('dropped', 'N/A')\n",
    "        kept = item.get('kept', 'N/A')\n",
    "        corr = item.get('corr', 0)\n",
    "        print(f\"    - {dropped} elendi (corr={corr:.3f} with {kept})\")\n",
    "\n",
    "# IV analizi\n",
    "if hasattr(pipeline, 'iv_filter_log_') and pipeline.iv_filter_log_:\n",
    "    low_iv_vars = [item for item in pipeline.iv_filter_log_ \n",
    "                   if item.get('reason', '').startswith('Low IV')]\n",
    "    if low_iv_vars:\n",
    "        print(\"\\n📊 IV FİLTRESİ:\")\n",
    "        print(f\"  Elenen değişkenler (IV < {cfg.iv_min}):\")\n",
    "        for item in low_iv_vars:\n",
    "            var = item.get('variable', 'N/A')\n",
    "            iv = item.get('iv', 0)\n",
    "            print(f\"    - {var}: IV={iv:.4f}\")\n",
    "\n",
    "print(\"\\n🏷️ NADİR KATEGORİ FİLTRESİ:\")\n",
    "print(f\"  Eşik: %{cfg.rare_threshold*100}\")\n",
    "print(f\"  Muhtemel elenen kategoriler: Rare1, Rare2 (product_type değişkeninde)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Excel Raporu Kontrolü"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Excel raporu kontrolü\n",
    "import os\n",
    "\n",
    "excel_path = os.path.join(cfg.output_folder, cfg.output_excel_path)\n",
    "if os.path.exists(excel_path):\n",
    "    print(f\"📁 Excel raporu oluşturuldu: {excel_path}\")\n",
    "    \n",
    "    excel_file = pd.ExcelFile(excel_path)\n",
    "    print(f\"\\n📋 Sheets ({len(excel_file.sheet_names)} adet):\")\n",
    "    for i, sheet in enumerate(excel_file.sheet_names[:10], 1):  # İlk 10 sheet\n",
    "        print(f\"  {i:2}. {sheet}\")\n",
    "    \n",
    "    # Model summary\n",
    "    if 'models_summary' in excel_file.sheet_names:\n",
    "        models_df = pd.read_excel(excel_path, sheet_name='models_summary')\n",
    "        print(f\"\\n📊 MODEL KARŞILAŞTIRMASI:\")\n",
    "        \n",
    "        # Select available columns\n",
    "        display_cols = ['model_name', 'Gini_train', 'Gini_test', 'Gini_OOT']\n",
    "        available_cols = [col for col in display_cols if col in models_df.columns]\n",
    "        \n",
    "        if available_cols:\n",
    "            print(models_df[available_cols].to_string(index=False))\n",
    "else:\n",
    "    print(f\"⚠️ Excel raporu bulunamadı: {excel_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Özet ve Sonuçlar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"📊 TEST ÖZET\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "print(\"\\n✅ TEST EDİLEN PIPELINE ADIMLARI:\")\n",
    "print(\"  1. Veri validasyon ve hazırlama\")\n",
    "print(\"  2. WOE binning ve transformation\")\n",
    "print(\"  3. PSI hesaplama ve filtreleme\")\n",
    "print(\"  4. IV hesaplama ve düşük bilgili değişkenleri eleme\")\n",
    "print(\"  5. Korelasyon analizi ve yüksek koreleli değişkenleri eleme\")\n",
    "print(\"  6. Nadir kategorileri birleştirme\")\n",
    "print(\"  7. Feature selection (Boruta + Forward Selection)\")\n",
    "print(\"  8. Model training (6 algoritma)\")\n",
    "print(\"  9. Model evaluation ve en iyi model seçimi\")\n",
    "print(\" 10. Kalibrasyon (isotonic)\")\n",
    "print(\" 11. Raporlama ve Excel export\")\n",
    "\n",
    "print(\"\\n📈 HEDEF PERFORMANS:\")\n",
    "print(f\"  Hedef Gini aralığı: %70-80\")\n",
    "print(f\"  Baseline Gini (Logistic Regression): {gini*100:.1f}%\")\n",
    "\n",
    "if pipeline.best_model_name_ and pipeline.models_summary_ is not None:\n",
    "    best = pipeline.models_summary_[pipeline.models_summary_['model_name'] == pipeline.best_model_name_].iloc[0]\n",
    "    if 'Gini_OOT' in best and best.get('Gini_OOT'):\n",
    "        gini_oot = best.get('Gini_OOT')\n",
    "        print(f\"  Pipeline OOT Gini: {gini_oot*100:.1f}%\")\n",
    "        \n",
    "        if 0.70 <= gini_oot <= 0.80:\n",
    "            print(\"\\n🎯 BAŞARILI: Gerçekçi Gini hedefi sağlandı (%70-80)\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"✅ TEST TAMAMLANDI!\")\n",
    "print(\"=\"*80)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}