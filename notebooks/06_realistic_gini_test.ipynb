{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Risk Model Pipeline - Gerçekçi Gini Testi (%70-80)\n",
    "\n",
    "Bu notebook:\n",
    "- Gerçekçi %70-80 Gini aralığında sentetik veri oluşturur\n",
    "- Pipeline'ın tüm adımlarını test eder\n",
    "- Filtreleme mekanizmalarının çalıştığını gösterir"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup ve Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pygam\n",
      "  Using cached pygam-0.10.1-py3-none-any.whl (80 kB)\n",
      "Requirement already satisfied: numpy>=1.5.0 in c:\\users\\acer\\anaconda3\\lib\\site-packages (from pygam) (1.21.5)\n",
      "Collecting progressbar2<5,>=4.2.0\n",
      "  Using cached progressbar2-4.5.0-py3-none-any.whl (57 kB)\n",
      "Collecting scipy<1.17,>=1.11.1\n",
      "  Downloading scipy-1.13.1-cp39-cp39-win_amd64.whl (46.2 MB)\n",
      "     --------------------------------------- 46.2/46.2 MB 12.3 MB/s eta 0:00:00\n",
      "Collecting python-utils>=3.8.1\n",
      "  Using cached python_utils-3.9.1-py2.py3-none-any.whl (32 kB)\n",
      "Collecting numpy>=1.5.0\n",
      "  Downloading numpy-2.0.2-cp39-cp39-win_amd64.whl (15.9 MB)\n",
      "     --------------------------------------- 15.9/15.9 MB 13.4 MB/s eta 0:00:00\n",
      "Requirement already satisfied: typing_extensions>3.10.0.2 in c:\\users\\acer\\anaconda3\\lib\\site-packages (from python-utils>=3.8.1->progressbar2<5,>=4.2.0->pygam) (4.14.1)\n",
      "Installing collected packages: python-utils, numpy, scipy, progressbar2, pygam\n",
      "  Attempting uninstall: numpy\n",
      "    Found existing installation: numpy 1.21.5\n",
      "    Uninstalling numpy-1.21.5:\n",
      "      Successfully uninstalled numpy-1.21.5\n",
      "  Attempting uninstall: scipy\n",
      "    Found existing installation: scipy 1.9.1\n",
      "    Uninstalling scipy-1.9.1:\n",
      "      Successfully uninstalled scipy-1.9.1\n",
      "Successfully installed numpy-2.0.2 progressbar2-4.5.0 pygam-0.10.1 python-utils-3.9.1 scipy-1.13.1\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "daal4py 2021.6.0 requires daal==2021.4.0, which is not installed.\n",
      "numba 0.55.1 requires numpy<1.22,>=1.18, but you have numpy 2.0.2 which is incompatible.\n"
     ]
    }
   ],
   "source": [
    "pip install pygam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Setup complete!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "import sys\n",
    "import os\n",
    "from datetime import datetime\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Add parent directory to path\n",
    "sys.path.append('..')\n",
    "from src.risk_pipeline.pipeline16 import RiskModelPipeline, Config\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "np.random.seed(2024)\n",
    "\n",
    "print(\"✅ Setup complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "# Pipeline konfigürasyonu\nprint(\"⚙️ Pipeline konfigürasyonu...\")\n\ncfg = Config(\n    # Temel ayarlar\n    id_col='app_id',\n    time_col='app_dt',\n    target_col='target',\n    \n    # Veri bölme\n    use_test_split=True,\n    test_size_row_frac=0.2,\n    oot_window_months=4,  # Son 4 ay OOT\n    \n    # Veri sözlüğü ve kalibrasyon\n    data_dictionary_df=data_dict,\n    calibration_df=cal_df,\n    calibration_method='isotonic',\n    \n    # Model ayarları\n    cv_folds=5,\n    random_state=2024,\n    n_jobs=2,\n    \n    # HPO ayarları (hızlı demo için)\n    hpo_timeout_sec=20,\n    hpo_trials=10,\n    \n    # Feature engineering eşikleri (DAHA AZ AGRESİF)\n    rare_threshold=0.005,     # %0.5'ten az (sadece çok nadir kategoriler)\n    psi_threshold=0.30,       # PSI > 0.30 (daha toleranslı)\n    iv_min=0.01,             # IV < 0.01 (sadece çok düşük IV elenecek)\n    rho_threshold=0.98,      # Korelasyon > 0.98 (neredeyse aynı değişkenler)\n    \n    # Çıktılar\n    output_folder='outputs_realistic_gini',\n    output_excel_path='realistic_gini_report.xlsx',\n    log_file='outputs_realistic_gini/pipeline.log',\n    write_parquet=False,\n    write_csv=False\n)\n\nprint(\"✅ Konfigürasyon hazır!\")\nprint(f\"\\n📋 Filtreleme Eşikleri (DAHA AZ AGRESİF):\")\nprint(f\"   PSI eşiği: {cfg.psi_threshold} (önceki: 0.20)\")\nprint(f\"   IV minimum: {cfg.iv_min} (önceki: 0.02)\")\nprint(f\"   Korelasyon eşiği: {cfg.rho_threshold} (önceki: 0.95)\")\nprint(f\"   Nadir kategori eşiği: %{cfg.rare_threshold*100} (önceki: %1)\")"
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📊 Gerçekçi sentetik veri oluşturuluyor...\n",
      "✅ Veri oluşturuldu: (5000, 19)\n",
      "   Target oranı: 50.0%\n",
      "   Değişken sayısı: 16\n"
     ]
    }
   ],
   "source": [
    "def create_realistic_credit_data(n_samples=5000):\n",
    "    \"\"\"\n",
    "    Gerçekçi kredi riski verisi - %70-80 Gini hedefli\n",
    "    \n",
    "    Özellikler:\n",
    "    - Güçlü tahmin ediciler (risk_score, payment_score, vb.)\n",
    "    - Korele değişkenler (korelasyon testi için)\n",
    "    - Drift eden değişkenler (PSI testi için)\n",
    "    - Düşük bilgi değerli değişkenler (IV testi için)\n",
    "    - Nadir kategoriler (rare threshold testi için)\n",
    "    \"\"\"\n",
    "    \n",
    "    # 1. GÜÇLÜ TAHMİN EDİCİLER (Yüksek IV)\n",
    "    risk_score = np.random.beta(2, 5, n_samples)  # Ana risk skoru\n",
    "    payment_score = np.random.beta(3, 7, n_samples)  # Ödeme geçmişi\n",
    "    debt_burden = np.random.beta(2, 8, n_samples)  # Borç yükü\n",
    "    income_stability = np.random.beta(4, 6, n_samples)  # Gelir istikrarı\n",
    "    employment_score = np.random.beta(5, 5, n_samples)  # İstihdam skoru\n",
    "    \n",
    "    # 2. KORELE DEĞİŞKENLER (Korelasyon testi için)\n",
    "    # risk_score ile yüksek korele (>0.95)\n",
    "    risk_score_v2 = risk_score + np.random.normal(0, 0.05, n_samples)\n",
    "    risk_score_v2 = np.clip(risk_score_v2, 0, 1)\n",
    "    \n",
    "    # payment_score ile korele (>0.90)\n",
    "    payment_behavior = payment_score * 0.9 + np.random.normal(0, 0.05, n_samples)\n",
    "    payment_behavior = np.clip(payment_behavior, 0, 1)\n",
    "    \n",
    "    # 3. DRIFT EDEN DEĞİŞKEN (PSI testi için)\n",
    "    time_index = np.arange(n_samples) / n_samples\n",
    "    drift_feature = np.random.normal(0.3 + 0.4 * time_index, 0.1, n_samples)\n",
    "    \n",
    "    # 4. STABIL DEĞİŞKEN (PSI geçecek)\n",
    "    stable_feature = np.random.normal(0.5, 0.15, n_samples)\n",
    "    \n",
    "    # 5. DÜŞÜK BİLGİ DEĞERLİ DEĞİŞKENLER (IV < 0.02, elenecek)\n",
    "    noise_feature1 = np.random.randn(n_samples)\n",
    "    noise_feature2 = np.random.uniform(0, 1, n_samples)\n",
    "    \n",
    "    # 6. KATEGORİK DEĞİŞKENLER\n",
    "    # Güçlü kategorik (risk_score ile ilişkili)\n",
    "    risk_category = pd.cut(risk_score, bins=4, \n",
    "                           labels=['Very_Low', 'Low', 'Medium', 'High'])\n",
    "    \n",
    "    # Nadir kategoriler içeren (rare threshold testi için)\n",
    "    product_type = np.random.choice(\n",
    "        ['Standard', 'Premium', 'Basic', 'Rare1', 'Rare2'], \n",
    "        n_samples,\n",
    "        p=[0.4, 0.3, 0.28, 0.015, 0.005]  # Rare1 ve Rare2 %1'den az\n",
    "    )\n",
    "    \n",
    "    region = np.random.choice(['North', 'South', 'East', 'West'], \n",
    "                              n_samples, p=[0.25, 0.25, 0.25, 0.25])\n",
    "    \n",
    "    # 7. TARGET OLUŞTURMA (Gerçekçi %70-80 Gini için)\n",
    "    default_score = (\n",
    "        3.5 * risk_score +           # En güçlü tahmin edici\n",
    "        3.0 * payment_score +         # İkinci güçlü\n",
    "        2.0 * debt_burden +           # Orta güçlü\n",
    "        1.2 * (1 - income_stability) + # Orta etki\n",
    "        1.0 * (1 - employment_score) + # Orta etki\n",
    "        np.random.normal(0, 0.6, n_samples)  # Optimal gürültü\n",
    "    )\n",
    "    \n",
    "    # Target (threshold ile binary)\n",
    "    threshold = np.percentile(default_score, 50)  # %50 default rate\n",
    "    target = (default_score > threshold).astype(int)\n",
    "    \n",
    "    # 8. DEMOGRAFİK ÖZELLİKLER\n",
    "    age = np.random.normal(40, 12, n_samples).clip(18, 70)\n",
    "    tenure = np.random.exponential(5, n_samples).clip(0, 30)\n",
    "    \n",
    "    # DataFrame oluştur\n",
    "    df = pd.DataFrame({\n",
    "        'app_id': [f'APP_{i:08d}' for i in range(n_samples)],\n",
    "        'app_dt': pd.date_range('2022-01-01', periods=n_samples, freq='6H'),\n",
    "        'target': target,\n",
    "        \n",
    "        # Güçlü tahmin ediciler\n",
    "        'risk_score': risk_score,\n",
    "        'payment_score': payment_score,\n",
    "        'debt_burden': debt_burden,\n",
    "        'income_stability': income_stability,\n",
    "        'employment_score': employment_score,\n",
    "        \n",
    "        # Korele değişkenler\n",
    "        'risk_score_v2': risk_score_v2,\n",
    "        'payment_behavior': payment_behavior,\n",
    "        \n",
    "        # PSI test değişkenleri\n",
    "        'drift_feature': drift_feature,\n",
    "        'stable_feature': stable_feature,\n",
    "        \n",
    "        # Düşük IV değişkenler\n",
    "        'noise_feature1': noise_feature1,\n",
    "        'noise_feature2': noise_feature2,\n",
    "        \n",
    "        # Kategorik değişkenler\n",
    "        'risk_category': risk_category,\n",
    "        'product_type': product_type,\n",
    "        'region': region,\n",
    "        \n",
    "        # Demografik\n",
    "        'age': age,\n",
    "        'tenure': tenure\n",
    "    })\n",
    "    \n",
    "    # Eksik değerler ekle (gerçekçilik için, %2-3)\n",
    "    missing_cols = ['employment_score', 'tenure']\n",
    "    for col in missing_cols:\n",
    "        missing_idx = np.random.choice(df.index, size=int(0.02 * len(df)), replace=False)\n",
    "        df.loc[missing_idx, col] = np.nan\n",
    "    \n",
    "    return df\n",
    "\n",
    "# Veri oluştur\n",
    "print(\"📊 Gerçekçi sentetik veri oluşturuluyor...\")\n",
    "df = create_realistic_credit_data(5000)\n",
    "print(f\"✅ Veri oluşturuldu: {df.shape}\")\n",
    "print(f\"   Target oranı: {df['target'].mean():.1%}\")\n",
    "print(f\"   Değişken sayısı: {df.shape[1] - 3}\")  # id, date, target hariç"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Baseline Performans Testi (Logistic Regression)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔬 Baseline Logistic Regression ile Gini testi...\n",
      "\n",
      "📊 BASELINE PERFORMANS:\n",
      "   AUC: 0.876\n",
      "   GINI: 0.752 (75.2%)\n",
      "\n",
      "✅ MÜKEMMEL: Gini hedef aralıkta (%70-80)\n",
      "\n",
      "📊 Değişken Önemleri (Logistic Regression Coefficients):\n",
      "         feature  coefficient\n",
      "      risk_score     8.663711\n",
      "   payment_score     7.743205\n",
      "     debt_burden     4.594925\n",
      "employment_score    -2.212899\n",
      "income_stability    -2.909652\n"
     ]
    }
   ],
   "source": [
    "# Baseline performans testi\n",
    "print(\"🔬 Baseline Logistic Regression ile Gini testi...\")\n",
    "\n",
    "# Güçlü değişkenlerle model\n",
    "strong_features = ['risk_score', 'payment_score', 'debt_burden', \n",
    "                  'income_stability', 'employment_score']\n",
    "\n",
    "# Train/test split\n",
    "X = df[strong_features].fillna(df[strong_features].median())\n",
    "y = df['target']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.3, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "# Logistic Regression\n",
    "lr = LogisticRegression(random_state=42, max_iter=1000)\n",
    "lr.fit(X_train, y_train)\n",
    "\n",
    "# Predictions\n",
    "y_pred_proba = lr.predict_proba(X_test)[:, 1]\n",
    "\n",
    "# Performance\n",
    "auc = roc_auc_score(y_test, y_pred_proba)\n",
    "gini = 2 * auc - 1\n",
    "\n",
    "print(f\"\\n📊 BASELINE PERFORMANS:\")\n",
    "print(f\"   AUC: {auc:.3f}\")\n",
    "print(f\"   GINI: {gini:.3f} ({gini*100:.1f}%)\")\n",
    "\n",
    "if 0.70 <= gini <= 0.80:\n",
    "    print(f\"\\n✅ MÜKEMMEL: Gini hedef aralıkta (%70-80)\")\n",
    "elif gini >= 0.70:\n",
    "    print(f\"\\n✅ İYİ: Gini %70+ ({gini*100:.1f}%)\")\n",
    "else:\n",
    "    print(f\"\\n⚠️ Gini hedefin altında: {gini*100:.1f}%\")\n",
    "\n",
    "# Feature importance\n",
    "print(\"\\n📊 Değişken Önemleri (Logistic Regression Coefficients):\")\n",
    "feature_importance = pd.DataFrame({\n",
    "    'feature': strong_features,\n",
    "    'coefficient': lr.coef_[0]\n",
    "}).sort_values('coefficient', ascending=False)\n",
    "print(feature_importance.to_string(index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Kalibrasyon Verisi ve Veri Sözlüğü"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📊 Kalibrasyon verisi hazırlanıyor...\n",
      "   Kalibrasyon boyutu: (1000, 19)\n",
      "   Kalibrasyon target oranı: 50.0%\n",
      "\n",
      "📚 Veri sözlüğü hazırlanıyor...\n",
      "   Tanımlanan değişken: 16\n",
      "\n",
      "📋 Veri Sözlüğü:\n",
      "        alan_adi                           alan_aciklamasi\n",
      "      risk_score       Ana risk skoru (0-1, yüksek=riskli)\n",
      "   payment_score     Ödeme geçmişi skoru (0-1, yüksek=iyi)\n",
      "     debt_burden Borç yükü göstergesi (0-1, yüksek=borçlu)\n",
      "income_stability  Gelir istikrarı (0-1, yüksek=istikrarlı)\n",
      "employment_score      İstihdam skoru (0-1, yüksek=güvenli)\n"
     ]
    }
   ],
   "source": [
    "# Kalibrasyon verisi\n",
    "print(\"📊 Kalibrasyon verisi hazırlanıyor...\")\n",
    "cal_df = create_realistic_credit_data(1000)\n",
    "print(f\"   Kalibrasyon boyutu: {cal_df.shape}\")\n",
    "print(f\"   Kalibrasyon target oranı: {cal_df['target'].mean():.1%}\")\n",
    "\n",
    "# Veri sözlüğü\n",
    "print(\"\\n📚 Veri sözlüğü hazırlanıyor...\")\n",
    "data_dict = pd.DataFrame({\n",
    "    'alan_adi': [\n",
    "        'risk_score', 'payment_score', 'debt_burden', 'income_stability', \n",
    "        'employment_score', 'risk_score_v2', 'payment_behavior',\n",
    "        'drift_feature', 'stable_feature', 'noise_feature1', 'noise_feature2',\n",
    "        'risk_category', 'product_type', 'region', 'age', 'tenure'\n",
    "    ],\n",
    "    'alan_aciklamasi': [\n",
    "        'Ana risk skoru (0-1, yüksek=riskli)',\n",
    "        'Ödeme geçmişi skoru (0-1, yüksek=iyi)',\n",
    "        'Borç yükü göstergesi (0-1, yüksek=borçlu)',\n",
    "        'Gelir istikrarı (0-1, yüksek=istikrarlı)',\n",
    "        'İstihdam skoru (0-1, yüksek=güvenli)',\n",
    "        'Risk skoru v2 (risk_score ile korele, elenecek)',\n",
    "        'Ödeme davranışı (payment_score ile korele)',\n",
    "        'Zamanla değişen özellik (PSI ile elenecek)',\n",
    "        'Sabit özellik (PSI testini geçecek)',\n",
    "        'Gürültü değişkeni 1 (düşük IV, elenecek)',\n",
    "        'Gürültü değişkeni 2 (düşük IV, elenecek)',\n",
    "        'Risk kategorisi (risk_score ile türetilmiş)',\n",
    "        'Ürün tipi (nadir kategoriler içerir)',\n",
    "        'Bölge',\n",
    "        'Müşteri yaşı',\n",
    "        'Müşteri kıdemi (yıl)'\n",
    "    ]\n",
    "})\n",
    "print(f\"   Tanımlanan değişken: {len(data_dict)}\")\n",
    "print(\"\\n📋 Veri Sözlüğü:\")\n",
    "print(data_dict.head(5).to_string(index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Pipeline Konfigürasyonu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚙️ Pipeline konfigürasyonu...\n",
      "✅ Konfigürasyon hazır!\n",
      "\n",
      "📋 Filtreleme Eşikleri:\n",
      "   PSI eşiği: 0.2\n",
      "   IV minimum: 0.02\n",
      "   Korelasyon eşiği: 0.95\n",
      "   Nadir kategori eşiği: %1.0\n"
     ]
    }
   ],
   "source": [
    "# Pipeline konfigürasyonu\n",
    "print(\"⚙️ Pipeline konfigürasyonu...\")\n",
    "\n",
    "cfg = Config(\n",
    "    # Temel ayarlar\n",
    "    id_col='app_id',\n",
    "    time_col='app_dt',\n",
    "    target_col='target',\n",
    "    \n",
    "    # Veri bölme\n",
    "    use_test_split=True,\n",
    "    test_size_row_frac=0.2,\n",
    "    oot_window_months=4,  # Son 4 ay OOT\n",
    "    \n",
    "    # Veri sözlüğü ve kalibrasyon\n",
    "    data_dictionary_df=data_dict,\n",
    "    calibration_df=cal_df,\n",
    "    calibration_method='isotonic',\n",
    "    \n",
    "    # Model ayarları\n",
    "    cv_folds=5,\n",
    "    random_state=2024,\n",
    "    n_jobs=2,\n",
    "    \n",
    "    # HPO ayarları (hızlı demo için)\n",
    "    hpo_timeout_sec=20,\n",
    "    hpo_trials=10,\n",
    "    \n",
    "    # Feature engineering eşikleri\n",
    "    rare_threshold=0.01,      # %1'den az (Rare1, Rare2 elenecek)\n",
    "    psi_threshold=0.20,       # PSI > 0.20 (drift_feature elenecek)\n",
    "    iv_min=0.02,             # IV < 0.02 (noise değişkenler elenecek)\n",
    "    rho_threshold=0.95,      # Korelasyon > 0.95 (risk_score_v2 elenecek)\n",
    "    \n",
    "    # Çıktılar\n",
    "    output_folder='outputs_realistic_gini',\n",
    "    output_excel_path='realistic_gini_report.xlsx',\n",
    "    log_file='outputs_realistic_gini/pipeline.log',\n",
    "    write_parquet=False,\n",
    "    write_csv=False\n",
    ")\n",
    "\n",
    "print(\"✅ Konfigürasyon hazır!\")\n",
    "print(f\"\\n📋 Filtreleme Eşikleri:\")\n",
    "print(f\"   PSI eşiği: {cfg.psi_threshold}\")\n",
    "print(f\"   IV minimum: {cfg.iv_min}\")\n",
    "print(f\"   Korelasyon eşiği: {cfg.rho_threshold}\")\n",
    "print(f\"   Nadir kategori eşiği: %{cfg.rare_threshold*100}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Pipeline Çalıştırma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "🚀 PIPELINE ÇALIŞTIRILIYOR...\n",
      "============================================================\n",
      "[20:35:51] >> 2) Giris dogrulama & sabitleme basliyor | CPU=6% RAM=44%\n",
      "[20:35:51] â--  2) Giris dogrulama & sabitleme bitti (0.13s) â€” OK | CPU=2% RAM=44%\n",
      "[20:35:51] >> 3) Degisken siniflamasi basliyor | CPU=1% RAM=44%\n",
      "   - numeric=13, categorical=4\n",
      "[20:35:51] â--  3) Degisken siniflamasi bitti (0.11s) â€” OK | CPU=5% RAM=44%\n",
      "[20:35:51] >> 4) Eksik & Nadir deger politikasi basliyor | CPU=1% RAM=44%\n",
      "[20:35:51] â--  4) Eksik & Nadir deger politikasi bitti (0.11s) â€” OK | CPU=1% RAM=44%\n",
      "[20:35:51] >> 5) Zaman bolmesi (Train/Test/OOT) basliyor | CPU=0% RAM=44%\n",
      "   - Train=3696, Test=924, OOT=380\n",
      "[20:35:52] â--  5) Zaman bolmesi (Train/Test/OOT) bitti (0.54s) â€” OK | CPU=1% RAM=44%\n",
      "[20:35:52] >> 6) WOE binleme (yalniz Train; adaptif) basliyor | CPU=4% RAM=44%\n",
      "   - WOE hazir: 17 degisken\n",
      "   - Not: WOE haritasi SADECE TRAIN'de ogrenildi; TEST/OOT icin ayni harita uygulanir (leakage yok)\n",
      "[20:35:52] â--  6) WOE binleme (yalniz Train; adaptif) bitti (0.20s) â€” OK | CPU=2% RAM=44%\n",
      "[20:35:52] >> 7) PSI (vektorize) basliyor | CPU=2% RAM=44%\n",
      "   * PSI özet: KEEP=15 | DROP=2 | WARN=0\n",
      "   - PSI sonrasi kalan: 15\n",
      "[20:35:53] â--  7) PSI (vektorize) bitti (0.71s) â€” OK | CPU=1% RAM=44%\n",
      "   - High IV flags: risk_category,risk_score,risk_score_v2\n",
      "[20:35:53] >> 8) WOE transform (Train/Test/OOT) basliyor | CPU=7% RAM=44%\n",
      "   - X_train=(3696, 8), X_test=(924, 8), X_oot=(380, 8)\n",
      "[20:35:53] â--  8) WOE transform (Train/Test/OOT) bitti (0.14s) â€” OK | CPU=2% RAM=44%\n",
      "[20:35:53] >> 9) Korelasyon & cluster basliyor | CPU=3% RAM=44%\n",
      "   - cluster temsilcisi=7\n",
      "[20:35:53] â--  9) Korelasyon & cluster bitti (0.17s) â€” OK | CPU=3% RAM=44%\n",
      "[20:35:54] >> 10) Feature selection (Forward+1SE) basliyor | CPU=2% RAM=44%\n",
      "   - Boruta: 8/8 kaldi\n",
      "   - Forward+1SE secti: 3\n",
      "   - baseline degisken=3\n",
      "[20:35:57] â--  10) Feature selection (Forward+1SE) bitti (3.07s) â€” OK | CPU=8% RAM=44%\n",
      "[20:35:57] >> 11) Nihai korelasyon filtresi basliyor | CPU=4% RAM=44%\n",
      "   - corr sonrasi=3\n",
      "[20:35:57] â--  11) Nihai korelasyon filtresi bitti (0.16s) â€” OK | CPU=1% RAM=44%\n",
      "[20:35:57] >> 12) Gurultu (noise) sentineli basliyor | CPU=0% RAM=44%\n",
      "   - final degisken=2\n",
      "[20:35:58] â--  12) Gurultu (noise) sentineli bitti (0.58s) â€” OK | CPU=1% RAM=44%\n",
      "[20:35:58] >> 13) Modelleme & degerlendirme basliyor | CPU=0% RAM=44%\n",
      "[20:35:58]   - Logit_L2 tuning | CPU=1% RAM=44%\n",
      "[20:35:58]   - Logit_L2 CV basliyor | CPU=4% RAM=44%\n",
      "[20:35:58]   - RandomForest tuning | CPU=2% RAM=44%\n",
      "[20:36:23]   - RandomForest CV basliyor | CPU=0% RAM=44%\n",
      "[20:36:37]   - ExtraTrees tuning | CPU=1% RAM=44%\n",
      "[20:36:58]   - ExtraTrees CV basliyor | CPU=2% RAM=44%\n",
      "[20:37:07]   - XGBoost tuning | CPU=9% RAM=44%\n",
      "[20:37:14]   - XGBoost CV basliyor | CPU=57% RAM=45%\n",
      "[20:37:15]   - LightGBM tuning | CPU=7% RAM=45%\n",
      "[20:37:27]   - LightGBM CV basliyor | CPU=5% RAM=45%\n",
      "[20:37:29]   - GAM tuning | CPU=6% RAM=45%\n",
      "[20:37:31]   - GAM CV basliyor | CPU=4% RAM=45%\n",
      "[20:37:31] â--  13) Modelleme & degerlendirme bitti (93.70s) â€” OK | CPU=2% RAM=45%\n",
      "[20:37:31] >> 14) En iyi model secimi basliyor | CPU=2% RAM=45%\n",
      "   - best=ExtraTrees\n",
      "[20:37:32] â--  14) En iyi model secimi bitti (0.11s) â€” OK | CPU=2% RAM=45%\n",
      "[20:37:32] >> 14b) Kalibrasyon basliyor | CPU=2% RAM=45%\n",
      "   - Using calibration DataFrame: (1000, 19)\n",
      "   - calibration data overlaps with train/test/oot; skipping calibration\n",
      "[20:37:32] â--  14b) Kalibrasyon bitti (0.12s) â€” OK | CPU=1% RAM=45%\n",
      "[20:37:32] >> 15) Rapor tablolari basliyor | CPU=1% RAM=45%\n",
      "   - Data dictionary loaded from DataFrame: 16 variables\n",
      "   - Data dictionary loaded from DataFrame: 16 variables\n",
      "[20:37:33] â--  15) Rapor tablolari bitti (0.73s) â€” OK | CPU=3% RAM=45%\n",
      "[20:37:33] >> 15b) Export (Excel/Parquet) basliyor | CPU=2% RAM=45%\n",
      "[20:37:33] â--  15b) Export (Excel/Parquet) bitti (0.60s) â€” OK | CPU=1% RAM=45%\n",
      "[20:37:33] >> RUN tamam - run_id=20250903_203538_54e787bb | CPU=1% RAM=45%\n",
      "\n",
      "============================================================\n",
      "✅ PIPELINE TAMAMLANDI!\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "# Pipeline çalıştır\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"🚀 PIPELINE ÇALIŞTIRILIYOR...\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "pipeline = RiskModelPipeline(cfg)\n",
    "pipeline.run(df)\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"✅ PIPELINE TAMAMLANDI!\")\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Pipeline Sonuçları ve Analiz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "📊 PIPELINE SONUÇLARI\n",
      "============================================================\n",
      "\n",
      "✅ EN İYİ MODEL: ExtraTrees\n",
      "✅ FİNAL DEĞİŞKEN SAYISI: 2\n",
      "\n",
      "📋 Final Değişkenler:\n",
      "  1. risk_score: Ana risk skoru (0-1, yüksek=riskli)\n",
      "  2. payment_score: Ödeme geçmişi skoru (0-1, yüksek=iyi)\n",
      "\n",
      "📈 MODEL PERFORMANSI:\n",
      "\n",
      "  OUT-OF-TIME (OOT):\n",
      "    AUC: 0.794\n",
      "    GINI: 0.588 (58.8%)\n",
      "    KS: 0.460\n",
      "\n",
      "    ⚠️ OOT Gini hedefin altında: 58.8%\n"
     ]
    }
   ],
   "source": [
    "# Sonuçları analiz et\n",
    "print(\"\\n📊 PIPELINE SONUÇLARI\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "if pipeline.best_model_name_:\n",
    "    print(f\"\\n✅ EN İYİ MODEL: {pipeline.best_model_name_}\")\n",
    "    print(f\"✅ FİNAL DEĞİŞKEN SAYISI: {len(pipeline.final_vars_)}\")\n",
    "    \n",
    "    # Final değişkenler\n",
    "    if pipeline.final_vars_:\n",
    "        print(f\"\\n📋 Final Değişkenler:\")\n",
    "        for i, var in enumerate(pipeline.final_vars_, 1):\n",
    "            desc = data_dict[data_dict['alan_adi'] == var]['alan_aciklamasi'].values\n",
    "            desc_str = desc[0] if len(desc) > 0 else \"Açıklama yok\"\n",
    "            print(f\"  {i}. {var}: {desc_str}\")\n",
    "    \n",
    "    # Model performansı\n",
    "    if pipeline.models_summary_ is not None and not pipeline.models_summary_.empty:\n",
    "        best = pipeline.models_summary_[pipeline.models_summary_['model_name'] == pipeline.best_model_name_].iloc[0]\n",
    "        \n",
    "        print(f\"\\n📈 MODEL PERFORMANSI:\")\n",
    "        \n",
    "        # OOT Performans (en önemli)\n",
    "        if 'AUC_OOT' in best and best.get('AUC_OOT'):\n",
    "            auc_oot = best.get('AUC_OOT')\n",
    "            gini_oot = best.get('Gini_OOT')\n",
    "            ks_oot = best.get('KS_OOT')\n",
    "            \n",
    "            print(f\"\\n  OUT-OF-TIME (OOT):\")\n",
    "            print(f\"    AUC: {auc_oot:.3f}\")\n",
    "            print(f\"    GINI: {gini_oot:.3f} ({gini_oot*100:.1f}%)\")\n",
    "            print(f\"    KS: {ks_oot:.3f}\")\n",
    "            \n",
    "            if 0.70 <= gini_oot <= 0.80:\n",
    "                print(f\"\\n    🎯 HEDEF BAŞARILI: OOT Gini %70-80 aralığında ({gini_oot*100:.1f}%)\")\n",
    "            elif gini_oot >= 0.70:\n",
    "                print(f\"\\n    ✅ İYİ: OOT Gini %70+ ({gini_oot*100:.1f}%)\")\n",
    "            else:\n",
    "                print(f\"\\n    ⚠️ OOT Gini hedefin altında: {gini_oot*100:.1f}%\")\n",
    "else:\n",
    "    print(\"⚠️ UYARI: Model seçilemedi!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "📊 FİLTRELEME DETAYLARI\n",
      "============================================================\n",
      "\n",
      "🏷️ NADİR KATEGORİ FİLTRESİ:\n",
      "  Eşik: %1.0\n",
      "  Muhtemel elenen kategoriler: Rare1, Rare2 (product_type değişkeninde)\n"
     ]
    }
   ],
   "source": [
    "# Filtreleme detayları\n",
    "print(\"\\n📊 FİLTRELEME DETAYLARI\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# PSI analizi\n",
    "if hasattr(pipeline, 'psi_df_') and pipeline.psi_df_ is not None:\n",
    "    print(\"\\n🔄 PSI FİLTRESİ:\")\n",
    "    high_psi = pipeline.psi_df_[pipeline.psi_df_['PSI'] > cfg.psi_threshold]\n",
    "    if not high_psi.empty:\n",
    "        print(f\"  Elenen değişkenler (PSI > {cfg.psi_threshold}):\")\n",
    "        for _, row in high_psi.iterrows():\n",
    "            print(f\"    - {row['variable']}: PSI={row['PSI']:.3f}\")\n",
    "    else:\n",
    "        print(f\"  Tüm değişkenler PSI < {cfg.psi_threshold}\")\n",
    "\n",
    "# Korelasyon analizi\n",
    "if hasattr(pipeline, 'corr_dropped_') and pipeline.corr_dropped_:\n",
    "    print(\"\\n🔗 KORELASYON FİLTRESİ:\")\n",
    "    print(f\"  Elenen değişkenler (corr > {cfg.rho_threshold}):\")\n",
    "    for item in pipeline.corr_dropped_:\n",
    "        dropped = item.get('dropped', 'N/A')\n",
    "        kept = item.get('kept', 'N/A')\n",
    "        corr = item.get('corr', 0)\n",
    "        print(f\"    - {dropped} elendi (corr={corr:.3f} with {kept})\")\n",
    "\n",
    "# IV analizi\n",
    "if hasattr(pipeline, 'iv_filter_log_') and pipeline.iv_filter_log_:\n",
    "    low_iv_vars = [item for item in pipeline.iv_filter_log_ \n",
    "                   if item.get('reason', '').startswith('Low IV')]\n",
    "    if low_iv_vars:\n",
    "        print(\"\\n📊 IV FİLTRESİ:\")\n",
    "        print(f\"  Elenen değişkenler (IV < {cfg.iv_min}):\")\n",
    "        for item in low_iv_vars:\n",
    "            var = item.get('variable', 'N/A')\n",
    "            iv = item.get('iv', 0)\n",
    "            print(f\"    - {var}: IV={iv:.4f}\")\n",
    "\n",
    "print(\"\\n🏷️ NADİR KATEGORİ FİLTRESİ:\")\n",
    "print(f\"  Eşik: %{cfg.rare_threshold*100}\")\n",
    "print(f\"  Muhtemel elenen kategoriler: Rare1, Rare2 (product_type değişkeninde)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Excel Raporu Kontrolü"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📁 Excel raporu oluşturuldu: outputs_realistic_gini\\realistic_gini_report.xlsx\n",
      "\n",
      "📋 Sheets (16 adet):\n",
      "   1. final_vars\n",
      "   2. best_name\n",
      "   3. models_summary\n",
      "   4. best_model\n",
      "   5. best_model_vars_df\n",
      "   6. best_model_woe_df\n",
      "   7. top20_iv_df\n",
      "   8. top50_univariate\n",
      "   9. ks_info_traincv\n",
      "  10. ks_info_test\n",
      "\n",
      "📊 MODEL KARŞILAŞTIRMASI:\n",
      "  model_name  Gini_OOT\n",
      "  ExtraTrees  0.588250\n",
      "    Logit_L2  0.593798\n",
      "RandomForest  0.586364\n",
      "     XGBoost  0.586364\n",
      "    LightGBM  0.586364\n",
      "         GAM  0.593798\n"
     ]
    }
   ],
   "source": [
    "# Excel raporu kontrolü\n",
    "import os\n",
    "\n",
    "excel_path = os.path.join(cfg.output_folder, cfg.output_excel_path)\n",
    "if os.path.exists(excel_path):\n",
    "    print(f\"📁 Excel raporu oluşturuldu: {excel_path}\")\n",
    "    \n",
    "    excel_file = pd.ExcelFile(excel_path)\n",
    "    print(f\"\\n📋 Sheets ({len(excel_file.sheet_names)} adet):\")\n",
    "    for i, sheet in enumerate(excel_file.sheet_names[:10], 1):  # İlk 10 sheet\n",
    "        print(f\"  {i:2}. {sheet}\")\n",
    "    \n",
    "    # Model summary\n",
    "    if 'models_summary' in excel_file.sheet_names:\n",
    "        models_df = pd.read_excel(excel_path, sheet_name='models_summary')\n",
    "        print(f\"\\n📊 MODEL KARŞILAŞTIRMASI:\")\n",
    "        \n",
    "        # Select available columns\n",
    "        display_cols = ['model_name', 'Gini_train', 'Gini_test', 'Gini_OOT']\n",
    "        available_cols = [col for col in display_cols if col in models_df.columns]\n",
    "        \n",
    "        if available_cols:\n",
    "            print(models_df[available_cols].to_string(index=False))\n",
    "else:\n",
    "    print(f\"⚠️ Excel raporu bulunamadı: {excel_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Özet ve Sonuçlar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "📊 TEST ÖZET\n",
      "================================================================================\n",
      "\n",
      "✅ TEST EDİLEN PIPELINE ADIMLARI:\n",
      "  1. Veri validasyon ve hazırlama\n",
      "  2. WOE binning ve transformation\n",
      "  3. PSI hesaplama ve filtreleme\n",
      "  4. IV hesaplama ve düşük bilgili değişkenleri eleme\n",
      "  5. Korelasyon analizi ve yüksek koreleli değişkenleri eleme\n",
      "  6. Nadir kategorileri birleştirme\n",
      "  7. Feature selection (Boruta + Forward Selection)\n",
      "  8. Model training (6 algoritma)\n",
      "  9. Model evaluation ve en iyi model seçimi\n",
      " 10. Kalibrasyon (isotonic)\n",
      " 11. Raporlama ve Excel export\n",
      "\n",
      "📈 HEDEF PERFORMANS:\n",
      "  Hedef Gini aralığı: %70-80\n",
      "  Baseline Gini (Logistic Regression): 75.2%\n",
      "  Pipeline OOT Gini: 58.8%\n",
      "\n",
      "================================================================================\n",
      "✅ TEST TAMAMLANDI!\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"📊 TEST ÖZET\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "print(\"\\n✅ TEST EDİLEN PIPELINE ADIMLARI:\")\n",
    "print(\"  1. Veri validasyon ve hazırlama\")\n",
    "print(\"  2. WOE binning ve transformation\")\n",
    "print(\"  3. PSI hesaplama ve filtreleme\")\n",
    "print(\"  4. IV hesaplama ve düşük bilgili değişkenleri eleme\")\n",
    "print(\"  5. Korelasyon analizi ve yüksek koreleli değişkenleri eleme\")\n",
    "print(\"  6. Nadir kategorileri birleştirme\")\n",
    "print(\"  7. Feature selection (Boruta + Forward Selection)\")\n",
    "print(\"  8. Model training (6 algoritma)\")\n",
    "print(\"  9. Model evaluation ve en iyi model seçimi\")\n",
    "print(\" 10. Kalibrasyon (isotonic)\")\n",
    "print(\" 11. Raporlama ve Excel export\")\n",
    "\n",
    "print(\"\\n📈 HEDEF PERFORMANS:\")\n",
    "print(f\"  Hedef Gini aralığı: %70-80\")\n",
    "print(f\"  Baseline Gini (Logistic Regression): {gini*100:.1f}%\")\n",
    "\n",
    "if pipeline.best_model_name_ and pipeline.models_summary_ is not None:\n",
    "    best = pipeline.models_summary_[pipeline.models_summary_['model_name'] == pipeline.best_model_name_].iloc[0]\n",
    "    if 'Gini_OOT' in best and best.get('Gini_OOT'):\n",
    "        gini_oot = best.get('Gini_OOT')\n",
    "        print(f\"  Pipeline OOT Gini: {gini_oot*100:.1f}%\")\n",
    "        \n",
    "        if 0.70 <= gini_oot <= 0.80:\n",
    "            print(\"\\n🎯 BAŞARILI: Gerçekçi Gini hedefi sağlandı (%70-80)\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"✅ TEST TAMAMLANDI!\")\n",
    "print(\"=\"*80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}