{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "68e2913b",
   "metadata": {},
   "source": [
    "\n",
    "# Dual Unified Pipeline Demo (RAW + WOE + Scoring)\n",
    "\n",
    "This notebook walks through the unified pipeline end-to-end. We build synthetic datasets, run the dual RAW+WOE flow, perform two-stage calibration, generate scores, and review the risk band metrics.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2b26d06",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "!{sys.executable} -m pip install --quiet --upgrade \"git+https://github.com/selimoksuz/risk-model-pipeline.git@development#egg=risk-pipeline\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f5d448c",
   "metadata": {},
   "source": [
    "\n",
    "> **Note:** Until the upstream development branch ships these fixes, run the next cell to copy patched modules from this workspace into the installed package directory.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e749776f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import importlib\n",
    "import shutil\n",
    "from pathlib import Path\n",
    "import risk_pipeline\n",
    "\n",
    "package_root = Path(risk_pipeline.__file__).resolve().parent\n",
    "local_root = Path(r\"C:/Users/Acer/risk-model-pipeline-dev/src/risk_pipeline\")\n",
    "modules = [\n",
    "    (local_root / \"core\" / \"feature_selector_enhanced.py\", package_root / \"core\" / \"feature_selector_enhanced.py\"),\n",
    "    (local_root / \"core\" / \"risk_band_optimizer.py\", package_root / \"core\" / \"risk_band_optimizer.py\"),\n",
    "    (local_root / \"unified_pipeline.py\", package_root / \"unified_pipeline.py\"),\n",
    "]\n",
    "for src, dst in modules:\n",
    "    shutil.copy(src, dst)\n",
    "\n",
    "importlib.invalidate_caches()\n",
    "importlib.reload(risk_pipeline.core.feature_selector_enhanced)\n",
    "importlib.reload(risk_pipeline.core.risk_band_optimizer)\n",
    "importlib.reload(risk_pipeline.unified_pipeline)\n",
    "print(\"Patched modules copied to the installed package.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75288b57",
   "metadata": {},
   "source": [
    "\n",
    "## 1. Generate datasets\n",
    "\n",
    "We create three synthetic datasets:\n",
    "- `df`: master dataset that will be split into train/test/OOT.\n",
    "- `stage2_df`: most recent observations used for stage-2 calibration.\n",
    "- `score_df`: separate sample to demonstrate scoring and band assignment.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54ddcbc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "from risk_pipeline.core.config import Config\n",
    "from risk_pipeline.unified_pipeline import UnifiedRiskPipeline\n",
    "\n",
    "def generate_synthetic(n: int = 12000, seed: int = 42, months: int = 24) -> pd.DataFrame:\n",
    "    rng = np.random.default_rng(seed)\n",
    "    dt0 = datetime(2023, 1, 1)\n",
    "\n",
    "    month_idx = rng.integers(0, months, size=n)\n",
    "    app_dt = [dt0 + timedelta(days=int(m * 30 + rng.integers(0, 30))) for m in month_idx]\n",
    "\n",
    "    x_num_strong = rng.normal(0, 1, n)\n",
    "    x_num_corr = x_num_strong * 0.9 + rng.normal(0, 0.2, n)\n",
    "    x_num_thresh = rng.exponential(1.0, n)\n",
    "    x_num_weak = rng.normal(0, 1, n)\n",
    "    x_num_noise1 = rng.normal(0, 1, n)\n",
    "    x_num_noise2 = rng.normal(0, 1, n)\n",
    "\n",
    "    x_num_psi = rng.normal(0, 1, n)\n",
    "    drift_months = set(range(months - 3, months))\n",
    "    drift_mask = np.array([m in drift_months for m in month_idx])\n",
    "    x_num_psi[drift_mask] = rng.normal(1.5, 1.0, drift_mask.sum())\n",
    "\n",
    "    cat1 = rng.choice([\"A\", \"B\", \"C\", \"D\", None], size=n, p=[0.35, 0.30, 0.20, 0.10, 0.05])\n",
    "    cat2_levels = [f\"K{i}\" for i in range(10)] + [None]\n",
    "    cat2_probs = np.array([0.10] * 5 + [0.04] * 5 + [0.06])\n",
    "    cat2_probs = cat2_probs / cat2_probs.sum()\n",
    "    cat2 = rng.choice(cat2_levels, size=n, p=cat2_probs)\n",
    "\n",
    "    cat1_map = {\"A\": 0.15, \"B\": 0.0, \"C\": -0.1, \"D\": 0.25}\n",
    "    cat2_map = {lvl: (0.2 if lvl in [\"K0\", \"K3\"] else (0.05 if lvl in [\"K1\", \"K7\"] else 0.0)) for lvl in cat2_levels}\n",
    "    cat1_term = pd.Series(cat1, dtype=\"object\").map(cat1_map).fillna(0.0).values\n",
    "    cat2_term = pd.Series(cat2, dtype=\"object\").map(cat2_map).fillna(0.0).values\n",
    "\n",
    "    season = 0.1 * np.sin(2 * np.pi * (np.array(month_idx) % 12) / 12.0)\n",
    "    logit = (\n",
    "        -1.2\n",
    "        + 1.2 * x_num_strong\n",
    "        + 0.9 * (x_num_thresh > 1.0).astype(int)\n",
    "        + 0.3 * x_num_weak\n",
    "        + 0.25 * (x_num_psi > 0.5).astype(int)\n",
    "        + cat1_term\n",
    "        + cat2_term\n",
    "        + season\n",
    "    )\n",
    "    p = 1.0 / (1.0 + np.exp(-logit))\n",
    "    y = (rng.random(n) < p).astype(int)\n",
    "\n",
    "    return pd.DataFrame(\n",
    "        {\n",
    "            \"app_id\": np.arange(1, n + 1),\n",
    "            \"app_dt\": app_dt,\n",
    "            \"x_num_strong\": x_num_strong,\n",
    "            \"x_num_corr\": x_num_corr,\n",
    "            \"x_num_thresh\": x_num_thresh,\n",
    "            \"x_num_weak\": x_num_weak,\n",
    "            \"x_num_psi\": x_num_psi,\n",
    "            \"x_num_noise1\": x_num_noise1,\n",
    "            \"x_num_noise2\": x_num_noise2,\n",
    "            \"cat1\": cat1,\n",
    "            \"cat2\": cat2,\n",
    "            \"target\": y,\n",
    "        }\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2643d7e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df = generate_synthetic(n=12000, seed=42)\n",
    "recent_cut = pd.Timestamp(df[\"app_dt\"].max()) - pd.Timedelta(days=60)\n",
    "stage2_df = df[pd.to_datetime(df[\"app_dt\"]) >= recent_cut].copy()\n",
    "score_df = generate_synthetic(n=3000, seed=123)\n",
    "\n",
    "print(f\"master data shape: {df.shape}\")\n",
    "print(f\"stage-2 data shape: {stage2_df.shape}\")\n",
    "print(f\"scoring data shape: {score_df.shape}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fde857d5",
   "metadata": {},
   "source": [
    "\n",
    "## 2. Configure the unified pipeline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f502615",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "cfg = Config(\n",
    "    target_col=\"target\",\n",
    "    id_col=\"app_id\",\n",
    "    time_col=\"app_dt\",\n",
    "    enable_scoring=True,\n",
    "    enable_calibration=True,\n",
    "    stage2_method=\"lower_mean\",\n",
    "    enable_woe=True,\n",
    "    selection_order=[\"psi\", \"vif\", \"correlation\", \"iv\", \"boruta\", \"stepwise\"],\n",
    "    iv_threshold=0.0,\n",
    "    psi_threshold=10.0,\n",
    "    use_boruta=True,\n",
    "    forward_selection=True,\n",
    "    max_features=12,\n",
    "    use_optuna=False,\n",
    "    model_type=\"all\",\n",
    "    use_test_split=True,\n",
    "    oot_months=3,\n",
    "    equal_default_splits=False,\n",
    "    n_risk_bands=10,\n",
    "    band_method=\"quantile\",\n",
    "    enable_dual_pipeline=True,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99a5cac6",
   "metadata": {},
   "source": [
    "\n",
    "## 3. Run the unified pipeline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0bff57c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "pipe = UnifiedRiskPipeline(cfg)\n",
    "results = pipe.fit(df=df, calibration_df=None, stage2_df=stage2_df, score_df=score_df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0eff56e",
   "metadata": {},
   "source": [
    "\n",
    "## 4. Inspect selected features, best model, and scoring output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f08f52b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "selected = results.get(\"selected_features\", [])\n",
    "best_name = results.get(\"best_model_name\")\n",
    "print(\"number of selected features:\", len(selected))\n",
    "print(\"selected features:\", selected)\n",
    "print(\"best model:\", best_name)\n",
    "\n",
    "scored_df = results.get(\"scoring_results\")\n",
    "if scored_df is not None and not scored_df.empty:\n",
    "    preview_cols = [cfg.id_col, \"risk_score\", cfg.target_col] if cfg.target_col in scored_df.columns else [cfg.id_col, \"risk_score\"]\n",
    "    display(scored_df[preview_cols].head())\n",
    "    display(scored_df[\"risk_band\"].value_counts().sort_index().to_frame(\"count\"))\n",
    "else:\n",
    "    print(\"scoring results are empty\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f44d82c",
   "metadata": {},
   "source": [
    "\n",
    "## 5. Review risk band metrics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2eede665",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "risk_bands = results.get(\"risk_bands\")\n",
    "if risk_bands:\n",
    "    display(risk_bands['bands'])\n",
    "    metrics = risk_bands.get('metrics', {})\n",
    "    print(\"\n",
    "metrics summary:\")\n",
    "    for key, value in metrics.items():\n",
    "        if isinstance(value, float):\n",
    "            print(f\"- {key}: {value:.4f}\")\n",
    "        else:\n",
    "            print(f\"- {key}: {value}\")\n",
    "else:\n",
    "    print(\"risk band results not available\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
