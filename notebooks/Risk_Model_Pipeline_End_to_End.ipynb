{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "795fc611",
   "metadata": {},
   "source": [
    "# Risk Model Pipeline - End-to-End Demo\n",
    "\n",
    "This notebook installs the package from the `development` branch, generates synthetic data, runs the unified pipeline (RAW + WOE) with two-stage calibration, and inspects the resulting reports. Adjust the configuration cell to scale the workload for your hardware."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa6739f6",
   "metadata": {},
   "source": [
    "## 0. Prerequisites\n",
    "\n",
    "- Ensure Python 3.10+ is available.\n",
    "- Install the package directly from GitHub (rerun to pick up the latest development changes)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e61b0e5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "# Uncomment and run if the package is not installed or you want the latest development build\n",
    "# !{sys.executable} -m pip install --upgrade \"git+https://github.com/selimoksuz/risk-model-pipeline.git@development#egg=risk-pipeline\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26484133",
   "metadata": {},
   "source": [
    "## 1. Runtime Controls\n",
    "\n",
    "Tweak these flags before running the pipeline. Reduce the sample sizes on smaller machines or disable optional components (scoring, Stage-2 calibration, tsfresh) if you only need a subset of the pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6a8d72a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Synthetic data controls\n",
    "N_SAMPLES = 12000           # master dataset size (train/test/OOT)\n",
    "STAGE2_LOOKBACK_MONTHS = 2  # window for recent observations feeding Stage-2 calibration\n",
    "SCORING_SAMPLES = 3000      # separate sample scored after training\n",
    "RANDOM_SEED = 42\n",
    "\n",
    "# Pipeline feature toggles\n",
    "ENABLE_SCORING = True\n",
    "ENABLE_STAGES = True        # Stage-1 + optional Stage-2 calibration\n",
    "ENABLE_STAGE2 = True        # Set False to skip Stage-2 even when ENABLE_STAGES is True\n",
    "ENABLE_DUAL_PIPELINE = True # RAW + WOE flows with automatic best-model pick\n",
    "ENABLE_TSFRESH = False      # Enable to append time-series descriptors (heavier)\n",
    "TSFRESH_WINDOW = 6          # Recent observations per entity (ignored if ENABLE_TSFRESH=False)\n",
    "\n",
    "# Modelling knobs\n",
    "SELECTION_ORDER = [\"psi\", \"vif\", \"correlation\", \"iv\", \"boruta\", \"stepwise\"]\n",
    "MODEL_TYPE = \"all\"          # \"all\", \"logistic\", \"tree\", etc.\n",
    "STAGE2_METHOD = \"lower_mean\"  # \"lower_mean\", \"mean\", \"upper_mean\", \"manual\"\n",
    "N_RISK_BANDS = 10\n",
    "\n",
    "# Output settings\n",
    "OUTPUT_DIR = \"output_reports\"  # XLSX reports are saved here\n",
    "SAVE_MODEL_ARTIFACTS = False    # Disable to avoid pickling large objects on demo runs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "875ccd1b",
   "metadata": {},
   "source": [
    "## 2. Helpers & Synthetic Data\n",
    "\n",
    "The helper below is identical to the one used in the CLI demo. It creates:\n",
    "- a master dataset (`df`),\n",
    "- a recent slice (`stage2_df`) for Stage-2 calibration,\n",
    "- an optional scoring sample (`score_df`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35365572",
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import annotations\n",
    "\n",
    "from datetime import datetime, timedelta\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "def generate_synthetic(n: int, seed: int = 42, months: int = 24) -> pd.DataFrame:\n",
    "    rng = np.random.default_rng(seed)\n",
    "    start = datetime(2023, 1, 1)\n",
    "\n",
    "    month_idx = rng.integers(0, months, size=n)\n",
    "    app_dt = [start + timedelta(days=int(m * 30 + rng.integers(0, 30))) for m in month_idx]\n",
    "\n",
    "    x_num_strong = rng.normal(0, 1, n)\n",
    "    x_num_corr = x_num_strong * 0.9 + rng.normal(0, 0.2, n)\n",
    "    x_num_thresh = rng.exponential(1.0, n)\n",
    "    x_num_weak = rng.normal(0, 1, n)\n",
    "    x_num_noise1 = rng.normal(0, 1, n)\n",
    "    x_num_noise2 = rng.normal(0, 1, n)\n",
    "\n",
    "    x_num_psi = rng.normal(0, 1, n)\n",
    "    drift_months = set(range(months - 3, months))\n",
    "    drift_mask = np.array([m in drift_months for m in month_idx])\n",
    "    x_num_psi[drift_mask] = rng.normal(1.5, 1.0, drift_mask.sum())\n",
    "\n",
    "    cat1 = rng.choice([\"A\", \"B\", \"C\", \"D\", None], size=n, p=[0.35, 0.30, 0.20, 0.10, 0.05])\n",
    "    cat2_levels = [f\"K{i}\" for i in range(10)] + [None]\n",
    "    cat2_probs = np.array([0.10] * 5 + [0.04] * 5 + [0.06])\n",
    "    cat2_probs /= cat2_probs.sum()\n",
    "    cat2 = rng.choice(cat2_levels, size=n, p=cat2_probs)\n",
    "\n",
    "    cat1_map = {\"A\": 0.15, \"B\": 0.0, \"C\": -0.1, \"D\": 0.25}\n",
    "    cat2_map = {lvl: (0.2 if lvl in {\"K0\", \"K3\"} else (0.05 if lvl in {\"K1\", \"K7\"} else 0.0)) for lvl in cat2_levels}\n",
    "    cat1_term = pd.Series(cat1, dtype=\"object\").map(cat1_map).fillna(0.0).values\n",
    "    cat2_term = pd.Series(cat2, dtype=\"object\").map(cat2_map).fillna(0.0).values\n",
    "\n",
    "    season = 0.1 * np.sin(2 * np.pi * (np.array(month_idx) % 12) / 12.0)\n",
    "    logit = (\n",
    "        -1.2\n",
    "        + 1.2 * x_num_strong\n",
    "        + 0.9 * (x_num_thresh > 1.0).astype(int)\n",
    "        + 0.3 * x_num_weak\n",
    "        + 0.25 * (x_num_psi > 0.5).astype(int)\n",
    "        + cat1_term\n",
    "        + cat2_term\n",
    "        + season\n",
    "    )\n",
    "    prob = 1.0 / (1.0 + np.exp(-logit))\n",
    "    target = (rng.random(n) < prob).astype(int)\n",
    "\n",
    "    return pd.DataFrame(\n",
    "        {\n",
    "            \"app_id\": np.arange(1, n + 1),\n",
    "            \"app_dt\": app_dt,\n",
    "            \"x_num_strong\": x_num_strong,\n",
    "            \"x_num_corr\": x_num_corr,\n",
    "            \"x_num_thresh\": x_num_thresh,\n",
    "            \"x_num_weak\": x_num_weak,\n",
    "            \"x_num_psi\": x_num_psi,\n",
    "            \"x_num_noise1\": x_num_noise1,\n",
    "            \"x_num_noise2\": x_num_noise2,\n",
    "            \"cat1\": cat1,\n",
    "            \"cat2\": cat2,\n",
    "            \"target\": target,\n",
    "        }\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f14ef10b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build datasets\n",
    "\n",
    "df = generate_synthetic(n=N_SAMPLES, seed=RANDOM_SEED)\n",
    "\n",
    "stage2_df = None\n",
    "if ENABLE_STAGES and ENABLE_STAGE2:\n",
    "    recent_cut = pd.Timestamp(df[\"app_dt\"].max()) - pd.Timedelta(days=STAGE2_LOOKBACK_MONTHS * 30)\n",
    "    stage2_df = df[pd.to_datetime(df[\"app_dt\"]) >= recent_cut].copy()\n",
    "\n",
    "score_df = None\n",
    "if ENABLE_SCORING:\n",
    "    score_df = generate_synthetic(n=SCORING_SAMPLES, seed=RANDOM_SEED + 7)\n",
    "\n",
    "print(f\"master dataset shape: {df.shape}\")\n",
    "if stage2_df is not None:\n",
    "    print(f\"stage2 calibration sample: {stage2_df.shape}\")\n",
    "if score_df is not None:\n",
    "    print(f\"scoring sample: {score_df.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e2ddf1c",
   "metadata": {},
   "source": [
    "## 3. Configure & Run the Unified Pipeline\n",
    "\n",
    "The configuration mirrors the CLI defaults with optional dual-mode (RAW + WOE). Toggle the flags above to simplify the run if needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ece17ba1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from time import perf_counter\n",
    "from risk_pipeline.core.config import Config\n",
    "from risk_pipeline.unified_pipeline import UnifiedRiskPipeline\n",
    "\n",
    "cfg = Config(\n",
    "    target_col=\"target\",\n",
    "    id_col=\"app_id\",\n",
    "    time_col=\"app_dt\",\n",
    "    enable_scoring=ENABLE_SCORING,\n",
    "    enable_calibration=ENABLE_STAGES,\n",
    "    stage2_method=STAGE2_METHOD,\n",
    "    enable_woe=True,\n",
    "    enable_dual_pipeline=ENABLE_DUAL_PIPELINE,\n",
    "    selection_order=SELECTION_ORDER,\n",
    "    use_boruta=\"boruta\" in [step.lower() for step in SELECTION_ORDER],\n",
    "    forward_selection=True,\n",
    "    max_features=12,\n",
    "    use_optuna=False,\n",
    "    model_type=MODEL_TYPE,\n",
    "    use_test_split=True,\n",
    "    oot_months=STAGE2_LOOKBACK_MONTHS,\n",
    "    equal_default_splits=False,\n",
    "    n_risk_bands=N_RISK_BANDS,\n",
    "    band_method=\"quantile\",\n",
    "    enable_tsfresh_features=ENABLE_TSFRESH,\n",
    "    tsfresh_window=TSFRESH_WINDOW if ENABLE_TSFRESH else None,\n",
    "    run_id=datetime.now().strftime(\"%Y%m%d_%H%M%S\"),\n",
    "    output_dir=OUTPUT_DIR,\n",
    "    save_model=SAVE_MODEL_ARTIFACTS,\n",
    ")\n",
    "\n",
    "stage2_input = stage2_df if (ENABLE_STAGES and ENABLE_STAGE2) else None\n",
    "score_input = score_df if ENABLE_SCORING else None\n",
    "\n",
    "pipeline = UnifiedRiskPipeline(cfg)\n",
    "start = perf_counter()\n",
    "results = pipeline.fit(df=df, calibration_df=None, stage2_df=stage2_input, score_df=score_input)\n",
    "elapsed = perf_counter() - start\n",
    "\n",
    "print(f\"Pipeline finished in {elapsed:.1f} seconds\")\n",
    "print(f\"Best model: {results.get('best_model_name')}\")\n",
    "print(f\"Selected features ({len(results.get('selected_features', []))}): {results.get('selected_features')}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "faa8976d",
   "metadata": {},
   "source": [
    "## 4. Inspect Key Outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1c78568",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "summary_rows = []\n",
    "\n",
    "splits = results.get(\"splits\", {})\n",
    "for split_name in (\"train\", \"test\", \"oot\"):\n",
    "    split_df = splits.get(split_name)\n",
    "    if split_df is not None:\n",
    "        summary_rows.append({\n",
    "            \"split\": split_name,\n",
    "            \"rows\": len(split_df),\n",
    "            \"default_rate\": split_df[cfg.target_col].mean(),\n",
    "        })\n",
    "\n",
    "stage1 = results.get(\"calibration_stage1\") or {}\n",
    "stage2 = results.get(\"calibration_stage2\") or {}\n",
    "if stage1:\n",
    "    summary_rows.append({\n",
    "        \"split\": \"stage1_observed_default_rate\",\n",
    "        \"rows\": stage1.get(\"observed_default_rate\"),\n",
    "        \"default_rate\": stage1.get(\"predicted_default_rate\"),\n",
    "    })\n",
    "if stage2_input is not None and stage2:\n",
    "    summary_rows.append({\n",
    "        \"split\": \"stage2_observed_default_rate\",\n",
    "        \"rows\": stage2.get(\"observed_default_rate\"),\n",
    "        \"default_rate\": stage2.get(\"predicted_default_rate\"),\n",
    "    })\n",
    "\n",
    "summary_df = pd.DataFrame(summary_rows)\n",
    "display(summary_df)\n",
    "\n",
    "excel_path = results.get(\"reports\", {}).get(\"excel_path\")\n",
    "if excel_path:\n",
    "    print(f\"Excel report saved to: {excel_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b200c9a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "risk_bands = results.get(\"risk_bands\")\n",
    "if risk_bands and \"bands\" in risk_bands:\n",
    "    display(risk_bands[\"bands\"].head())\n",
    "    metrics = risk_bands.get(\"metrics\", {})\n",
    "    if metrics:\n",
    "        print(\"\n",
    "Risk-band metrics:\")\n",
    "        for key, value in metrics.items():\n",
    "            if isinstance(value, float):\n",
    "                print(f\"- {key}: {value:.4f}\")\n",
    "            else:\n",
    "                print(f\"- {key}: {value}\")\n",
    "else:\n",
    "    print(\"Risk bands were not generated (check ENABLE_SCORING/ENABLE_STAGES settings).\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c97ccd02",
   "metadata": {},
   "outputs": [],
   "source": [
    "if ENABLE_SCORING:\n",
    "    scored_df = results.get(\"scoring_results\")\n",
    "    if scored_df is not None and not scored_df.empty:\n",
    "        preview_cols = [cfg.id_col, \"risk_score\"]\n",
    "        if cfg.target_col in scored_df.columns:\n",
    "            preview_cols.append(cfg.target_col)\n",
    "        display(scored_df[preview_cols].head())\n",
    "        print(\"\n",
    "Risk band distribution:\")\n",
    "        display(scored_df[\"risk_band\"].value_counts().sort_index())\n",
    "    else:\n",
    "        print(\"Scoring results are empty. Confirm score_df was provided and scoring is enabled.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32edafa5",
   "metadata": {},
   "source": [
    "## 5. Next Steps\n",
    "\n",
    "- Review `output_reports/` for the exported Excel workbook.\n",
    "- Use the same configuration with your own data by supplying real data frames to `pipeline.fit`.\n",
    "- For reproducible automation, mirror this configuration inside a script or the existing CLI (`risk-pipeline`)."
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
