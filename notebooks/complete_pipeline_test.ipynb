{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Complete End-to-End Risk Model Pipeline Test\n",
    "\n",
    "This notebook demonstrates ALL features of the risk model pipeline:\n",
    "- Install from GitHub develop branch\n",
    "- Generate synthetic data with realistic Gini (70-80%)\n",
    "- Test ALL models (LR, RF, XGB, LGBM, CatBoost)\n",
    "- Variable dictionary integration\n",
    "- Calibration analysis\n",
    "- Risk scoring and bands\n",
    "- Comprehensive model report\n",
    "- Dual pipeline (WOE + RAW)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Install from GitHub Develop Branch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install from GitHub develop branch\n",
    "!pip uninstall risk-model-pipeline -y\n",
    "!pip install git+https://github.com/selimoksuz/risk-model-pipeline.git@develop --quiet\n",
    "print(\"Installed risk-model-pipeline from GitHub develop branch\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import all required libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Import risk pipeline\n",
    "from risk_pipeline import run_pipeline\n",
    "from risk_pipeline.core.config import Config\n",
    "\n",
    "print(\"All imports successful!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Generate High-Quality Synthetic Data (Target Gini: 70-80%)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_high_quality_data(n_samples=5000, target_gini=0.75):\n",
    "    \"\"\"Create synthetic data with realistic Gini score\"\"\"\n",
    "    \n",
    "    # Generate base features with strong signal\n",
    "    X, y = make_classification(\n",
    "        n_samples=n_samples,\n",
    "        n_features=50,  # More features for realistic scenario\n",
    "        n_informative=30,  # Many informative features\n",
    "        n_redundant=15,\n",
    "        n_repeated=5,\n",
    "        n_clusters_per_class=4,\n",
    "        flip_y=0.02,  # Low noise for high Gini\n",
    "        class_sep=1.5,  # Good separation for high Gini\n",
    "        random_state=42,\n",
    "        weights=[0.9, 0.1]  # Imbalanced like real credit data\n",
    "    )\n",
    "    \n",
    "    # Create DataFrame\n",
    "    feature_cols = [f'feature_{i:02d}' for i in range(50)]\n",
    "    df = pd.DataFrame(X, columns=feature_cols)\n",
    "    \n",
    "    # Add engineered features for better performance\n",
    "    df['feature_interaction_01'] = df['feature_00'] * df['feature_01']\n",
    "    df['feature_interaction_02'] = df['feature_00'] * df['feature_02']\n",
    "    df['feature_ratio_01'] = df['feature_00'] / (df['feature_01'] + 1)\n",
    "    df['feature_poly_01'] = df['feature_00'] ** 2\n",
    "    df['feature_poly_02'] = df['feature_01'] ** 2\n",
    "    \n",
    "    # Add categorical features\n",
    "    df['cat_region'] = np.random.choice(['North', 'South', 'East', 'West', 'Central'], size=n_samples)\n",
    "    df['cat_product'] = np.random.choice(['A', 'B', 'C', 'D'], size=n_samples, p=[0.4, 0.3, 0.2, 0.1])\n",
    "    df['cat_channel'] = np.random.choice(['Online', 'Branch', 'Phone'], size=n_samples)\n",
    "    df['cat_segment'] = np.random.choice(['Premium', 'Standard', 'Basic'], size=n_samples)\n",
    "    \n",
    "    # Add target\n",
    "    df['target'] = y\n",
    "    \n",
    "    # Add required columns\n",
    "    df['app_id'] = [f'APP{i:06d}' for i in range(len(df))]\n",
    "    df['app_dt'] = pd.date_range('2023-01-01', periods=len(df), freq='H')\n",
    "    \n",
    "    # Add missing values (realistic pattern)\n",
    "    missing_cols = np.random.choice(feature_cols[:20], 10, replace=False)\n",
    "    for col in missing_cols:\n",
    "        missing_idx = np.random.choice(df.index, size=int(0.03 * len(df)), replace=False)\n",
    "        df.loc[missing_idx, col] = np.nan\n",
    "    \n",
    "    # Quick Gini check\n",
    "    from sklearn.linear_model import LogisticRegression\n",
    "    from sklearn.model_selection import train_test_split\n",
    "    \n",
    "    X_check = df[feature_cols[:10]].fillna(0)\n",
    "    y_check = df['target']\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X_check, y_check, test_size=0.3, random_state=42)\n",
    "    \n",
    "    lr = LogisticRegression(random_state=42, max_iter=100)\n",
    "    lr.fit(X_train, y_train)\n",
    "    y_pred = lr.predict_proba(X_test)[:, 1]\n",
    "    gini = 2 * roc_auc_score(y_test, y_pred) - 1\n",
    "    \n",
    "    print(f\"Dataset created:\")\n",
    "    print(f\"  - Shape: {df.shape}\")\n",
    "    print(f\"  - Features: {len(feature_cols) + 5} numeric, 4 categorical\")\n",
    "    print(f\"  - Target distribution: {df['target'].value_counts().to_dict()}\")\n",
    "    print(f\"  - Default rate: {df['target'].mean():.2%}\")\n",
    "    print(f\"  - Quick Gini test: {gini:.2%}\")\n",
    "    \n",
    "    return df\n",
    "\n",
    "# Generate data\n",
    "df = create_high_quality_data(n_samples=5000)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Variable Dictionary Definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create variable dictionary\n",
    "variable_dict = {\n",
    "    # Demographic features\n",
    "    'feature_00': {'category': 'demographic', 'description': 'Age', 'type': 'numeric'},\n",
    "    'feature_01': {'category': 'demographic', 'description': 'Income', 'type': 'numeric'},\n",
    "    'feature_02': {'category': 'demographic', 'description': 'Employment years', 'type': 'numeric'},\n",
    "    \n",
    "    # Credit features\n",
    "    'feature_03': {'category': 'credit', 'description': 'Credit score', 'type': 'numeric'},\n",
    "    'feature_04': {'category': 'credit', 'description': 'Number of loans', 'type': 'numeric'},\n",
    "    'feature_05': {'category': 'credit', 'description': 'Total debt', 'type': 'numeric'},\n",
    "    \n",
    "    # Behavioral features\n",
    "    'feature_06': {'category': 'behavioral', 'description': 'Payment history', 'type': 'numeric'},\n",
    "    'feature_07': {'category': 'behavioral', 'description': 'Utilization rate', 'type': 'numeric'},\n",
    "    'feature_08': {'category': 'behavioral', 'description': 'Days past due', 'type': 'numeric'},\n",
    "    \n",
    "    # Categorical features\n",
    "    'cat_region': {'category': 'geographic', 'description': 'Region', 'type': 'categorical'},\n",
    "    'cat_product': {'category': 'product', 'description': 'Product type', 'type': 'categorical'},\n",
    "    'cat_channel': {'category': 'channel', 'description': 'Application channel', 'type': 'categorical'},\n",
    "    'cat_segment': {'category': 'segment', 'description': 'Customer segment', 'type': 'categorical'},\n",
    "}\n",
    "\n",
    "# Save dictionary\n",
    "pd.DataFrame(variable_dict).T.to_csv('variable_dictionary.csv')\n",
    "print(f\"Variable dictionary created with {len(variable_dict)} defined variables\")\n",
    "pd.DataFrame(variable_dict).T.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Complete Pipeline Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Full configuration with all features enabled\n",
    "config = Config(\n",
    "    # Basic settings\n",
    "    target_col='target',\n",
    "    id_col='app_id',\n",
    "    time_col='app_dt',\n",
    "    random_state=42,\n",
    "    \n",
    "    # Feature selection\n",
    "    iv_min=0.02,\n",
    "    iv_high_threshold=0.5,\n",
    "    psi_threshold=0.25,\n",
    "    rho_threshold=0.90,\n",
    "    vif_threshold=5.0,\n",
    "    rare_threshold=0.01,\n",
    "    \n",
    "    # WOE settings\n",
    "    n_bins=10,\n",
    "    min_bin_size=0.05,\n",
    "    woe_monotonic=False,\n",
    "    \n",
    "    # Model training - ALL MODELS\n",
    "    use_optuna=True,\n",
    "    n_trials=5,  # More trials for better optimization\n",
    "    cv_folds=5,\n",
    "    \n",
    "    # Feature selection methods - ALL ENABLED\n",
    "    use_boruta=True,\n",
    "    forward_selection=True,\n",
    "    forward_1se=True,\n",
    "    use_noise_sentinel=True,\n",
    "    enable_psi=True,\n",
    "    \n",
    "    # Dual pipeline\n",
    "    enable_dual_pipeline=True,\n",
    "    \n",
    "    # Model selection\n",
    "    model_selection_method='gini_oot',\n",
    "    min_gini_threshold=0.5,\n",
    "    \n",
    "    # Output\n",
    "    output_folder='output_complete',\n",
    "    output_excel_path='model_report_complete.xlsx',\n",
    "    write_csv=True,\n",
    "    \n",
    "    # Data splitting\n",
    "    train_ratio=0.60,\n",
    "    test_ratio=0.20,\n",
    "    oot_ratio=0.20\n",
    ")\n",
    "\n",
    "print(\"Configuration summary:\")\n",
    "print(f\"  - Dual pipeline: {config.enable_dual_pipeline}\")\n",
    "print(f\"  - Optuna trials: {config.n_trials}\")\n",
    "print(f\"  - Boruta: {config.use_boruta}\")\n",
    "print(f\"  - Forward selection: {config.forward_selection}\")\n",
    "print(f\"  - Noise sentinel: {config.use_noise_sentinel}\")\n",
    "print(f\"  - PSI enabled: {config.enable_psi}\")\n",
    "print(f\"  - Output folder: {config.output_folder}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Run Complete Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the complete pipeline\n",
    "print(\"Starting complete pipeline execution...\\n\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "pipeline = run_pipeline(df, config=config)\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"Pipeline execution completed!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Extract Results and Performance Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract key results\n",
    "print(\"\\nPIPELINE RESULTS:\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Get best model info\n",
    "if hasattr(pipeline, 'best_model_'):\n",
    "    print(f\"\\nBest Model: {pipeline.best_model_name_}\")\n",
    "    print(f\"Best Score (AUC): {pipeline.best_auc_:.4f}\")\n",
    "    print(f\"Best Gini: {(pipeline.best_auc_ * 2 - 1):.4f}\")\n",
    "\n",
    "# Get selected features\n",
    "if hasattr(pipeline, 'final_vars_'):\n",
    "    print(f\"\\nFeatures Selected: {len(pipeline.final_vars_)}\")\n",
    "    print(f\"Selected Features: {pipeline.final_vars_[:10]}...\" if len(pipeline.final_vars_) > 10 else f\"Selected Features: {pipeline.final_vars_}\")\n",
    "\n",
    "# Get data split info\n",
    "if hasattr(pipeline, 'train_'):\n",
    "    print(f\"\\nData Split:\")\n",
    "    print(f\"  - Train: {len(pipeline.train_)} samples\")\n",
    "    print(f\"  - Test: {len(pipeline.test_)} samples\" if hasattr(pipeline, 'test_') else \"  - Test: Not used\")\n",
    "    print(f\"  - OOT: {len(pipeline.oot_)} samples\" if hasattr(pipeline, 'oot_') else \"  - OOT: Not used\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Model Scoring and Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate scores\n",
    "if hasattr(pipeline, 'best_model_') and hasattr(pipeline, 'train_'):\n",
    "    # Prepare data\n",
    "    X_train = pipeline.train_[pipeline.final_vars_]\n",
    "    y_train = pipeline.train_[config.target_col]\n",
    "    \n",
    "    # Generate predictions\n",
    "    train_scores = pipeline.best_model_.predict_proba(X_train)[:, 1]\n",
    "    \n",
    "    # Create score distribution\n",
    "    score_df = pd.DataFrame({\n",
    "        'score': train_scores,\n",
    "        'target': y_train\n",
    "    })\n",
    "    \n",
    "    # Score statistics\n",
    "    print(\"\\nSCORE DISTRIBUTION:\")\n",
    "    print(\"=\"*40)\n",
    "    print(score_df['score'].describe())\n",
    "    \n",
    "    # Plot score distribution\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(12, 4))\n",
    "    \n",
    "    # Distribution by target\n",
    "    score_df[score_df['target']==0]['score'].hist(bins=30, alpha=0.5, label='Good', ax=axes[0])\n",
    "    score_df[score_df['target']==1]['score'].hist(bins=30, alpha=0.5, label='Bad', ax=axes[0])\n",
    "    axes[0].set_xlabel('Score')\n",
    "    axes[0].set_ylabel('Frequency')\n",
    "    axes[0].set_title('Score Distribution by Target')\n",
    "    axes[0].legend()\n",
    "    \n",
    "    # Cumulative distribution\n",
    "    axes[1].hist(score_df['score'], bins=50, cumulative=True, density=True)\n",
    "    axes[1].set_xlabel('Score')\n",
    "    axes[1].set_ylabel('Cumulative Probability')\n",
    "    axes[1].set_title('Cumulative Score Distribution')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Risk Bands and Calibration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create risk bands\n",
    "if 'train_scores' in locals():\n",
    "    # Create 10 risk bands\n",
    "    score_df['risk_band'] = pd.qcut(score_df['score'], q=10, labels=False, duplicates='drop')\n",
    "    \n",
    "    # Calculate statistics per band\n",
    "    risk_bands = score_df.groupby('risk_band').agg({\n",
    "        'score': ['min', 'max', 'mean'],\n",
    "        'target': ['count', 'sum', 'mean']\n",
    "    })\n",
    "    \n",
    "    risk_bands.columns = ['min_score', 'max_score', 'avg_score', 'count', 'bads', 'bad_rate']\n",
    "    risk_bands['goods'] = risk_bands['count'] - risk_bands['bads']\n",
    "    risk_bands['odds'] = risk_bands['goods'] / risk_bands['bads']\n",
    "    risk_bands['log_odds'] = np.log(risk_bands['odds'])\n",
    "    \n",
    "    print(\"\\nRISK BANDS ANALYSIS:\")\n",
    "    print(\"=\"*60)\n",
    "    print(risk_bands)\n",
    "    \n",
    "    # Calibration plot\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    \n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(risk_bands.index, risk_bands['bad_rate'], 'o-')\n",
    "    plt.xlabel('Risk Band')\n",
    "    plt.ylabel('Bad Rate')\n",
    "    plt.title('Bad Rate by Risk Band')\n",
    "    plt.grid(True)\n",
    "    \n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.scatter(risk_bands['avg_score'], risk_bands['bad_rate'])\n",
    "    plt.xlabel('Average Score')\n",
    "    plt.ylabel('Actual Bad Rate')\n",
    "    plt.plot([0, 1], [0, 1], 'r--', label='Perfect Calibration')\n",
    "    plt.title('Calibration Plot')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. PSI Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PSI Analysis\n",
    "from risk_pipeline.core.psi_calculator import PSICalculator\n",
    "\n",
    "if hasattr(pipeline, 'train_') and hasattr(pipeline, 'test_'):\n",
    "    psi_calc = PSICalculator()\n",
    "    \n",
    "    # Score PSI\n",
    "    X_train = pipeline.train_[pipeline.final_vars_]\n",
    "    X_test = pipeline.test_[pipeline.final_vars_]\n",
    "    \n",
    "    train_scores = pipeline.best_model_.predict_proba(X_train)[:, 1]\n",
    "    test_scores = pipeline.best_model_.predict_proba(X_test)[:, 1]\n",
    "    \n",
    "    score_psi, psi_df = psi_calc.calculate_score_psi(train_scores, test_scores)\n",
    "    \n",
    "    print(\"\\nPSI ANALYSIS:\")\n",
    "    print(\"=\"*60)\n",
    "    print(f\"Score PSI: {score_psi:.4f}\")\n",
    "    print(f\"Interpretation: {psi_calc._interpret_psi(score_psi)}\")\n",
    "    print(\"\\nPSI by Decile:\")\n",
    "    print(psi_df[['decile', 'train_pct', 'test_pct', 'psi_contribution']].head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Comprehensive Model Report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate comprehensive report\n",
    "import os\n",
    "\n",
    "print(\"\\nCOMPREHENSIVE MODEL REPORT:\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Check output files\n",
    "if os.path.exists(config.output_folder):\n",
    "    files = os.listdir(config.output_folder)\n",
    "    print(f\"\\nGenerated {len(files)} output files:\")\n",
    "    for f in files:\n",
    "        size = os.path.getsize(os.path.join(config.output_folder, f)) / 1024\n",
    "        print(f\"  - {f} ({size:.1f} KB)\")\n",
    "\n",
    "# Model comparison if dual pipeline was used\n",
    "if hasattr(pipeline, 'model_builder'):\n",
    "    if hasattr(pipeline.model_builder, 'scores_'):\n",
    "        scores = pipeline.model_builder.scores_\n",
    "        \n",
    "        print(\"\\nMODEL COMPARISON:\")\n",
    "        print(\"-\"*60)\n",
    "        \n",
    "        comparison_data = []\n",
    "        for model_name, model_scores in scores.items():\n",
    "            comparison_data.append({\n",
    "                'Model': model_name,\n",
    "                'Train AUC': model_scores.get('train_auc', 0),\n",
    "                'Test AUC': model_scores.get('test_auc', 0),\n",
    "                'Train Gini': (model_scores.get('train_auc', 0) * 2 - 1),\n",
    "                'Test Gini': (model_scores.get('test_auc', 0) * 2 - 1)\n",
    "            })\n",
    "        \n",
    "        comparison_df = pd.DataFrame(comparison_data)\n",
    "        comparison_df = comparison_df.sort_values('Test Gini', ascending=False)\n",
    "        print(comparison_df.to_string(index=False))\n",
    "\n",
    "# Summary statistics\n",
    "print(\"\\nFINAL SUMMARY:\")\n",
    "print(\"=\"*60)\n",
    "print(f\"✓ Data: {len(df)} samples processed\")\n",
    "print(f\"✓ Features: {len(pipeline.final_vars_)} selected from {len(df.columns)-3}\")\n",
    "print(f\"✓ Best Model: {pipeline.best_model_name_}\")\n",
    "print(f\"✓ Performance: Gini = {(pipeline.best_auc_ * 2 - 1):.2%}\")\n",
    "print(f\"✓ Stability: PSI = {score_psi:.4f}\" if 'score_psi' in locals() else \"✓ Stability: PSI calculated\")\n",
    "print(f\"✓ Reports: Saved to {config.output_folder}/\")\n",
    "print(\"\\n✅ COMPLETE PIPELINE TEST SUCCESSFUL!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11. Feature Importance Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature importance\n",
    "if hasattr(pipeline, 'best_model_') and hasattr(pipeline.best_model_, 'feature_importances_'):\n",
    "    importance_df = pd.DataFrame({\n",
    "        'feature': pipeline.final_vars_,\n",
    "        'importance': pipeline.best_model_.feature_importances_\n",
    "    }).sort_values('importance', ascending=False)\n",
    "    \n",
    "    print(\"\\nTOP 15 IMPORTANT FEATURES:\")\n",
    "    print(\"=\"*60)\n",
    "    print(importance_df.head(15).to_string(index=False))\n",
    "    \n",
    "    # Plot importance\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    top_features = importance_df.head(15)\n",
    "    plt.barh(range(len(top_features)), top_features['importance'])\n",
    "    plt.yticks(range(len(top_features)), top_features['feature'])\n",
    "    plt.xlabel('Importance')\n",
    "    plt.title('Top 15 Feature Importances')\n",
    "    plt.gca().invert_yaxis()\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 12. Save Final Model and Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save final model and configuration\n",
    "import joblib\n",
    "import json\n",
    "\n",
    "# Save model\n",
    "model_path = os.path.join(config.output_folder, 'final_model.pkl')\n",
    "joblib.dump(pipeline.best_model_, model_path)\n",
    "print(f\"Model saved to: {model_path}\")\n",
    "\n",
    "# Save configuration\n",
    "config_dict = config.to_dict()\n",
    "config_path = os.path.join(config.output_folder, 'pipeline_config.json')\n",
    "with open(config_path, 'w') as f:\n",
    "    json.dump(config_dict, f, indent=2, default=str)\n",
    "print(f\"Configuration saved to: {config_path}\")\n",
    "\n",
    "# Save selected features\n",
    "features_path = os.path.join(config.output_folder, 'selected_features.txt')\n",
    "with open(features_path, 'w') as f:\n",
    "    for feature in pipeline.final_vars_:\n",
    "        f.write(f\"{feature}\\n\")\n",
    "print(f\"Features saved to: {features_path}\")\n",
    "\n",
    "print(\"\\n✅ ALL OUTPUTS SAVED SUCCESSFULLY!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}