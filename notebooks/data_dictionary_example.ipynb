{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Risk Model Pipeline - Data Dictionary Example\n",
    "\n",
    "This notebook demonstrates how to use the Risk Model Pipeline with:\n",
    "- Data dictionary support for variable descriptions\n",
    "- Proper model report extraction\n",
    "- DataFrame-based calibration\n",
    "- WOE reports with monotonic ordering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "from datetime import datetime, timedelta\n",
    "import sys\n",
    "import os\n",
    "\n",
    "# Add parent directory to path\n",
    "sys.path.append('..')\n",
    "\n",
    "# Import pipeline components\n",
    "from src.risk_pipeline.pipeline16 import RiskModelPipeline, Config\n",
    "from src.risk_pipeline.utils.pipeline_runner import run_pipeline_from_dataframe\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "print(\"Pipeline modules imported successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Generate Sample Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set random seed for reproducibility\n",
    "np.random.seed(42)\n",
    "\n",
    "# Generate sample data\n",
    "n_samples = 5000\n",
    "\n",
    "# Create base date range\n",
    "start_date = datetime(2023, 1, 1)\n",
    "dates = [start_date + timedelta(days=i) for i in range(n_samples)]\n",
    "\n",
    "# Generate features\n",
    "df = pd.DataFrame({\n",
    "    'app_id': [f'APP_{i:06d}' for i in range(n_samples)],\n",
    "    'app_dt': dates,\n",
    "    'target': np.random.binomial(1, 0.2, n_samples),  # 20% default rate\n",
    "    \n",
    "    # Numeric features\n",
    "    'age': np.random.randint(18, 70, n_samples),\n",
    "    'income': np.random.lognormal(10, 1, n_samples),  # Log-normal income distribution\n",
    "    'credit_score': np.random.normal(650, 100, n_samples).clip(300, 850),\n",
    "    'loan_amount': np.random.exponential(50000, n_samples),\n",
    "    'employment_years': np.random.exponential(5, n_samples).clip(0, 40),\n",
    "    \n",
    "    # Categorical features\n",
    "    'education': np.random.choice(['High School', 'Bachelor', 'Master', 'PhD'], n_samples, p=[0.3, 0.4, 0.25, 0.05]),\n",
    "    'employment_type': np.random.choice(['Salaried', 'Self-Employed', 'Retired', 'Student'], n_samples, p=[0.6, 0.25, 0.1, 0.05]),\n",
    "    'marital_status': np.random.choice(['Single', 'Married', 'Divorced', 'Widowed'], n_samples, p=[0.3, 0.5, 0.15, 0.05]),\n",
    "    'property_type': np.random.choice(['Own', 'Rent', 'Family', 'Other'], n_samples, p=[0.4, 0.35, 0.2, 0.05]),\n",
    "    'city_tier': np.random.choice([1, 2, 3, 4], n_samples, p=[0.3, 0.35, 0.25, 0.1])\n",
    "})\n",
    "\n",
    "# Add some missing values\n",
    "missing_indices = np.random.choice(df.index, size=int(0.05 * len(df)), replace=False)\n",
    "df.loc[missing_indices, 'employment_years'] = np.nan\n",
    "\n",
    "missing_indices = np.random.choice(df.index, size=int(0.03 * len(df)), replace=False)\n",
    "df.loc[missing_indices, 'marital_status'] = np.nan\n",
    "\n",
    "print(f\"Dataset shape: {df.shape}\")\n",
    "print(f\"Target distribution:\\n{df['target'].value_counts(normalize=True)}\")\n",
    "print(f\"\\nFeatures: {list(df.columns[3:])}\")\n",
    "print(f\"\\nDate range: {df['app_dt'].min()} to {df['app_dt'].max()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Create Data Dictionary (Veri Sözlüğü)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create data dictionary with Turkish descriptions\n",
    "data_dictionary = pd.DataFrame({\n",
    "    'alan_adi': [\n",
    "        'age', 'income', 'credit_score', 'loan_amount', 'employment_years',\n",
    "        'education', 'employment_type', 'marital_status', 'property_type', 'city_tier'\n",
    "    ],\n",
    "    'alan_aciklamasi': [\n",
    "        'Müşteri yaşı (yıl)',\n",
    "        'Aylık gelir tutarı (TL)',\n",
    "        'Kredi skoru (300-850 arası)',\n",
    "        'Talep edilen kredi tutarı (TL)',\n",
    "        'Toplam çalışma süresi (yıl)',\n",
    "        'Eğitim durumu',\n",
    "        'İstihdam türü',\n",
    "        'Medeni durum',\n",
    "        'Konut sahiplik durumu',\n",
    "        'Şehir kategorisi (1-4)'\n",
    "    ]\n",
    "})\n",
    "\n",
    "print(\"Data Dictionary (Veri Sözlüğü):\")\n",
    "print(data_dictionary.to_string(index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Run Pipeline with Data Dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure and run pipeline\n",
    "cfg = Config(\n",
    "    id_col='app_id',\n",
    "    time_col='app_dt',\n",
    "    target_col='target',\n",
    "    use_test_split=True,\n",
    "    test_size_row_frac=0.2,\n",
    "    oot_window_months=3,\n",
    "    output_folder='outputs',\n",
    "    output_excel_path='model_report_with_dict.xlsx',\n",
    "    data_dictionary_df=data_dictionary,  # Pass data dictionary\n",
    "    cv_folds=3,\n",
    "    random_state=42,\n",
    "    # Quick run for demo\n",
    "    hpo_timeout=60,\n",
    "    hpo_n_trials=10,\n",
    "    rare_threshold=0.02,\n",
    "    psi_threshold=0.20\n",
    ")\n",
    "\n",
    "print(\"Starting pipeline run with data dictionary...\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Create and run pipeline\n",
    "pipeline = RiskModelPipeline(cfg)\n",
    "pipeline.run(df)\n",
    "\n",
    "# Note: pipeline.run() returns the pipeline object itself for method chaining\n",
    "# NOT a dictionary - this was the previous error\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"Pipeline completed successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Extract Model Results (No .get() Error!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correct way to access pipeline results - directly from pipeline attributes\n",
    "print(\"Model Results:\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Access run ID from config\n",
    "print(f\"Run ID: {pipeline.cfg.run_id}\")\n",
    "\n",
    "# Access best model\n",
    "print(f\"Best Model: {pipeline.best_model_name_}\")\n",
    "\n",
    "# Access final features\n",
    "print(f\"Number of Final Features: {len(pipeline.final_vars_)}\")\n",
    "print(f\"Final Features: {pipeline.final_vars_[:10]}...\")  # Show first 10\n",
    "\n",
    "# Access model performance\n",
    "if pipeline.models_summary_ is not None:\n",
    "    print(\"\\nModel Performance Summary:\")\n",
    "    print(pipeline.models_summary_[['model', 'auc_oot', 'gini_oot']].to_string())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. View Best Model Variables with Descriptions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check best model variables with descriptions from data dictionary\n",
    "if pipeline.best_model_vars_df_ is not None:\n",
    "    print(\"Best Model Variables with Descriptions:\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    # Display variables with their descriptions\n",
    "    display_cols = ['variable', 'description', 'coef_or_importance', 'variable_group']\n",
    "    available_cols = [col for col in display_cols if col in pipeline.best_model_vars_df_.columns]\n",
    "    \n",
    "    print(pipeline.best_model_vars_df_[available_cols].head(15).to_string())\n",
    "    \n",
    "    # Check if descriptions were loaded\n",
    "    has_descriptions = pipeline.best_model_vars_df_['description'].notna().any()\n",
    "    print(f\"\\nDescriptions loaded: {'Yes ✓' if has_descriptions else 'No ✗'}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. View WOE Report with Monotonic Ordering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check WOE report structure\n",
    "if pipeline.best_model_woe_df_ is not None:\n",
    "    print(\"WOE Report Structure:\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    # Show available columns\n",
    "    print(f\"Columns: {list(pipeline.best_model_woe_df_.columns)}\")\n",
    "    \n",
    "    # Get first variable for demonstration\n",
    "    first_var = pipeline.best_model_woe_df_['variable'].iloc[0]\n",
    "    var_woe = pipeline.best_model_woe_df_[pipeline.best_model_woe_df_['variable'] == first_var]\n",
    "    \n",
    "    print(f\"\\nWOE bins for '{first_var}' (sorted by event_rate - monotonic):\")\n",
    "    print(\"-\"*80)\n",
    "    \n",
    "    # Show description if available\n",
    "    if 'variable_description' in var_woe.columns:\n",
    "        desc = var_woe['variable_description'].iloc[0]\n",
    "        if desc:\n",
    "            print(f\"Description: {desc}\")\n",
    "    \n",
    "    # Display WOE bins\n",
    "    display_cols = ['group', 'bin_from', 'bin_to', 'count', 'event_rate', 'woe']\n",
    "    available_cols = [col for col in display_cols if col in var_woe.columns]\n",
    "    \n",
    "    print(\"\\n\" + var_woe[available_cols].to_string())\n",
    "    \n",
    "    # Check monotonicity\n",
    "    event_rates = var_woe['event_rate'].values\n",
    "    is_monotonic = all(event_rates[i] <= event_rates[i+1] for i in range(len(event_rates)-1))\n",
    "    print(f\"\\nMonotonic ordering: {'Yes ✓' if is_monotonic else 'No ✗'}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Alternative: Using Helper Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# You can also use the helper function for simpler usage\n",
    "from src.risk_pipeline.utils.pipeline_runner import run_pipeline_from_dataframe\n",
    "\n",
    "# Run with helper function\n",
    "results = run_pipeline_from_dataframe(\n",
    "    df=df,\n",
    "    data_dictionary_df=data_dictionary,  # Pass data dictionary\n",
    "    output_folder='outputs_helper',\n",
    "    output_excel='model_report_helper.xlsx',\n",
    "    use_test_split=True,\n",
    "    oot_months=3,\n",
    "    hpo_timeout=30,\n",
    "    hpo_n_trials=5\n",
    ")\n",
    "\n",
    "# With helper function, results is a dictionary\n",
    "print(\"Results from helper function:\")\n",
    "print(f\"Best model: {results['best_model']}\")\n",
    "print(f\"Number of final features: {len(results['final_features'])}\")\n",
    "print(f\"Run ID: {results['run_id']}\")\n",
    "print(f\"Output folder: {results['output_folder']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Load and View Excel Report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the Excel report to verify data dictionary integration\n",
    "import os\n",
    "\n",
    "excel_path = os.path.join(pipeline.cfg.output_folder, pipeline.cfg.output_excel_path)\n",
    "\n",
    "if os.path.exists(excel_path):\n",
    "    # Load Excel file\n",
    "    excel_file = pd.ExcelFile(excel_path)\n",
    "    \n",
    "    print(f\"Excel report created: {excel_path}\")\n",
    "    print(f\"\\nAvailable sheets ({len(excel_file.sheet_names)}):\")\n",
    "    for i, sheet in enumerate(excel_file.sheet_names, 1):\n",
    "        print(f\"{i:2}. {sheet}\")\n",
    "    \n",
    "    # Check best_model_vars sheet\n",
    "    if 'best_model_vars_df' in excel_file.sheet_names:\n",
    "        best_vars_df = pd.read_excel(excel_path, sheet_name='best_model_vars_df')\n",
    "        print(\"\\nBest Model Variables from Excel:\")\n",
    "        print(best_vars_df[['variable', 'description', 'coef_or_importance']].head(5))\n",
    "    \n",
    "    # Check WOE report sheet\n",
    "    if 'best_model_woe_df' in excel_file.sheet_names:\n",
    "        woe_df = pd.read_excel(excel_path, sheet_name='best_model_woe_df')\n",
    "        print(\"\\nWOE Report from Excel (first variable):\")\n",
    "        first_var = woe_df['variable'].iloc[0]\n",
    "        print(woe_df[woe_df['variable'] == first_var][['group', 'event_rate', 'woe']].head())\n",
    "else:\n",
    "    print(f\"Excel report not found at {excel_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Example: Calibration with DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate calibration data\n",
    "n_cal = 1000\n",
    "cal_df = pd.DataFrame({\n",
    "    'app_id': [f'CAL_{i:06d}' for i in range(n_cal)],\n",
    "    'app_dt': pd.date_range('2023-12-01', periods=n_cal, freq='H'),\n",
    "    'target': np.random.binomial(1, 0.25, n_cal),  # Slightly different default rate\n",
    "    \n",
    "    # Same features as training\n",
    "    'age': np.random.randint(18, 70, n_cal),\n",
    "    'income': np.random.lognormal(10, 1, n_cal),\n",
    "    'credit_score': np.random.normal(650, 100, n_cal).clip(300, 850),\n",
    "    'loan_amount': np.random.exponential(50000, n_cal),\n",
    "    'employment_years': np.random.exponential(5, n_cal).clip(0, 40),\n",
    "    'education': np.random.choice(['High School', 'Bachelor', 'Master', 'PhD'], n_cal),\n",
    "    'employment_type': np.random.choice(['Salaried', 'Self-Employed', 'Retired', 'Student'], n_cal),\n",
    "    'marital_status': np.random.choice(['Single', 'Married', 'Divorced', 'Widowed'], n_cal),\n",
    "    'property_type': np.random.choice(['Own', 'Rent', 'Family', 'Other'], n_cal),\n",
    "    'city_tier': np.random.choice([1, 2, 3, 4], n_cal)\n",
    "})\n",
    "\n",
    "print(f\"Calibration data shape: {cal_df.shape}\")\n",
    "print(f\"Calibration target rate: {cal_df['target'].mean():.3f}\")\n",
    "\n",
    "# Run pipeline with calibration DataFrame\n",
    "cfg_with_cal = Config(\n",
    "    id_col='app_id',\n",
    "    time_col='app_dt',\n",
    "    target_col='target',\n",
    "    use_test_split=True,\n",
    "    oot_window_months=2,\n",
    "    output_folder='outputs_calibrated',\n",
    "    output_excel_path='model_report_calibrated.xlsx',\n",
    "    data_dictionary_df=data_dictionary,  # Data dictionary\n",
    "    calibration_df=cal_df,  # Calibration DataFrame\n",
    "    cv_folds=3,\n",
    "    hpo_timeout=30,\n",
    "    hpo_n_trials=5\n",
    ")\n",
    "\n",
    "print(\"\\nRunning pipeline with calibration...\")\n",
    "pipeline_cal = RiskModelPipeline(cfg_with_cal)\n",
    "pipeline_cal.run(df)\n",
    "\n",
    "print(f\"\\nCalibration applied: {pipeline_cal.calibrator_ is not None}\")\n",
    "print(f\"Best model: {pipeline_cal.best_model_name_}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "This notebook demonstrated:\n",
    "\n",
    "1. **Data Dictionary Support**: Variables now have Turkish descriptions in reports\n",
    "2. **Correct Result Access**: No more `.get()` errors - access attributes directly from pipeline\n",
    "3. **WOE Monotonic Ordering**: Bins sorted by default rate for better risk understanding\n",
    "4. **Enhanced WOE Report**: Separate columns for bin ranges (bin_from, bin_to)\n",
    "5. **DataFrame Calibration**: Direct DataFrame support without requiring CSV files\n",
    "\n",
    "The Excel report (`model_report_with_dict.xlsx`) contains all results with variable descriptions!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}