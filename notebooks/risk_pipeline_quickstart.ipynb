{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2a5e5a47",
   "metadata": {},
   "source": [
    "# Credit Risk Pipeline Quickstart\n",
    "\n",
    "This notebook runs the **Unified Risk Pipeline** end-to-end on the bundled synthetic dataset while preserving the step-by-step execution flow. You can rerun individual sections independently without switching to a simplified pipeline."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a536aab0",
   "metadata": {},
   "source": [
    "## 1. Environment & Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e17d5e56",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import importlib\n",
    "import importlib.util\n",
    "import subprocess\n",
    "import site\n",
    "import shutil\n",
    "from pathlib import Path\n",
    "\n",
    "NOTEBOOK_FLAGS = globals().setdefault('_NOTEBOOK_FLAGS', {})\n",
    "\n",
    "PROJECT_ROOT = Path.cwd().resolve()\n",
    "SRC_PATH = PROJECT_ROOT / \"src\"\n",
    "if SRC_PATH.exists() and str(SRC_PATH) not in sys.path:\n",
    "    sys.path.insert(0, str(SRC_PATH))\n",
    "\n",
    "\n",
    "def _force_reinstall_from_dev() -> None:\n",
    "    # Uninstall existing risk-pipeline packages and reinstall the development branch\n",
    "    python_exe = sys.executable\n",
    "    for name in ('risk-pipeline', 'risk_pipeline'):\n",
    "        try:\n",
    "            subprocess.run([python_exe, '-m', 'pip', 'uninstall', '-y', name], check=False)\n",
    "        except Exception:\n",
    "            pass\n",
    "    try:\n",
    "        for sp in site.getsitepackages() + [site.getusersitepackages()]:\n",
    "            package_path = Path(sp) / 'risk_pipeline'\n",
    "            if package_path.exists():\n",
    "                shutil.rmtree(package_path, ignore_errors=True)\n",
    "    except Exception:\n",
    "        pass\n",
    "    try:\n",
    "        subprocess.run([python_exe, '-m', 'pip', 'cache', 'purge'], check=False)\n",
    "    except Exception:\n",
    "        pass\n",
    "    git_url = 'git+https://github.com/selimoksuz/risk-model-pipeline.git@development'\n",
    "    subprocess.run([python_exe, '-m', 'pip', 'install', '--no-cache-dir', '--force-reinstall', '-U', git_url], check=True)\n",
    "\n",
    "\n",
    "def _import_risk_pipeline():\n",
    "    try:\n",
    "        import risk_pipeline as rp\n",
    "        return rp\n",
    "    except Exception as exc:\n",
    "        message = repr(exc)\n",
    "        print('risk_pipeline import failed:', message)\n",
    "        if 'IndentationError' in message or 'data_processor.py' in message:\n",
    "            print('Attempting clean reinstall from development branch...')\n",
    "            _force_reinstall_from_dev()\n",
    "            import importlib as _il\n",
    "            return _il.import_module('risk_pipeline')\n",
    "        print('Manual install hint:')\n",
    "        print('  pip install -U \"git+https://github.com/selimoksuz/risk-model-pipeline.git@development\"')\n",
    "        raise\n",
    "\n",
    "\n",
    "TSFRESH_AVAILABLE = importlib.util.find_spec('tsfresh') is not None\n",
    "if TSFRESH_AVAILABLE:\n",
    "    print('tsfresh available (advanced time-series features can be enabled via config).')\n",
    "else:\n",
    "    print('tsfresh is not installed; pipeline will proceed without time-series feature mining.')\n",
    "\n",
    "risk_pipeline = _import_risk_pipeline()\n",
    "NOTEBOOK_FLAGS['tsfresh_available'] = TSFRESH_AVAILABLE\n",
    "\n",
    "if 'pipe' not in globals():\n",
    "    pipe = None\n",
    "if 'results' not in globals():\n",
    "    results = {}\n",
    "if 'full_results' not in globals():\n",
    "    full_results = {}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61748424",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from IPython.display import display\n",
    "\n",
    "from risk_pipeline.data.sample import load_credit_risk_sample\n",
    "\n",
    "sample = load_credit_risk_sample()\n",
    "OUTPUT_DIR = Path('notebooks/outputs/credit_risk_sample_notebook')\n",
    "OUTPUT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "NOTEBOOK_CONTEXT = globals().setdefault('_NOTEBOOK_CONTEXT', {\n",
    "    'data': {},\n",
    "    'artifacts': {},\n",
    "    'paths': {},\n",
    "    'options': {}\n",
    "})\n",
    "\n",
    "NOTEBOOK_CONTEXT['paths']['root'] = PROJECT_ROOT\n",
    "NOTEBOOK_CONTEXT['paths']['output'] = OUTPUT_DIR\n",
    "\n",
    "NOTEBOOK_CONTEXT['data']['development'] = sample.development.copy()\n",
    "NOTEBOOK_CONTEXT['data']['calibration_longrun'] = sample.calibration_longrun.copy()\n",
    "NOTEBOOK_CONTEXT['data']['calibration_recent'] = sample.calibration_recent.copy()\n",
    "NOTEBOOK_CONTEXT['data']['scoring_future'] = sample.scoring_future.copy()\n",
    "NOTEBOOK_CONTEXT['data']['data_dictionary'] = sample.data_dictionary.copy()\n",
    "\n",
    "NOTEBOOK_CONTEXT['artifacts'].setdefault('processed', None)\n",
    "NOTEBOOK_CONTEXT['artifacts'].setdefault('splits', None)\n",
    "NOTEBOOK_CONTEXT['artifacts'].setdefault('woe', None)\n",
    "NOTEBOOK_CONTEXT['artifacts'].setdefault('selection', {})\n",
    "NOTEBOOK_CONTEXT['artifacts'].setdefault('modeling', {})\n",
    "NOTEBOOK_CONTEXT['artifacts'].setdefault('calibration', {})\n",
    "NOTEBOOK_CONTEXT['artifacts'].setdefault('risk_bands', {})\n",
    "NOTEBOOK_CONTEXT['artifacts'].setdefault('reports', {})\n",
    "\n",
    "NOTEBOOK_CONTEXT['options']['random_state'] = 42\n",
    "\n",
    "\n",
    "MAX_DEV_ROWS = 50000\n",
    "if len(NOTEBOOK_CONTEXT['data']['development']) > MAX_DEV_ROWS:\n",
    "    NOTEBOOK_CONTEXT['data']['development'] = NOTEBOOK_CONTEXT['data']['development'].sample(n=MAX_DEV_ROWS, random_state=42).reset_index(drop=True)\n",
    "    print(f'Warning: downsampled development data to {MAX_DEV_ROWS:,} rows to avoid memory pressure.')\n",
    "\n",
    "MAX_SCORE_ROWS = 50000\n",
    "if len(NOTEBOOK_CONTEXT['data']['scoring_future']) > MAX_SCORE_ROWS:\n",
    "    NOTEBOOK_CONTEXT['data']['scoring_future'] = NOTEBOOK_CONTEXT['data']['scoring_future'].sample(n=MAX_SCORE_ROWS, random_state=42).reset_index(drop=True)\n",
    "\n",
    "DEV_DF = NOTEBOOK_CONTEXT['data']['development']\n",
    "CAL_LONG_DF = NOTEBOOK_CONTEXT['data']['calibration_longrun']\n",
    "CAL_RECENT_DF = NOTEBOOK_CONTEXT['data']['calibration_recent']\n",
    "SCORE_DF = NOTEBOOK_CONTEXT['data']['scoring_future']\n",
    "DATA_DICTIONARY = NOTEBOOK_CONTEXT['data']['data_dictionary']\n",
    "\n",
    "dev_df = DEV_DF\n",
    "cal_long_df = CAL_LONG_DF\n",
    "cal_recent_df = CAL_RECENT_DF\n",
    "score_df = SCORE_DF\n",
    "data_dictionary = DATA_DICTIONARY\n",
    "\n",
    "print(f\"Development dataset: {dev_df.shape[0]:,} rows, {dev_df.shape[1]} columns\")\n",
    "print(f\"Stage 1 calibration dataset: {cal_long_df.shape[0]:,} rows\")\n",
    "print(f\"Stage 2 calibration dataset: {cal_recent_df.shape[0]:,} rows\")\n",
    "print(f\"Scoring dataset: {score_df.shape[0]:,} rows\")\n",
    "\n",
    "display(dev_df.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06c34ad2",
   "metadata": {},
   "source": [
    "## 2. Pipeline Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3766f120",
   "metadata": {},
   "outputs": [],
   "source": [
    "from risk_pipeline.core.config import Config\n",
    "from risk_pipeline.unified_pipeline import UnifiedRiskPipeline\n",
    "\n",
    "cfg = Config(\n",
    "    target_column='target',\n",
    "    id_column='customer_id',\n",
    "    time_column='app_dt',\n",
    "\n",
    "    create_test_split=True,\n",
    "    stratify_test=True,\n",
    "    group_split_by_id=True,\n",
    "    train_ratio=0.8,\n",
    "    test_ratio=0.2,\n",
    "    oot_months=3,\n",
    "\n",
    "    output_folder=str(OUTPUT_DIR),\n",
    "    output_excel_path=str(OUTPUT_DIR / 'risk_pipeline_report.xlsx'),\n",
    "\n",
    "    enable_tsfresh_features=NOTEBOOK_FLAGS.get('tsfresh_available', False),\n",
    "    enable_tsfresh_rolling=False,\n",
    "    tsfresh_feature_set='efficient',\n",
    "    tsfresh_n_jobs=4,\n",
    "    tsfresh_window_months=12,\n",
    "    tsfresh_min_events=1,\n",
    "    tsfresh_min_unique_months=1,\n",
    "    tsfresh_min_coverage_ratio=1.0,\n",
    "    tsfresh_include_current_record=False,\n",
    "\n",
    "    selection_steps=[\n",
    "        'univariate',\n",
    "        'psi',\n",
    "        'vif',\n",
    "        'correlation',\n",
    "        'iv',\n",
    "        'boruta',\n",
    "        'stepwise',\n",
    "    ],\n",
    "    min_univariate_gini=0.05,\n",
    "    psi_threshold=0.25,\n",
    "    monthly_psi_threshold=0.15,\n",
    "    oot_psi_threshold=0.25,\n",
    "    test_psi_threshold=0.25,\n",
    "    vif_threshold=5.0,\n",
    "    correlation_threshold=0.9,\n",
    "    iv_threshold=0.02,\n",
    "    stepwise_method='forward',\n",
    "    stepwise_max_features=25,\n",
    "    psi_compare_axes=['monthly', 'oot', 'test'],\n",
    "    psi_decision='all',\n",
    "\n",
    "    algorithms=[\n",
    "        'logistic',\n",
    "        'lightgbm',\n",
    "        'xgboost',\n",
    "        'catboost',\n",
    "        'randomforest',\n",
    "        'extratrees',\n",
    "        'woe_boost',\n",
    "        'woe_li',\n",
    "        'shao',\n",
    "        'xbooster',\n",
    "    ],\n",
    "    model_selection_method='gini_oot',\n",
    "    model_stability_weight=0.2,\n",
    "    min_gini_threshold=0.5,\n",
    "    max_train_oot_gap=0.03,\n",
    "    use_optuna=True,\n",
    "    hpo_trials=1,\n",
    "    hpo_timeout_sec=1800,\n",
    "    cv_folds=5,\n",
    "    early_stopping_rounds=200,\n",
    "\n",
    "    use_noise_sentinel=True,\n",
    "    enable_dual=True,\n",
    "    enable_woe_boost_scorecard=True,\n",
    "    calculate_shap=True,\n",
    "    shap_sample_size=2000,\n",
    "    enable_scoring=True,\n",
    "    score_model_name='best',\n",
    "    enable_stage2_calibration=True,\n",
    "\n",
    "    optimize_risk_bands=True,\n",
    "    n_risk_bands=10,\n",
    "    risk_band_method='pd_constraints',\n",
    "    risk_band_min_bins=7,\n",
    "    risk_band_max_bins=10,\n",
    "    risk_band_micro_bins=1000,\n",
    "    risk_band_min_sample_size=0,\n",
    "    risk_band_min_weight=0.05,\n",
    "    risk_band_max_weight=0.30,\n",
    "    risk_band_hhi_threshold=0.15,\n",
    "    risk_band_binomial_pass_weight=0.85,\n",
    "    risk_band_max_iterations=100,\n",
    "    risk_band_max_phase_iterations=50,\n",
    "    risk_band_early_stop_rounds=10,\n",
    "\n",
    "    random_state=42,\n",
    "    n_jobs=-1,\n",
    "    log_level='INFO',\n",
    ")\n",
    "\n",
    "pipe = UnifiedRiskPipeline(cfg)\n",
    "cfg.excel_overwrite = True\n",
    "cfg.cv_enable = True\n",
    "cfg.class_weight = 'balanced'\n",
    "cfg.sample_weight_column = None\n",
    "cfg.freeze_config = True\n",
    "cfg.persist_artifacts = True\n",
    "cfg.save_model = True\n",
    "cfg.run_id = 'quickstart_pipeline'\n",
    "NOTEBOOK_CONTEXT['artifacts']['pipeline'] = pipe\n",
    "NOTEBOOK_CONTEXT['artifacts']['config'] = cfg\n",
    "print('Pipeline configured. enable_dual:', cfg.enable_dual, '| tsfresh enabled:', cfg.enable_tsfresh_features)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a88ab09",
   "metadata": {},
   "source": [
    "### Konfig Aciklamalari (Ozet)\n",
    "\n",
    "- Cekirdek: target_column, id_column, time_column (snapshot_column otomatik olarak snapshot_month olarak ayarlanir)\n",
    "- Ayirim: create_test_split, stratify_test, group_split_by_id, train_ratio, test_ratio, oot_ratio, oot_months\n",
    "- Cikti: output_folder, output_excel_path, excel_overwrite\n",
    "- TSFresh: enable_tsfresh_features, enable_tsfresh_rolling, tsfresh_window_months, tsfresh_min_events, tsfresh_min_unique_months, tsfresh_min_coverage_ratio, tsfresh_include_current_record\n",
    "- Secim: selection_steps, min_univariate_gini, psi_threshold, monthly_psi_threshold, oot_psi_threshold, test_psi_threshold, vif_threshold, correlation_threshold, stepwise_method, stepwise_max_features\n",
    "- PSI: psi_compare_axes, psi_decision, psi_bucketing_mode_woe, psi_bucketing_mode_raw\n",
    "- Model: algorithms, model_selection_method, model_stability_weight, min_gini_threshold, max_train_oot_gap\n",
    "- HPO/CV: use_optuna, hpo_trials, hpo_timeout_sec, cv_enable, cv_folds, early_stopping_rounds\n",
    "- Agirliklar: class_weight, sample_weight_column\n",
    "- Tanimlama: use_noise_sentinel, calculate_shap, enable_dual, enable_woe_boost_scorecard, enable_stage2_calibration, enable_scoring, score_model_name\n",
    "- Kalibrasyon: stage1 ve stage2 zinciri (isotonic -> stage2 hedef ayari), stage2 hedef orani icin hazir alanlar\n",
    "- Risk Bant: n_risk_bands, risk_band_method, risk_band_min_bins, risk_band_max_bins, risk_band_micro_bins, risk_band_min_sample_size, risk_band_min_weight, risk_band_max_weight, risk_band_hhi_threshold, risk_band_binomial_pass_weight, risk_band_max_iterations, risk_band_max_phase_iterations, risk_band_early_stop_rounds\n",
    "- Calisma: random_state, n_jobs, freeze_config, persist_artifacts, save_model, run_id, log_level\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0627e30",
   "metadata": {},
   "source": [
    "## 3. TSFresh Feature Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "259cbf23",
   "metadata": {},
   "outputs": [],
   "source": [
    "processed = pipe.run_process(dev_df, create_map=True, force=True)\n",
    "NOTEBOOK_CONTEXT['artifacts']['processed'] = processed\n",
    "print(f\"Processed feature space: {processed.shape[1]} columns\")\n",
    "\n",
    "meta = pipe.data_.get('tsfresh_metadata')\n",
    "if isinstance(meta, pd.DataFrame) and not meta.empty:\n",
    "    display(meta.head())\n",
    "else:\n",
    "    status = 'disabled via config' if not cfg.enable_tsfresh_features else 'not generated'\n",
    "    print(f'No TSFresh feature metadata available ({status}).')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c9d7720",
   "metadata": {},
   "source": [
    "## 4. Raw Numeric Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d4324ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "splits = pipe.run_split(processed, force=True)\n",
    "NOTEBOOK_CONTEXT['artifacts']['splits'] = splits\n",
    "raw_layers = pipe.results_.get('raw_numeric_layers', {})\n",
    "print(f\"Identified numeric features: {len(pipe.data_.get('numeric_features', []))}\")\n",
    "if raw_layers:\n",
    "    train_raw = raw_layers.get('train_raw_prepped')\n",
    "    if isinstance(train_raw, pd.DataFrame):\n",
    "        preview_cols = pipe.data_.get('numeric_features', [])[:10]\n",
    "        if preview_cols:\n",
    "            display(train_raw[preview_cols].head())\n",
    "\n",
    "impute_stats = getattr(pipe.data_processor, 'imputation_stats_', {})\n",
    "if impute_stats:\n",
    "    display(pd.DataFrame(impute_stats).T.head())\n",
    "\n",
    "config_summary = pd.DataFrame([\n",
    "    (\"Target column\", cfg.target_column),\n",
    "    (\"ID column\", cfg.id_column),\n",
    "    (\"Time column\", cfg.time_column),\n",
    "    (\"Train/Test/OOT split\", f\"{cfg.train_ratio:.0%}/{cfg.test_ratio:.0%}/{cfg.oot_ratio:.0%}\"),\n",
    "    (\"OOT holdout months\", cfg.oot_months),\n",
    "    (\"Risk band method\", cfg.risk_band_method),\n",
    "    (\"Calibration chain\", 'stage1 -> stage2'),\n",
    "], columns=['Parameter', 'Configured value'])\n",
    "display(config_summary)\n",
    "\n",
    "flag_toggles = pd.DataFrame({\n",
    "    'Feature': [\n",
    "        'Dual RAW+WOE flow',\n",
    "        'TSFresh feature mining',\n",
    "        'Noise sentinel checks',\n",
    "        'Optuna HPO',\n",
    "        'Stage 2 calibration',\n",
    "        'Scoring pipeline',\n",
    "        'SHAP importance',\n",
    "    ],\n",
    "    'Enabled': [\n",
    "        cfg.enable_dual,\n",
    "        cfg.enable_tsfresh_features,\n",
    "        cfg.use_noise_sentinel,\n",
    "        cfg.use_optuna,\n",
    "        cfg.enable_stage2_calibration,\n",
    "        cfg.enable_scoring,\n",
    "        cfg.calculate_shap,\n",
    "    ],\n",
    "})\n",
    "flag_toggles['Enabled'] = flag_toggles['Enabled'].map({True: 'Yes', False: 'No'})\n",
    "display(flag_toggles)\n",
    "\n",
    "thresholds = pd.DataFrame({\n",
    "    'Threshold': [\n",
    "        'PSI master',\n",
    "        'Monthly PSI',\n",
    "        'OOT PSI',\n",
    "        'Test PSI',\n",
    "        'IV floor',\n",
    "        'Univariate Gini floor',\n",
    "        'Correlation ceiling',\n",
    "        'VIF ceiling',\n",
    "        '|Train-OOT| Gini gap',\n",
    "    ],\n",
    "    'Value': [\n",
    "        cfg.psi_threshold,\n",
    "        cfg.monthly_psi_threshold,\n",
    "        cfg.oot_psi_threshold,\n",
    "        cfg.test_psi_threshold,\n",
    "        cfg.iv_threshold,\n",
    "        cfg.min_univariate_gini,\n",
    "        cfg.correlation_threshold,\n",
    "        cfg.vif_threshold,\n",
    "        cfg.max_train_oot_gap,\n",
    "    ],\n",
    "})\n",
    "display(thresholds)\n",
    "\n",
    "selection_order = pd.DataFrame({'Selection step': cfg.selection_steps})\n",
    "selection_order.index = selection_order.index + 1\n",
    "display(selection_order)\n",
    "\n",
    "algorithms = pd.DataFrame({'Algorithm': cfg.algorithms})\n",
    "algorithms.index = algorithms.index + 1\n",
    "display(algorithms)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7ca54b3",
   "metadata": {},
   "source": [
    "## 5. WOE Transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e814e4bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "woe_results = pipe.run_woe(splits, force=True)\n",
    "NOTEBOOK_CONTEXT['artifacts']['woe'] = woe_results\n",
    "values = woe_results.get('woe_values', {})\n",
    "print(f\"WOE maps generated for {len(values)} variables\")\n",
    "if values:\n",
    "    preview_rows = [\n",
    "        {\n",
    "            'variable': name,\n",
    "            'type': info.get('type'),\n",
    "            'iv': info.get('iv'),\n",
    "        }\n",
    "        for name, info in list(values.items())[:10]\n",
    "    ]\n",
    "    if preview_rows:\n",
    "        display(pd.DataFrame(preview_rows))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c47d674",
   "metadata": {},
   "source": [
    "## 6. Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c37859b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "selection_raw = pipe.run_selection(mode='RAW', splits=splits, woe_results=woe_results, force=True)\n",
    "selection_woe = pipe.run_selection(mode='WOE', splits=splits, woe_results=woe_results, force=True)\n",
    "\n",
    "NOTEBOOK_CONTEXT['artifacts']['selection']['RAW'] = selection_raw\n",
    "NOTEBOOK_CONTEXT['artifacts']['selection']['WOE'] = selection_woe\n",
    "\n",
    "summary = pd.DataFrame([\n",
    "    {'mode': 'RAW', 'selected_features': len(selection_raw.get('selected_features', []) or [])},\n",
    "    {'mode': 'WOE', 'selected_features': len(selection_woe.get('selected_features', []) or [])},\n",
    "])\n",
    "display(summary)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "138907b8",
   "metadata": {},
   "source": [
    "## 7. Modeling (RAW vs WOE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "544851ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _best_auc(payload):\n",
    "    scores = payload.get('scores', {}) or {}\n",
    "    preferred = payload.get('best_model_name')\n",
    "\n",
    "    def _score(metrics):\n",
    "        if not metrics:\n",
    "            return float('-inf')\n",
    "        for key in ('oot_auc', 'test_auc', 'train_auc'):\n",
    "            value = metrics.get(key)\n",
    "            if value is not None:\n",
    "                return value\n",
    "        return float('-inf')\n",
    "\n",
    "    if preferred and preferred in scores:\n",
    "        return _score(scores[preferred])\n",
    "    if scores:\n",
    "        return max((_score(metrics) for metrics in scores.values()), default=float('-inf'))\n",
    "    return float('-inf')\n",
    "\n",
    "models_raw = pipe.run_modeling(mode='RAW', splits=splits, selection_results=selection_raw, force=True)\n",
    "models_woe = pipe.run_modeling(mode='WOE', splits=splits, selection_results=selection_woe, force=True)\n",
    "\n",
    "NOTEBOOK_CONTEXT['artifacts']['modeling']['RAW'] = models_raw\n",
    "NOTEBOOK_CONTEXT['artifacts']['modeling']['WOE'] = models_woe\n",
    "\n",
    "frames = []\n",
    "for mode_label, payload in [('RAW', models_raw), ('WOE', models_woe)]:\n",
    "    scores = payload.get('scores', {})\n",
    "    if scores:\n",
    "        frame = pd.DataFrame(scores).T\n",
    "        frame['mode'] = mode_label\n",
    "        frames.append(frame)\n",
    "\n",
    "if frames:\n",
    "    combined = pd.concat(frames).reset_index().rename(columns={'index': 'model'})\n",
    "    if 'status' in combined.columns:\n",
    "        combined = combined.drop(columns=['status'])\n",
    "    display(combined.sort_values(['mode', 'oot_auc'], ascending=[True, False]))\n",
    "else:\n",
    "    print('No models trained for either mode.')\n",
    "\n",
    "flows = {\n",
    "    'RAW': {\n",
    "        'selection_results': selection_raw,\n",
    "        'model_results': models_raw,\n",
    "        'best_auc': _best_auc(models_raw),\n",
    "    },\n",
    "    'WOE': {\n",
    "        'selection_results': selection_woe,\n",
    "        'model_results': models_woe,\n",
    "        'best_auc': _best_auc(models_woe),\n",
    "    },\n",
    "}\n",
    "\n",
    "best_mode, best_flow = max(flows.items(), key=lambda item: item[1]['best_auc'])\n",
    "pipe.results_['flows'] = flows\n",
    "pipe.results_['best_mode'] = best_mode\n",
    "pipe.results_['selection_results'] = best_flow['selection_results']\n",
    "pipe.results_['model_results'] = best_flow['model_results']\n",
    "pipe.config.enable_woe = (best_mode == 'WOE')\n",
    "pipe.models_ = best_flow['model_results'].get('models', {})\n",
    "pipe.selected_features_ = best_flow['selection_results'].get('selected_features', [])\n",
    "\n",
    "print(f\"Best mode: {best_mode} | Best model: {best_flow['model_results'].get('best_model_name')}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b418397",
   "metadata": {},
   "source": [
    "## 8. Calibration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3b22237",
   "metadata": {},
   "outputs": [],
   "source": [
    "stage1 = pipe.run_stage1_calibration(model_results=pipe.results_['model_results'], calibration_df=cal_long_df, force=True)\n",
    "stage2 = pipe.run_stage2_calibration(stage1_results=stage1, recent_df=cal_recent_df, force=True)\n",
    "\n",
    "NOTEBOOK_CONTEXT['artifacts']['calibration']['stage1'] = stage1\n",
    "NOTEBOOK_CONTEXT['artifacts']['calibration']['stage2'] = stage2\n",
    "\n",
    "if isinstance(stage1, dict) and stage1.get('calibration_metrics'):\n",
    "    print('Stage 1 calibration metrics:')\n",
    "    display(pd.DataFrame([stage1['calibration_metrics']]))\n",
    "else:\n",
    "    print('Stage 1 calibration metrics unavailable.')\n",
    "\n",
    "if isinstance(stage2, dict) and stage2.get('stage2_metrics'):\n",
    "    print('Stage 2 calibration metrics:')\n",
    "    display(pd.DataFrame([stage2['stage2_metrics']]))\n",
    "else:\n",
    "    print('Stage 2 calibration metrics unavailable.')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72b0915d",
   "metadata": {},
   "source": [
    "## 9. Risk Band Optimisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bced66b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "bands = pipe.run_risk_bands(stage1_results=stage1, stage2_results=stage2, splits=pipe.results_.get('splits'), force=True)\n",
    "NOTEBOOK_CONTEXT['artifacts']['risk_bands'] = bands\n",
    "\n",
    "if isinstance(bands, dict):\n",
    "    metrics = bands.get('metrics')\n",
    "    band_stats = bands.get('band_stats') or bands.get('bands')\n",
    "    if isinstance(metrics, dict):\n",
    "        print('Risk band metrics:')\n",
    "        display(pd.DataFrame(metrics, index=['value']).T)\n",
    "    if isinstance(band_stats, pd.DataFrame) and not band_stats.empty:\n",
    "        display(band_stats.head(20))\n",
    "else:\n",
    "    print('Risk band optimisation output not available.')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fedfca08",
   "metadata": {},
   "source": [
    "## 10. Reporting & Diagnostics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27a9a750",
   "metadata": {},
   "outputs": [],
   "source": [
    "reports = pipe.run_reporting(force=True)\n",
    "NOTEBOOK_CONTEXT['artifacts']['reports'] = reports\n",
    "\n",
    "excel_path = Path(cfg.output_excel_path)\n",
    "if excel_path.exists():\n",
    "    print(f\"Excel workbook generated: {excel_path}\")\n",
    "    try:\n",
    "        xls = pd.ExcelFile(excel_path)\n",
    "        print('Workbook sheets:')\n",
    "        for sheet in xls.sheet_names:\n",
    "            print(' -', sheet)\n",
    "    except Exception as exc:\n",
    "        print('Excel inspection failed:', exc)\n",
    "else:\n",
    "    print('Excel workbook has not been created.')\n",
    "\n",
    "available_reports = sorted((reports or {}).keys())\n",
    "if available_reports:\n",
    "    display(pd.DataFrame({'report_key': available_reports}))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73559e3b",
   "metadata": {},
   "source": [
    "## 11. Consolidated Pipeline Run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbfb8169",
   "metadata": {},
   "outputs": [],
   "source": [
    "full_pipe = UnifiedRiskPipeline(cfg)\n",
    "full_results = full_pipe.fit(\n",
    "    dev_df,\n",
    "    data_dictionary=data_dictionary,\n",
    "    calibration_df=cal_long_df,\n",
    "    stage2_df=cal_recent_df,\n",
    "    score_df=score_df,\n",
    ")\n",
    "\n",
    "NOTEBOOK_CONTEXT['artifacts']['full_run'] = full_results\n",
    "print(f\"Best mode: {full_results.get('best_model_mode')} | Best model: {full_results.get('best_model_name')}\")\n",
    "registry = pd.DataFrame(full_results.get('model_registry', []))\n",
    "if not registry.empty:\n",
    "    display(registry.sort_values(['mode', 'oot_auc'], ascending=[True, False]).head(20))\n",
    "else:\n",
    "    print('Model registry is empty.')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe1a2f08",
   "metadata": {},
   "source": [
    "## 12. Scoring on Recent Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1067aaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "scoring_output = pipe.run_scoring(score_df, force=True)\n",
    "NOTEBOOK_CONTEXT['artifacts']['scoring'] = scoring_output\n",
    "\n",
    "scored_df = scoring_output.get('dataframe') if isinstance(scoring_output, dict) else None\n",
    "if isinstance(scored_df, pd.DataFrame):\n",
    "    display(scored_df.head(10))\n",
    "else:\n",
    "    print('Scored dataframe unavailable.')\n",
    "\n",
    "metrics = scoring_output.get('metrics') if isinstance(scoring_output, dict) else None\n",
    "if isinstance(metrics, dict) and metrics:\n",
    "    display(pd.DataFrame([metrics]).T)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ef1032f",
   "metadata": {},
   "source": [
    "## 13. Detayli Rapor Aciklamalari"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e23fe3ab",
   "metadata": {},
   "source": [
    "**Model Ozeti & Performans**\n",
    "- models_summary\n",
    "- best_model\n",
    "- best_model_vars_df\n",
    "- confusion_matrix\n",
    "- performance_report (AUC, Gini, KS, Brier, LogLoss, F1, Precision, Recall)\n",
    "- lift_table (band, records, events, mean_score, lift, ks, capture_rate)\n",
    "- baseline_metrics ve baseline_lift_table\n",
    "- shap_importance\n",
    "\n",
    "**Degisken Analizi**\n",
    "- final_vars\n",
    "- top20_iv\n",
    "- top50_univariate\n",
    "- selection_history\n",
    "- correlation_clusters\n",
    "- vif_summary\n",
    "- noise_sentinel_check\n",
    "- variable_dictionary\n",
    "- shap_summary\n",
    "\n",
    "**WOE & Binning**\n",
    "- woe_mapping (numeric ve kategorik detay)\n",
    "- woe_bins (degisken bazinda bin istatistikleri)\n",
    "- best_model_details (bin_number, bin_range, woe, counts, event_rate, iv_contrib, importance)\n",
    "- woe_degradation (raw ve woe gini farki)\n",
    "\n",
    "**Stabilite & Validasyon**\n",
    "- psi_summary, psi_dropped_features (train vs test, train vs oot)\n",
    "- WOE_PSI, Score_PSI, Quantile_PSI\n",
    "- run_meta (calisma parametreleri)\n",
    "- monitor_report (score_psi, feature_psi)\n",
    "\n",
    "**Kalibrasyon**\n",
    "- calibration_metrics (Brier, ECE, MCE, Spiegelhalter z/p)\n",
    "- calibration_tables (band bazinda observed_pd, predicted_pd, guven araliklari, binomial p)\n",
    "- stage1 ve stage2 ciktisi\n",
    "- hosmer_lemeshow sonucu\n",
    "\n",
    "**Risk Bantlari & Skorlama**\n",
    "- risk_bands (min_score, max_score, mean_score, n_samples, n_events, event_rate, sample_pct)\n",
    "- band_tests: binomial_test, hosmer_lemeshow_test, herfindahl_index, monotonicity, band_psi\n",
    "- risk_band_summary (scaled_score 300-850, risk_level)\n",
    "- risk_score_mapping (SQL/Python uretimi)\n",
    "- scoring_summary ve scored_data\n",
    "\n",
    "**PD Binleme Optimizasyonu**\n",
    "- micro_bins\n",
    "- evaluate_bins (CI, DR-PD farki, HHI, agirlik, monotonluk, binomial pass weight)\n",
    "- calculate_penalty (ceza bilesenleri: CI overlap, binomial fail/pas, DR-PD, HHI, weight, monotonicity)\n",
    "- multi_start_optimization -> stepwise_optimize (fazlar: CI, Binomial, ince ayar)\n",
    "- report_results (optimum esikler ve detay tablo)\n",
    "\n",
    "**CLI / Notebook / Surec**\n",
    "- Tek pipeline akisi (config ile dual secenekler)\n",
    "- Train + OOT zorunlu; varsa sozluk rapora eklenir\n",
    "- Secim akisi: PSI -> IV -> Correlation/VIF -> Boruta -> Stepwise (+noise sentinel)\n",
    "- Algoritmalar: Logistic, GAM, CatBoost, LightGBM, XGBoost, RandomForest, ExtraTrees\n",
    "- Notebook: end-to-end calisma, skor uretimi ve prediction\n",
    "\n",
    "**Operasyon & Iyilestirme**\n",
    "- README ve lisans kontrolleri\n",
    "- Test kapsamini ve CI/CD akisini takip edin\n",
    "- Surumleme, pre-commit, drift izleme (PSI/KS otomasyonu, alarm mekanizmalari)\n",
    "\n",
    "**Git Is Akisi**\n",
    "- development dalini guncel tutun (fetch/checkout/pull)\n",
    "- git status ve remote show origin ile takibi surdurun\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
