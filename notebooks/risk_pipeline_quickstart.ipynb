{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "244c9779",
   "metadata": {},
   "source": [
    "# Credit Risk Pipeline Quickstart\n",
    "\n",
    "This notebook runs the **Unified Risk Pipeline** end-to-end on the bundled synthetic dataset.\n",
    "The sample includes stratified monthly observations, calibration hold-outs, stage-2 data, and a future scoring batch\n",
    "so each major step can be validated quickly.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f55c9a1a",
   "metadata": {},
   "source": [
    "## 1. Environment & Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22d95991",
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib\n",
    "import importlib.metadata as metadata\n",
    "import importlib.util\n",
    "import subprocess\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "\n",
    "def _locate_project_root() -> Path:\n",
    "    cwd = Path.cwd().resolve()\n",
    "    if (cwd / 'src' / 'risk_pipeline').exists():\n",
    "        return cwd\n",
    "    candidate = cwd / 'risk-model-pipeline-dev'\n",
    "    if (candidate / 'src' / 'risk_pipeline').exists():\n",
    "        return candidate\n",
    "    for parent in cwd.parents:\n",
    "        maybe = parent / 'risk-model-pipeline-dev'\n",
    "        if (maybe / 'src' / 'risk_pipeline').exists():\n",
    "            return maybe\n",
    "    return cwd\n",
    "\n",
    "\n",
    "PROJECT_ROOT = _locate_project_root()\n",
    "SRC_PATH = PROJECT_ROOT / 'src'\n",
    "PACKAGE_PATH = SRC_PATH / 'risk_pipeline'\n",
    "MODULE_INIT = PACKAGE_PATH / '__init__.py'\n",
    "if SRC_PATH.exists() and str(SRC_PATH) not in sys.path:\n",
    "    sys.path.insert(0, str(SRC_PATH))\n",
    "\n",
    "TARGET_VERSION = '0.4.1'\n",
    "GIT_SPEC = 'risk-pipeline[ml,notebook] @ git+https://github.com/selimoksuz/risk-model-pipeline.git@development'\n",
    "PREREQ_PACKAGES = [\n",
    "    'numba==0.59.1',\n",
    "    'llvmlite==0.42.0',\n",
    "    'scipy==1.11.4',\n",
    "    'pandas==2.3.2',\n",
    "    'tsfresh==0.20.1',\n",
    "    'matrixprofile==1.1.10',\n",
    "    'shap==0.48.0',\n",
    "    'stumpy==1.13.0',\n",
    "]\n",
    "\n",
    "\n",
    "def _parse_version(value: str):\n",
    "    parts = []\n",
    "    for part in value.split('.'):\n",
    "        if not part.isdigit():\n",
    "            break\n",
    "        parts.append(int(part))\n",
    "    return tuple(parts)\n",
    "\n",
    "\n",
    "def _run_pip(args):\n",
    "    subprocess.check_call([\n",
    "        sys.executable,\n",
    "        '-m',\n",
    "        'pip',\n",
    "        'install',\n",
    "        '--no-cache-dir',\n",
    "        '--upgrade',\n",
    "        '--force-reinstall',\n",
    "        *args,\n",
    "    ])\n",
    "\n",
    "\n",
    "def _install_prerequisites():\n",
    "    print(f\"Installing prerequisite stack: {', '.join(PREREQ_PACKAGES)}\")\n",
    "    _run_pip(PREREQ_PACKAGES)\n",
    "\n",
    "\n",
    "def _sanity_check():\n",
    "    import shap  # noqa: F401\n",
    "    from llvmlite import binding as _ll_binding\n",
    "    _ = _ll_binding.ffi.lib\n",
    "    from numba import njit\n",
    "\n",
    "    @njit\n",
    "    def _probe(x):\n",
    "        return x + 1\n",
    "\n",
    "    assert _probe(1) == 2\n",
    "\n",
    "\n",
    "def _tsfresh_smoke_test():\n",
    "    import pandas as pd\n",
    "    from tsfresh import extract_features\n",
    "    from tsfresh.feature_extraction import EfficientFCParameters\n",
    "\n",
    "    data = pd.DataFrame(\n",
    "        {\n",
    "            'id': ['a', 'a', 'a', 'b', 'b', 'b'],\n",
    "            'time': [0, 1, 2, 0, 1, 2],\n",
    "            'value': [1.0, 2.0, 3.0, 4.0, 9.0, 16.0],\n",
    "        }\n",
    "    )\n",
    "    features = extract_features(\n",
    "        data,\n",
    "        column_id='id',\n",
    "        column_sort='time',\n",
    "        column_value='value',\n",
    "        default_fc_parameters=EfficientFCParameters(),\n",
    "        disable_progressbar=True,\n",
    "        n_jobs=0,\n",
    "    )\n",
    "    if not any('entropy' in col for col in features.columns):\n",
    "        raise RuntimeError('tsfresh smoke test did not produce entropy features')\n",
    "\n",
    "\n",
    "def _resolve_installed_version(module):\n",
    "    module_path = Path(getattr(module, '__file__', '')).resolve()\n",
    "    if SRC_PATH in module_path.parents:\n",
    "        return TARGET_VERSION\n",
    "    try:\n",
    "        return metadata.version('risk-pipeline')\n",
    "    except metadata.PackageNotFoundError:\n",
    "        return '0.0.0'\n",
    "\n",
    "\n",
    "def _load_local_package():\n",
    "    if not MODULE_INIT.exists():\n",
    "        return None\n",
    "    spec = importlib.util.spec_from_file_location('risk_pipeline', MODULE_INIT)\n",
    "    if spec and spec.loader:\n",
    "        module = importlib.util.module_from_spec(spec)\n",
    "        sys.modules['risk_pipeline'] = module\n",
    "        spec.loader.exec_module(module)\n",
    "        return module\n",
    "    return None\n",
    "\n",
    "\n",
    "def ensure_risk_pipeline():\n",
    "    print(f\"Resolved project root: {PROJECT_ROOT}\")\n",
    "    try:\n",
    "        module = _load_local_package()\n",
    "        if module is None:\n",
    "            module = importlib.import_module('risk_pipeline')\n",
    "        installed = _resolve_installed_version(module)\n",
    "        if _parse_version(installed) < _parse_version(TARGET_VERSION):\n",
    "            raise ModuleNotFoundError(f'risk-pipeline {installed} < {TARGET_VERSION}')\n",
    "        print(f'risk-pipeline {installed} available (path: {module.__file__}).')\n",
    "        _sanity_check()\n",
    "        _tsfresh_smoke_test()\n",
    "    except Exception as exc:\n",
    "        print(f'risk-pipeline import failed: {exc}')\n",
    "        try:\n",
    "            _install_prerequisites()\n",
    "            print(f'Attempting GitHub install: {GIT_SPEC}')\n",
    "            _run_pip([GIT_SPEC])\n",
    "            print('GitHub install succeeded.')\n",
    "            raise SystemExit('Installation complete. Restart the kernel and rerun this cell.')\n",
    "        except subprocess.CalledProcessError as err:\n",
    "            print(f'GitHub install failed: {err}')\n",
    "            raise SystemExit('Installation failed. Review the errors above.')\n",
    "    else:\n",
    "        print('Numba/llvmlite sanity check passed.')\n",
    "        print('tsfresh smoke test passed (entropy features available).')\n",
    "\n",
    "\n",
    "ensure_risk_pipeline()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a762023",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "\n",
    "from IPython.display import display\n",
    "\n",
    "from risk_pipeline.data.sample import load_credit_risk_sample\n",
    "\n",
    "sample = load_credit_risk_sample()\n",
    "OUTPUT_DIR = Path('output/credit_risk_sample_notebook')\n",
    "OUTPUT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "dev_df = sample.development.copy()\n",
    "cal_long_df = sample.calibration_longrun.copy()\n",
    "cal_recent_df = sample.calibration_recent.copy()\n",
    "score_df = sample.scoring_future.copy()\n",
    "data_dictionary = sample.data_dictionary.copy()\n",
    "\n",
    "print(f\"Development dataset: {dev_df.shape[0]:,} rows, {dev_df.shape[1]} columns\")\n",
    "print(f\"Stage 1 calibration dataset: {cal_long_df.shape[0]:,} rows\")\n",
    "print(f\"Stage 2 calibration dataset: {cal_recent_df.shape[0]:,} rows\")\n",
    "print(f\"Scoring dataset: {score_df.shape[0]:,} rows\")\n",
    "\n",
    "display(dev_df.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e810cc0",
   "metadata": {},
   "source": [
    "## 2. Pipeline Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10426cfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "from risk_pipeline.core.config import Config\n",
    "from risk_pipeline.unified_pipeline import UnifiedRiskPipeline\n",
    "\n",
    "cfg = Config(\n",
    "    # Core identifiers\n",
    "    target_column='target',\n",
    "    id_column='customer_id',\n",
    "    time_column='app_dt',\n",
    "    snapshot_column='snapshot_month',\n",
    "\n",
    "    # Split configuration\n",
    "    create_test_split=True,\n",
    "    stratify_test=True,\n",
    "    train_ratio=0.6,\n",
    "    test_ratio=0.2,\n",
    "    oot_ratio=0.2,\n",
    "    oot_months=3,\n",
    "    equal_default_splits=False,\n",
    "\n",
    "    # TSFresh controls\n",
    "    enable_tsfresh_features=True,\n",
    "    tsfresh_feature_set='efficient',\n",
    "    tsfresh_n_jobs=4,\n",
    "    tsfresh_cpu_fraction=0.75,\n",
    "\n",
    "    # Feature selection strategy\n",
    "    selection_steps=[\n",
    "        'univariate',\n",
    "        'psi',\n",
    "        'vif',\n",
    "        'correlation',\n",
    "        'iv',\n",
    "        'boruta',\n",
    "        'stepwise',\n",
    "    ],\n",
    "    min_univariate_gini=0.05,\n",
    "    psi_threshold=0.25,\n",
    "    monthly_psi_threshold=0.15,\n",
    "    oot_psi_threshold=0.25,\n",
    "    max_vif=5.0,\n",
    "    correlation_threshold=0.9,\n",
    "    iv_threshold=0.02,\n",
    "    stepwise_method='forward',\n",
    "    stepwise_max_features=25,\n",
    "\n",
    "    # Model training preferences\n",
    "    algorithms=[\n",
    "        'logistic',\n",
    "        'lightgbm',\n",
    "        'xgboost',\n",
    "        'catboost',\n",
    "        'randomforest',\n",
    "        'extratrees',\n",
    "        'woe_boost',\n",
    "    ],\n",
    "    model_selection_method='gini_oot',\n",
    "    model_stability_weight=0.2,\n",
    "    min_gini_threshold=0.5,\n",
    "    max_train_oot_gap=0.03,\n",
    "    use_optuna=True,\n",
    "    hpo_trials=75,\n",
    "    hpo_timeout_sec=1800,\n",
    "\n",
    "    # Diagnostics & toggles\n",
    "    use_noise_sentinel=True,\n",
    "    enable_dual_pipeline=True,\n",
    "    enable_woe_boost_scorecard=True,\n",
    "    calculate_shap=True,\n",
    "    enable_scoring=True,\n",
    "    enable_stage2_calibration=True,\n",
    "\n",
    "    # Risk band settings\n",
    "    n_risk_bands=10,\n",
    "    risk_band_method='pd_constraints',\n",
    "    risk_band_min_bins=7,\n",
    "    risk_band_max_bins=10,\n",
    "    risk_band_hhi_threshold=0.15,\n",
    "    risk_band_binomial_pass_weight=0.85,\n",
    "\n",
    "    # Runtime controls\n",
    "    random_state=42,\n",
    "    n_jobs=-1,\n",
    ")\n",
    "\n",
    "pipe = UnifiedRiskPipeline(cfg)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed1555b8",
   "metadata": {},
   "source": [
    "## 3. TSFresh Feature Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fbab735",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "processed = pipe.run_process(dev_df, create_map=True, force=True)\n",
    "print(f\"Processed feature space: {processed.shape[1]} columns\")\n",
    "\n",
    "if pipe.data_.get('tsfresh_metadata') is not None and not pipe.data_['tsfresh_metadata'].empty:\n",
    "    display(pipe.data_['tsfresh_metadata'].head())\n",
    "else:\n",
    "    print('No TSFresh features were generated (configuration disabled).')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "251cad32",
   "metadata": {},
   "source": [
    "## 4. Raw Numeric Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af1fea4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "splits = pipe.run_split(processed, force=True)\n",
    "raw_layers = pipe.results_.get('raw_numeric_layers', {})\n",
    "print(f\"Identified numeric features: {len(pipe.data_.get('numeric_features', []))}\")\n",
    "if raw_layers:\n",
    "    train_raw = raw_layers.get('train_raw_prepped')\n",
    "    if train_raw is not None:\n",
    "        display(train_raw[pipe.data_.get('numeric_features', [])].head())\n",
    "else:\n",
    "    print('No numeric preprocessing layer was created.')\n",
    "\n",
    "impute_stats = getattr(pipe.data_processor, 'imputation_stats_', {})\n",
    "if impute_stats:\n",
    "    display(pd.DataFrame(impute_stats).T.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fe6e1e4",
   "metadata": {},
   "source": [
    "## 5. WOE Transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fc3bbb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "woe_results = pipe.run_woe(splits, force=True)\n",
    "woe_values = woe_results.get('woe_values', {})\n",
    "print(f\"WOE maps generated for {len(woe_values)} variables\")\n",
    "if woe_values:\n",
    "    preview = pd.DataFrame([\n",
    "        {\n",
    "            'variable': name,\n",
    "            'type': info.get('type'),\n",
    "            'iv': info.get('iv'),\n",
    "        }\n",
    "        for name, info in list(woe_values.items())[:5]\n",
    "    ])\n",
    "    display(preview)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60fc5aa0",
   "metadata": {},
   "source": [
    "## 6. Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "699f3d4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "selection_raw = pipe.run_selection(mode='RAW', splits=splits, woe_results=woe_results, force=True)\n",
    "selection_woe = pipe.run_selection(mode='WOE', splits=splits, woe_results=woe_results, force=True)\n",
    "\n",
    "selection_summary = pd.DataFrame([\n",
    "    {'mode': 'RAW', 'n_features': len(selection_raw.get('selected_features', []))},\n",
    "    {'mode': 'WOE', 'n_features': len(selection_woe.get('selected_features', []))},\n",
    "])\n",
    "print('Selected feature counts by mode:')\n",
    "display(selection_summary)\n",
    "\n",
    "pipe.results_['selection_results_RAW'] = selection_raw\n",
    "pipe.results_['selection_results_WOE'] = selection_woe\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0af1f05",
   "metadata": {},
   "source": [
    "## 7. Modeling (RAW vs WOE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "339a6045",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def _best_auc(model_results):\n",
    "    scores = model_results.get('scores', {}) or {}\n",
    "    preferred = model_results.get('best_model_name')\n",
    "\n",
    "    def _score(metrics):\n",
    "        if not metrics:\n",
    "            return float('-inf')\n",
    "        for key in ('oot_auc', 'test_auc', 'train_auc'):\n",
    "            value = metrics.get(key)\n",
    "            if value is not None:\n",
    "                return value\n",
    "        return float('-inf')\n",
    "\n",
    "    if preferred and preferred in scores:\n",
    "        return _score(scores[preferred])\n",
    "    if scores:\n",
    "        return max((_score(metrics) for metrics in scores.values()), default=float('-inf'))\n",
    "    return float('-inf')\n",
    "\n",
    "models_raw = pipe.run_modeling(mode='RAW', splits=splits, selection_results=selection_raw, force=True)\n",
    "models_woe = pipe.run_modeling(mode='WOE', splits=splits, selection_results=selection_woe, force=True)\n",
    "\n",
    "score_frames = []\n",
    "for mode_label, payload in [('RAW', models_raw), ('WOE', models_woe)]:\n",
    "    scores = payload.get('scores', {})\n",
    "    if scores:\n",
    "        frame = pd.DataFrame(scores).T\n",
    "        frame['mode'] = mode_label\n",
    "        score_frames.append(frame)\n",
    "\n",
    "if score_frames:\n",
    "    combined = pd.concat(score_frames).reset_index().rename(columns={'index': 'model'})\n",
    "    display(combined.sort_values(['mode', 'oot_auc'], ascending=[True, False]))\n",
    "else:\n",
    "    print('No models were trained.')\n",
    "\n",
    "flows = {\n",
    "    'RAW': {'selection_results': selection_raw, 'model_results': models_raw, 'best_auc': _best_auc(models_raw)},\n",
    "    'WOE': {'selection_results': selection_woe, 'model_results': models_woe, 'best_auc': _best_auc(models_woe)},\n",
    "}\n",
    "\n",
    "best_mode = max(flows.items(), key=lambda item: item[1]['best_auc'])[0]\n",
    "best_flow = flows[best_mode]\n",
    "\n",
    "pipe.results_['flows'] = flows\n",
    "pipe.results_['best_mode'] = best_mode\n",
    "pipe.results_['selection_results'] = best_flow['selection_results']\n",
    "pipe.results_['model_results'] = best_flow['model_results']\n",
    "pipe.config.enable_woe = (best_mode == 'WOE')\n",
    "pipe.models_ = best_flow['model_results'].get('models', {})\n",
    "pipe.selected_features_ = best_flow['selection_results'].get('selected_features', [])\n",
    "\n",
    "print(f\"Best mode: {best_mode} | Best model: {best_flow['model_results'].get('best_model_name')}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28851631",
   "metadata": {},
   "source": [
    "## 8. Calibration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a607124",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "stage1 = pipe.run_stage1_calibration(model_results=pipe.results_['model_results'], calibration_df=cal_long_df, force=True)\n",
    "stage2 = pipe.run_stage2_calibration(stage1_results=stage1, recent_df=cal_recent_df, force=True)\n",
    "\n",
    "if isinstance(stage1, dict) and stage1.get('calibration_curve') is not None:\n",
    "    curve = stage1['calibration_curve']\n",
    "    if hasattr(curve, 'head'):\n",
    "        display(curve.head())\n",
    "\n",
    "pipe.results_['calibration_stage1'] = stage1\n",
    "pipe.results_['calibration_stage2'] = stage2\n",
    "print('Stage 1 and Stage 2 calibration completed.')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efff055f",
   "metadata": {},
   "source": [
    "## 9. Risk Band Optimisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "363e6d41",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "bands = pipe.run_risk_bands(stage2_results=stage2, splits=pipe.results_['splits'], force=True)\n",
    "pipe.results_['risk_bands'] = bands\n",
    "\n",
    "if isinstance(bands, dict):\n",
    "    metrics = bands.get('metrics')\n",
    "    if isinstance(metrics, dict):\n",
    "        display(pd.DataFrame(metrics, index=['value']).T)\n",
    "    else:\n",
    "        print('Risk band metrics not available.')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3347a97c",
   "metadata": {},
   "source": [
    "## 10. Consolidated Pipeline Run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7605948",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "full_pipe = UnifiedRiskPipeline(cfg)\n",
    "full_results = full_pipe.fit(\n",
    "    dev_df,\n",
    "    data_dictionary=data_dictionary,\n",
    "    calibration_df=cal_long_df,\n",
    "    stage2_df=cal_recent_df,\n",
    "    score_df=score_df,\n",
    ")\n",
    "\n",
    "print(f\"Best mode: {full_results.get('best_model_mode')} | Best model: {full_results.get('best_model_name')}\")\n",
    "print('Model registry (top rows):')\n",
    "model_registry = pd.DataFrame(full_results.get('model_registry', []))\n",
    "if not model_registry.empty:\n",
    "    display(model_registry.sort_values(['mode', 'oot_auc'], ascending=[True, False]).head())\n",
    "else:\n",
    "    print('Model registry is empty.')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a90f6e6e",
   "metadata": {},
   "source": [
    "## 11. Recent Raw Data Scoring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fe3d0c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "scoring_output = pipe.run_scoring(score_df, force=True)\n",
    "scored_df = scoring_output.get('dataframe')\n",
    "if scored_df is not None:\n",
    "    display(scored_df.head())\n",
    "metrics = scoring_output.get('metrics')\n",
    "if metrics:\n",
    "    print('Scoring metrics:')\n",
    "    display(pd.DataFrame(metrics, index=[0]).T)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a84c253f",
   "metadata": {},
   "source": [
    "For automation examples, see examples/quickstart_demo.py."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
