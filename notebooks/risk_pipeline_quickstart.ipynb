{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5dfd24c9",
   "metadata": {},
   "source": [
    "# Credit Risk Pipeline Quickstart\n",
    "\n",
    "This notebook runs the **Unified Risk Pipeline** end-to-end on the bundled synthetic dataset.\n",
    "The sample includes stratified monthly observations, calibration hold-outs, stage-2 data, and a future scoring batch\n",
    "so each major step can be validated quickly.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff4cc2bd",
   "metadata": {},
   "source": [
    "## 0. Environment setup\n",
    "\n",
    "This cell ensures `risk-pipeline` 0.4.1 is installed from the GitHub `development` branch.\n",
    "Restart the kernel and rerun after refreshing the environment.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e44d8807",
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib\n",
    "import importlib.metadata as metadata\n",
    "import subprocess\n",
    "import sys\n",
    "\n",
    "TARGET_VERSION = \"0.4.1\"\n",
    "GIT_SPEC = \"risk-pipeline[ml,notebook] @ git+https://github.com/selimoksuz/risk-model-pipeline.git@development\"\n",
    "PREREQ_PACKAGES = [\n",
    "    \"numba==0.59.1\",\n",
    "    \"llvmlite==0.42.0\",\n",
    "    \"scipy==1.11.4\",\n",
    "    \"pandas==2.3.2\",\n",
    "    \"tsfresh==0.20.1\",\n",
    "    \"matrixprofile==1.1.10\",\n",
    "    \"shap==0.48.0\",\n",
    "    \"stumpy==1.13.0\",\n",
    "]\n",
    "\n",
    "def _parse_version(value: str):\n",
    "    parts = []\n",
    "    for part in value.split('.'):\n",
    "        if not part.isdigit():\n",
    "            break\n",
    "        parts.append(int(part))\n",
    "    return tuple(parts)\n",
    "\n",
    "def _run_pip(args):\n",
    "    subprocess.check_call([\n",
    "        sys.executable,\n",
    "        \"-m\",\n",
    "        \"pip\",\n",
    "        \"install\",\n",
    "        \"--no-cache-dir\",\n",
    "        \"--upgrade\",\n",
    "        \"--force-reinstall\",\n",
    "        *args,\n",
    "    ])\n",
    "\n",
    "def _install_prerequisites():\n",
    "    print(f\"Installing prerequisite stack: {', '.join(PREREQ_PACKAGES)}\")\n",
    "    _run_pip(PREREQ_PACKAGES)\n",
    "\n",
    "def _sanity_check():\n",
    "    import shap  # noqa: F401\n",
    "    from llvmlite import binding as _ll_binding\n",
    "    _ = _ll_binding.ffi.lib\n",
    "    from numba import njit\n",
    "\n",
    "    @njit\n",
    "    def _probe(x):\n",
    "        return x + 1\n",
    "\n",
    "    assert _probe(1) == 2\n",
    "\n",
    "def _tsfresh_smoke_test():\n",
    "    import pandas as pd\n",
    "    from tsfresh import extract_features\n",
    "    from tsfresh.feature_extraction import EfficientFCParameters\n",
    "\n",
    "    data = pd.DataFrame(\n",
    "        {\n",
    "            \"id\": [\"a\", \"a\", \"a\", \"b\", \"b\", \"b\"],\n",
    "            \"time\": [0, 1, 2, 0, 1, 2],\n",
    "            \"value\": [1.0, 2.0, 3.0, 4.0, 9.0, 16.0],\n",
    "        }\n",
    "    )\n",
    "    features = extract_features(\n",
    "        data,\n",
    "        column_id=\"id\",\n",
    "        column_sort=\"time\",\n",
    "        column_value=\"value\",\n",
    "        default_fc_parameters=EfficientFCParameters(),\n",
    "        disable_progressbar=True,\n",
    "        n_jobs=0,\n",
    "    )\n",
    "    if not any(\"entropy\" in col for col in features.columns):\n",
    "        raise RuntimeError(\"tsfresh smoke test did not produce entropy features\")\n",
    "\n",
    "def ensure_risk_pipeline():\n",
    "    try:\n",
    "        importlib.import_module(\"risk_pipeline\")\n",
    "        installed = metadata.version(\"risk-pipeline\")\n",
    "        if _parse_version(installed) < _parse_version(TARGET_VERSION):\n",
    "            raise ModuleNotFoundError(f\"risk-pipeline {installed} < {TARGET_VERSION}\")\n",
    "        print(f\"risk-pipeline {installed} already installed.\")\n",
    "        _sanity_check()\n",
    "        _tsfresh_smoke_test()\n",
    "    except Exception as exc:\n",
    "        print(f\"risk-pipeline import failed: {exc}\")\n",
    "        try:\n",
    "            _install_prerequisites()\n",
    "            print(f\"Attempting GitHub install: {GIT_SPEC}\")\n",
    "            _run_pip([GIT_SPEC])\n",
    "            print(\"GitHub install succeeded.\")\n",
    "            raise SystemExit(\"Installation complete. Restart the kernel and rerun this cell.\")\n",
    "        except subprocess.CalledProcessError as err:\n",
    "            print(f\"GitHub install failed: {err}\")\n",
    "            raise SystemExit(\"Installation failed. Review the errors above.\")\n",
    "    else:\n",
    "        print(\"Numba/llvmlite sanity check passed.\")\n",
    "        print(\"tsfresh smoke test passed (entropy features available).\")\n",
    "\n",
    "ensure_risk_pipeline()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d62ed2c3",
   "metadata": {},
   "source": [
    "## 1. Imports and sample loader\n",
    "\n",
    "The dataset ships with the package under `risk_pipeline.data.sample`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c082243b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "\n",
    "from IPython.display import display\n",
    "\n",
    "from risk_pipeline.core.config import Config\n",
    "from risk_pipeline.unified_pipeline import UnifiedRiskPipeline\n",
    "from risk_pipeline.data.sample import load_credit_risk_sample\n",
    "\n",
    "sample = load_credit_risk_sample()\n",
    "OUTPUT_DIR = Path('output/credit_risk_sample_notebook')\n",
    "OUTPUT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "dev_df = sample.development\n",
    "cal_long_df = sample.calibration_longrun\n",
    "cal_recent_df = sample.calibration_recent\n",
    "score_df = sample.scoring_future\n",
    "data_dictionary = sample.data_dictionary\n",
    "\n",
    "dev_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d401383f",
   "metadata": {},
   "source": [
    "## 2. Quick sanity checks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eee0dafa",
   "metadata": {},
   "outputs": [],
   "source": [
    "dev_df['target'].value_counts(normalize=True).rename('default_rate')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fe05a0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "dev_df.groupby('snapshot_month')['target'].mean().rename('monthly_default_rate')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41159584",
   "metadata": {},
   "source": [
    "## 3. Configure the pipeline\n",
    "\n",
    "The configuration below enables dual modelling (raw + WoE), Optuna (single rapid trial), balanced model selection with stability guard rails,\n",
    "noise sentinel monitoring, SHAP explainability, the WoE-LI and Shao logistic challengers, and the PD-constrained risk band optimizer.\n",
    "Train/Test/OOT ratios and all threshold knobs (PSI/IV/Gini/Correlation) are explicit so the notebook mirrors production-ready configuration files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2a49bfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg = Config(\n",
    "    target_column='target',\n",
    "    id_column='customer_id',\n",
    "    time_column='app_dt',\n",
    "    create_test_split=True,\n",
    "    use_test_split=True,\n",
    "    train_ratio=0.6,\n",
    "    test_ratio=0.2,\n",
    "    oot_ratio=0.2,\n",
    "    stratify_test=True,\n",
    "    oot_months=2,\n",
    "    enable_dual=True,\n",
    "    enable_tsfresh_features=True,\n",
    "    tsfresh_feature_set='efficient',\n",
    "    tsfresh_n_jobs=-1,\n",
    "    enable_scoring=True,\n",
    "    enable_stage2_calibration=True,\n",
    "    output_folder=str(OUTPUT_DIR),\n",
    "    selection_steps=['psi', 'univariate', 'iv', 'correlation', 'boruta', 'stepwise'],\n",
    "    algorithms=[\n",
    "        'logistic', 'gam', 'catboost', 'lightgbm', 'xgboost',\n",
    "        'randomforest', 'extratrees', 'woe_boost', 'woe_li', 'shao', 'xbooster',\n",
    "    ],\n",
    "    model_selection_method='balanced',\n",
    "    model_stability_weight=0.25,\n",
    "    min_gini_threshold=0.45,\n",
    "    max_train_oot_gap=0.08,\n",
    "    psi_threshold=0.25,\n",
    "    iv_threshold=0.02,\n",
    "    univariate_gini_threshold=0.05,\n",
    "    correlation_threshold=0.95,\n",
    "    vif_threshold=5.0,\n",
    "    woe_binning_strategy='iv_optimal',\n",
    "    use_optuna=True,\n",
    "    n_trials=1,\n",
    "    optuna_timeout=120,\n",
    "    hpo_method='optuna',\n",
    "    hpo_trials=1,\n",
    "    hpo_timeout_sec=120,\n",
    "    use_noise_sentinel=True,\n",
    "    calculate_shap=True,\n",
    "    shap_sample_size=500,\n",
    "    risk_band_method='pd_constraints',\n",
    "    n_risk_bands=8,\n",
    "    risk_band_min_bins=7,\n",
    "    risk_band_max_bins=10,\n",
    "    risk_band_micro_bins=1000,\n",
    "    risk_band_min_weight=0.05,\n",
    "    risk_band_max_weight=0.30,\n",
    "    risk_band_hhi_threshold=0.15,\n",
    "    risk_band_binomial_pass_weight=0.85,\n",
    "    risk_band_alpha=0.05,\n",
    "    risk_band_pd_dr_tolerance=1e-4,\n",
    "    risk_band_max_iterations=100,\n",
    "    risk_band_max_phase_iterations=50,\n",
    "    risk_band_early_stop_rounds=10,\n",
    "    calibration_stage1_method='isotonic',\n",
    "    calibration_stage2_method='lower_mean',\n",
    "    random_state=42,\n",
    ")\n",
    "cfg.model_type = 'all'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9e5543e",
   "metadata": {},
   "source": [
    "## 4. Run the unified pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71519f7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = UnifiedRiskPipeline(cfg)\n",
    "results = pipe.fit(\n",
    "    dev_df,\n",
    "    data_dictionary=data_dictionary,\n",
    "    calibration_df=cal_long_df,\n",
    "    stage2_df=cal_recent_df,\n",
    "    score_df=score_df,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f1170d5",
   "metadata": {},
   "source": [
    "## 5. Inspect key outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09882c48",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model = results.get('best_model_name')\n",
    "model_scores = results.get('model_results', {}).get('scores', {})\n",
    "print(f'Best model: {best_model}')\n",
    "pd.DataFrame(model_scores).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06d7c44a",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_report = pipe.reporter.reports_.get('features')\n",
    "feature_report.head() if feature_report is not None else 'No feature report available.'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f98c1b63",
   "metadata": {},
   "outputs": [],
   "source": [
    "calibration_report = pipe.reporter.reports_.get('calibration')\n",
    "calibration_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b526862",
   "metadata": {},
   "outputs": [],
   "source": [
    "risk_band_source = pipe.results_.get('risk_bands')\n",
    "risk_bands_table = pipe.reporter.generate_risk_band_report(risk_band_source) if risk_band_source else None\n",
    "risk_bands_summary = pipe.reporter.reports_.get('risk_bands_summary_table')\n",
    "risk_bands_tests = pipe.reporter.reports_.get('risk_bands_tests')\n",
    "\n",
    "display(risk_bands_table if isinstance(risk_bands_table, pd.DataFrame) and not risk_bands_table.empty else 'No risk band table available.')\n",
    "display(risk_bands_summary if isinstance(risk_bands_summary, pd.DataFrame) and not risk_bands_summary.empty else 'No risk band summary available.')\n",
    "display(risk_bands_tests if isinstance(risk_bands_tests, pd.DataFrame) and not risk_bands_tests.empty else 'No binomial test results available.')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4af7eac6",
   "metadata": {},
   "source": [
    "## 6. Generated files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d68abf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted(p.relative_to(OUTPUT_DIR.parent) for p in OUTPUT_DIR.glob('**/*') if p.is_file())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17e2a2b5",
   "metadata": {},
   "source": [
    "## 7. XBooster scorecard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94166e80",
   "metadata": {},
   "outputs": [],
   "source": [
    "xbooster_artifacts = results.get('model_results', {}).get('interpretability', {}).get('XBooster', {})\n",
    "if isinstance(xbooster_artifacts, dict):\n",
    "    scorecard_df = xbooster_artifacts.get('scorecard_points')\n",
    "    warnings = xbooster_artifacts.get('warnings')\n",
    "    display_obj = scorecard_df.head() if hasattr(scorecard_df, 'head') else xbooster_artifacts\n",
    "else:\n",
    "    warnings = None\n",
    "    display_obj = 'No XBooster artifacts available.'\n",
    "print('Warnings:', warnings if warnings else 'None')\n",
    "display_obj"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6a920df",
   "metadata": {},
   "source": [
    "## 8. Automating via script\n",
    "\n",
    "`examples/quickstart_demo.py` mirrors the steps above so the flow can be validated headless\n",
    "(e.g. in CI pipelines)."
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
