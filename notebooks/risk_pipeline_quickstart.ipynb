{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5dfd24c9",
   "metadata": {},
   "source": [
    "# Credit Risk Pipeline Quickstart\n",
    "\n",
    "This notebook exercises the **Unified Risk Pipeline** end-to-end using the bundled synthetic dataset.\n",
    "The sample includes stratified monthly observations, calibration hold-outs, stage-2 data and a future\n",
    "scoring batch so that every major pipeline step can be validated quickly."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff4cc2bd",
   "metadata": {},
   "source": [
    "## 0. Environment setup\n",
    "\n",
    "Install the latest development build of the pipeline (latest development build) directly from GitHub.\n",
    "Re-run this cell if you refresh the kernel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e44d8807",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install --quiet --no-cache-dir --upgrade --force-reinstall \\\n",
    "    \"risk-pipeline @ git+https://github.com/selimoksuz/risk-model-pipeline.git@development\" \\\n",
    "    \"tsfresh==0.20.1\" \"scipy==1.11.4\" \"numba==0.57.1\" \"llvmlite==0.40.1\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d62ed2c3",
   "metadata": {},
   "source": [
    "## 1. Imports and sample loader\n",
    "\n",
    "The dataset ships with the package under `risk_pipeline.data.sample`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c082243b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "\n",
    "from IPython.display import display\n",
    "\n",
    "from risk_pipeline.core.config import Config\n",
    "from risk_pipeline.unified_pipeline import UnifiedRiskPipeline\n",
    "from risk_pipeline.data.sample import load_credit_risk_sample\n",
    "\n",
    "sample = load_credit_risk_sample()\n",
    "OUTPUT_DIR = Path('output/credit_risk_sample_notebook')\n",
    "OUTPUT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "dev_df = sample.development\n",
    "cal_long_df = sample.calibration_longrun\n",
    "cal_recent_df = sample.calibration_recent\n",
    "score_df = sample.scoring_future\n",
    "data_dictionary = sample.data_dictionary\n",
    "\n",
    "dev_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d401383f",
   "metadata": {},
   "source": [
    "## 2. Quick sanity checks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eee0dafa",
   "metadata": {},
   "outputs": [],
   "source": [
    "dev_df['target'].value_counts(normalize=True).rename('default_rate')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fe05a0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "dev_df.groupby('snapshot_month')['target'].mean().rename('monthly_default_rate')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41159584",
   "metadata": {},
   "source": [
    "## 3. Configure the pipeline\n",
    "\n",
    "The configuration below enables dual modelling (raw + WoE), Optuna (single rapid trial), balanced model selection with stability guard rails,\n",
    "noise sentinel monitoring, SHAP explainability, the WoE-LI and Shao logistic challengers, and the PD-constrained risk band optimizer.\n",
    "Train/Test/OOT ratios and all threshold knobs (PSI/IV/Gini/Correlation) are explicit so the notebook mirrors production-ready configuration files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2a49bfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg = Config(\n",
    "    target_column='target',\n",
    "    id_column='customer_id',\n",
    "    time_column='app_dt',\n",
    "    create_test_split=True,\n",
    "    use_test_split=True,\n",
    "    train_ratio=0.6,\n",
    "    test_ratio=0.2,\n",
    "    oot_ratio=0.2,\n",
    "    stratify_test=True,\n",
    "    oot_months=2,\n",
    "    enable_dual=True,\n",
    "    enable_tsfresh_features=True,\n",
    "    tsfresh_feature_set='efficient',\n",
    "    tsfresh_n_jobs=-1,\n",
    "    enable_scoring=True,\n",
    "    enable_stage2_calibration=True,\n",
    "    output_folder=str(OUTPUT_DIR),\n",
    "    selection_steps=['psi', 'univariate', 'iv', 'correlation', 'boruta', 'stepwise'],\n",
    "    algorithms=[\n",
    "        'logistic', 'gam', 'catboost', 'lightgbm', 'xgboost',\n",
    "        'randomforest', 'extratrees', 'woe_boost', 'woe_li', 'shao', 'xbooster',\n",
    "    ],\n",
    "    model_selection_method='balanced',\n",
    "    model_stability_weight=0.25,\n",
    "    min_gini_threshold=0.45,\n",
    "    max_train_oot_gap=0.08,\n",
    "    psi_threshold=0.25,\n",
    "    iv_threshold=0.02,\n",
    "    univariate_gini_threshold=0.05,\n",
    "    correlation_threshold=0.95,\n",
    "    vif_threshold=5.0,\n",
    "    woe_binning_strategy='iv_optimal',\n",
    "    use_optuna=True,\n",
    "    n_trials=1,\n",
    "    optuna_timeout=120,\n",
    "    hpo_method='optuna',\n",
    "    hpo_trials=1,\n",
    "    hpo_timeout_sec=120,\n",
    "    use_noise_sentinel=True,\n",
    "    calculate_shap=True,\n",
    "    shap_sample_size=500,\n",
    "    risk_band_method='pd_constraints',\n",
    "    n_risk_bands=8,\n",
    "    risk_band_min_bins=7,\n",
    "    risk_band_max_bins=10,\n",
    "    risk_band_micro_bins=1000,\n",
    "    risk_band_min_weight=0.05,\n",
    "    risk_band_max_weight=0.30,\n",
    "    risk_band_hhi_threshold=0.15,\n",
    "    risk_band_binomial_pass_weight=0.85,\n",
    "    risk_band_alpha=0.05,\n",
    "    risk_band_pd_dr_tolerance=1e-4,\n",
    "    risk_band_max_iterations=100,\n",
    "    risk_band_max_phase_iterations=50,\n",
    "    risk_band_early_stop_rounds=10,\n",
    "    calibration_stage1_method='isotonic',\n",
    "    calibration_stage2_method='lower_mean',\n",
    "    random_state=42,\n",
    ")\n",
    "cfg.model_type = 'all'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9e5543e",
   "metadata": {},
   "source": [
    "## 4. Run the unified pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71519f7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = UnifiedRiskPipeline(cfg)\n",
    "results = pipe.fit(\n",
    "    dev_df,\n",
    "    data_dictionary=data_dictionary,\n",
    "    calibration_df=cal_long_df,\n",
    "    stage2_df=cal_recent_df,\n",
    "    score_df=score_df,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f1170d5",
   "metadata": {},
   "source": [
    "## 5. Inspect key outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09882c48",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model = results.get('best_model_name')\n",
    "model_scores = results.get('model_results', {}).get('scores', {})\n",
    "print(f'Best model: {best_model}')\n",
    "pd.DataFrame(model_scores).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06d7c44a",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_report = pipe.reporter.reports_.get('features')\n",
    "feature_report.head() if feature_report is not None else 'No feature report available.'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f98c1b63",
   "metadata": {},
   "outputs": [],
   "source": [
    "calibration_report = pipe.reporter.reports_.get('calibration')\n",
    "calibration_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b526862",
   "metadata": {},
   "outputs": [],
   "source": [
    "risk_bands_summary = pipe.reporter.reports_.get('risk_bands_summary_table')\n",
    "risk_bands_tests = pipe.reporter.reports_.get('risk_bands_tests')\n",
    "\n",
    "display(risk_bands_summary if risk_bands_summary is not None else 'No risk band summary available.')\n",
    "display(risk_bands_tests if risk_bands_tests is not None else 'No binomial test results available.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4af7eac6",
   "metadata": {},
   "source": [
    "## 6. Generated files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d68abf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted(p.relative_to(OUTPUT_DIR.parent) for p in OUTPUT_DIR.glob('**/*') if p.is_file())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17e2a2b5",
   "metadata": {},
   "source": [
    "## 7. XBooster scorecard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94166e80",
   "metadata": {},
   "outputs": [],
   "source": [
    "xbooster_artifacts = results.get('model_results', {}).get('interpretability', {}).get('XBooster', {})\n",
    "if isinstance(xbooster_artifacts, dict):\n",
    "    scorecard_df = xbooster_artifacts.get('scorecard_points')\n",
    "    warnings = xbooster_artifacts.get('warnings')\n",
    "    display_obj = scorecard_df.head() if hasattr(scorecard_df, 'head') else xbooster_artifacts\n",
    "else:\n",
    "    warnings = None\n",
    "    display_obj = 'No XBooster artifacts available.'\n",
    "print('Warnings:', warnings if warnings else 'None')\n",
    "display_obj"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6a920df",
   "metadata": {},
   "source": [
    "## 8. Automating via script\n",
    "\n",
    "`examples/quickstart_demo.py` mirrors the steps above so the flow can be validated headless\n",
    "(e.g. in CI pipelines)."
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
