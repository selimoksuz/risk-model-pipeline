{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Unified Risk Model Pipeline - Complete Test\\n\\nBu notebook tek bir pipeline ile tüm risk modelleme işlemlerini göstermektedir:\\n\\n1. Otomatik veri oluşturma\\n2. WOE transformasyonu ve univariate Gini\\n3. PSI -> VIF -> Correlation -> IV -> Boruta -> Stepwise selection\\n4. Tüm ML modelleri (Logistic, GAM, CatBoost, LightGBM, XGBoost, RF, ExtraTrees)\\n5. Stage 1 ve Stage 2 kalibrasyon\\n6. Risk band optimizasyonu (Herfindahl, Hosmer-Lemeshow, Binomial testler)\\n7. Kapsamlı raporlama"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kütüphaneler başarıyla yüklendi!\n",
      "Çalışma dizini: C:\\Users\\Acer\\risk-model-pipeline-dev\\notebooks\n",
      "Python versiyonu: 3.9.13 (main, Aug 25 2022, 23:51:50) [MSC v.1916 64 bit (AMD64)]\n"
     ]
    }
   ],
   "source": [
    "# Gerekli kütüphaneleri yükle\n",
    "import sys\n",
    "import os\n",
    "import warnings\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from datetime import datetime, timedelta\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Parent directory'yi path'e ekle\n",
    "sys.path.insert(0, os.path.abspath('../'))\n",
    "\n",
    "# Pipeline bileşenlerini import et\n",
    "from src.risk_pipeline.core.config import Config\n",
    "from src.risk_pipeline.unified_pipeline import UnifiedRiskPipeline\n",
    "\n",
    "print(\"Kütüphaneler başarıyla yüklendi!\")\n",
    "print(f\"Çalışma dizini: {os.getcwd()}\")\n",
    "print(f\"Python versiyonu: {sys.version}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Sentetik Veri Oluşturma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Veri seti oluşturuldu: 15000 kayıt\n",
      "Default oranı: 12.81%\n",
      "Boyut: (15000, 19)\n",
      "\n",
      "Özellikler: ['customer_id', 'application_date', 'age', 'income', 'loan_amount', 'employment_years', 'credit_score', 'debt_to_income', 'num_credit_lines', 'months_since_delinquent', 'total_credit_limit', 'utilization_rate', 'home_ownership', 'loan_purpose', 'employment_type', 'education', 'marital_status', 'state', 'default']\n",
      "\n",
      "İlk 5 satır:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>customer_id</th>\n",
       "      <th>application_date</th>\n",
       "      <th>age</th>\n",
       "      <th>income</th>\n",
       "      <th>loan_amount</th>\n",
       "      <th>employment_years</th>\n",
       "      <th>credit_score</th>\n",
       "      <th>debt_to_income</th>\n",
       "      <th>num_credit_lines</th>\n",
       "      <th>months_since_delinquent</th>\n",
       "      <th>total_credit_limit</th>\n",
       "      <th>utilization_rate</th>\n",
       "      <th>home_ownership</th>\n",
       "      <th>loan_purpose</th>\n",
       "      <th>employment_type</th>\n",
       "      <th>education</th>\n",
       "      <th>marital_status</th>\n",
       "      <th>state</th>\n",
       "      <th>default</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>2020-01-01 00:00:00</td>\n",
       "      <td>45</td>\n",
       "      <td>33321.098707</td>\n",
       "      <td>2739.532121</td>\n",
       "      <td>1.822872</td>\n",
       "      <td>510.601996</td>\n",
       "      <td>18.042761</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6583.662106</td>\n",
       "      <td>36.216158</td>\n",
       "      <td>RENT</td>\n",
       "      <td>credit_card</td>\n",
       "      <td>Part-time</td>\n",
       "      <td>Bachelor</td>\n",
       "      <td>Single</td>\n",
       "      <td>CA</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2020-01-01 06:00:00</td>\n",
       "      <td>38</td>\n",
       "      <td>35610.878918</td>\n",
       "      <td>5744.576564</td>\n",
       "      <td>7.168679</td>\n",
       "      <td>568.446315</td>\n",
       "      <td>9.224136</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>22535.996273</td>\n",
       "      <td>14.791731</td>\n",
       "      <td>RENT</td>\n",
       "      <td>other</td>\n",
       "      <td>Self-employed</td>\n",
       "      <td>High School</td>\n",
       "      <td>Married</td>\n",
       "      <td>NC</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2020-01-01 12:00:00</td>\n",
       "      <td>47</td>\n",
       "      <td>37743.816018</td>\n",
       "      <td>8353.010359</td>\n",
       "      <td>3.291365</td>\n",
       "      <td>847.762386</td>\n",
       "      <td>44.379225</td>\n",
       "      <td>2</td>\n",
       "      <td>1.029136</td>\n",
       "      <td>24181.888050</td>\n",
       "      <td>37.934405</td>\n",
       "      <td>MORTGAGE</td>\n",
       "      <td>debt_consolidation</td>\n",
       "      <td>Full-time</td>\n",
       "      <td>Bachelor</td>\n",
       "      <td>Divorced</td>\n",
       "      <td>IL</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>2020-01-01 18:00:00</td>\n",
       "      <td>58</td>\n",
       "      <td>64094.694924</td>\n",
       "      <td>15059.060698</td>\n",
       "      <td>9.425473</td>\n",
       "      <td>533.344587</td>\n",
       "      <td>21.626382</td>\n",
       "      <td>5</td>\n",
       "      <td>14.771954</td>\n",
       "      <td>8890.186718</td>\n",
       "      <td>26.375190</td>\n",
       "      <td>MORTGAGE</td>\n",
       "      <td>major_purchase</td>\n",
       "      <td>Full-time</td>\n",
       "      <td>Bachelor</td>\n",
       "      <td>Divorced</td>\n",
       "      <td>OH</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>2020-01-02 00:00:00</td>\n",
       "      <td>37</td>\n",
       "      <td>23194.480385</td>\n",
       "      <td>30312.936916</td>\n",
       "      <td>14.180700</td>\n",
       "      <td>620.178434</td>\n",
       "      <td>46.276800</td>\n",
       "      <td>1</td>\n",
       "      <td>74.013684</td>\n",
       "      <td>38768.961266</td>\n",
       "      <td>NaN</td>\n",
       "      <td>OTHER</td>\n",
       "      <td>debt_consolidation</td>\n",
       "      <td>Part-time</td>\n",
       "      <td>High School</td>\n",
       "      <td>Single</td>\n",
       "      <td>GA</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   customer_id    application_date  age        income   loan_amount  \\\n",
       "0            0 2020-01-01 00:00:00   45  33321.098707   2739.532121   \n",
       "1            1 2020-01-01 06:00:00   38  35610.878918   5744.576564   \n",
       "2            2 2020-01-01 12:00:00   47  37743.816018   8353.010359   \n",
       "3            3 2020-01-01 18:00:00   58  64094.694924  15059.060698   \n",
       "4            4 2020-01-02 00:00:00   37  23194.480385  30312.936916   \n",
       "\n",
       "   employment_years  credit_score  debt_to_income  num_credit_lines  \\\n",
       "0          1.822872    510.601996       18.042761                 3   \n",
       "1          7.168679    568.446315        9.224136                 2   \n",
       "2          3.291365    847.762386       44.379225                 2   \n",
       "3          9.425473    533.344587       21.626382                 5   \n",
       "4         14.180700    620.178434       46.276800                 1   \n",
       "\n",
       "   months_since_delinquent  total_credit_limit  utilization_rate  \\\n",
       "0                      NaN         6583.662106         36.216158   \n",
       "1                      NaN        22535.996273         14.791731   \n",
       "2                 1.029136        24181.888050         37.934405   \n",
       "3                14.771954         8890.186718         26.375190   \n",
       "4                74.013684        38768.961266               NaN   \n",
       "\n",
       "  home_ownership        loan_purpose employment_type    education  \\\n",
       "0           RENT         credit_card       Part-time     Bachelor   \n",
       "1           RENT               other   Self-employed  High School   \n",
       "2       MORTGAGE  debt_consolidation       Full-time     Bachelor   \n",
       "3       MORTGAGE      major_purchase       Full-time     Bachelor   \n",
       "4          OTHER  debt_consolidation       Part-time  High School   \n",
       "\n",
       "  marital_status state  default  \n",
       "0         Single    CA        1  \n",
       "1        Married    NC        0  \n",
       "2       Divorced    IL        1  \n",
       "3       Divorced    OH        0  \n",
       "4         Single    GA        0  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Rastgelelik için seed ayarla\n",
    "np.random.seed(42)\n",
    "\n",
    "# Sentetik kredi riski verisi oluştur\n",
    "n_samples = 15000\n",
    "\n",
    "# Temel özellikler\n",
    "data = pd.DataFrame({\n",
    "    'customer_id': range(n_samples),\n",
    "    'application_date': pd.date_range(\n",
    "        start='2020-01-01', \n",
    "        periods=n_samples, \n",
    "        freq='6H'\n",
    "    ),\n",
    "    \n",
    "    # Numerik değişkenler\n",
    "    'age': np.random.normal(40, 12, n_samples).clip(18, 80).astype(int),\n",
    "    'income': np.random.lognormal(10.5, 0.6, n_samples),\n",
    "    'loan_amount': np.random.lognormal(9.5, 0.8, n_samples),\n",
    "    'employment_years': np.random.exponential(5, n_samples).clip(0, 40),\n",
    "    'credit_score': np.random.normal(650, 100, n_samples).clip(300, 850),\n",
    "    'debt_to_income': np.random.beta(2, 5, n_samples) * 100,\n",
    "    'num_credit_lines': np.random.poisson(3, n_samples),\n",
    "    'months_since_delinquent': np.random.exponential(24, n_samples),\n",
    "    'total_credit_limit': np.random.lognormal(10, 0.7, n_samples),\n",
    "    'utilization_rate': np.random.beta(3, 5, n_samples) * 100,\n",
    "    \n",
    "    # Kategorik değişkenler\n",
    "    'home_ownership': np.random.choice(['RENT', 'OWN', 'MORTGAGE', 'OTHER'], \n",
    "                                      n_samples, p=[0.35, 0.20, 0.40, 0.05]),\n",
    "    'loan_purpose': np.random.choice(['debt_consolidation', 'credit_card', \n",
    "                                     'home_improvement', 'major_purchase', 'other'], \n",
    "                                    n_samples, p=[0.35, 0.20, 0.15, 0.15, 0.15]),\n",
    "    'employment_type': np.random.choice(['Full-time', 'Part-time', 'Self-employed', \n",
    "                                        'Unemployed', 'Retired'], \n",
    "                                       n_samples, p=[0.60, 0.15, 0.15, 0.05, 0.05]),\n",
    "    'education': np.random.choice(['High School', 'Bachelor', 'Master', 'PhD', 'Other'], \n",
    "                                 n_samples, p=[0.30, 0.40, 0.20, 0.05, 0.05]),\n",
    "    'marital_status': np.random.choice(['Single', 'Married', 'Divorced', 'Widowed'], \n",
    "                                      n_samples, p=[0.30, 0.50, 0.15, 0.05]),\n",
    "    'state': np.random.choice(['CA', 'NY', 'TX', 'FL', 'PA', 'IL', 'OH', 'GA', 'NC', 'MI'],\n",
    "                             n_samples)\n",
    "})\n",
    "\n",
    "# Eksik değerler ekle (gerçekçi olması için)\n",
    "missing_cols = ['months_since_delinquent', 'employment_years', 'utilization_rate']\n",
    "for col in missing_cols:\n",
    "    missing_idx = np.random.choice(n_samples, size=int(0.1 * n_samples), replace=False)\n",
    "    data.loc[missing_idx, col] = np.nan\n",
    "\n",
    "# Hedef değişken oluştur (gerçekçi default pattern'leri ile)\n",
    "default_prob_base = 0.08  # Temel default oranı\n",
    "\n",
    "# Risk skoru hesapla\n",
    "risk_score = (\n",
    "    (data['credit_score'] < 600).astype(float) * 0.25 +\n",
    "    (data['debt_to_income'] > 40).astype(float) * 0.20 +\n",
    "    (data['loan_amount'] / data['income'] > 0.5).astype(float) * 0.15 +\n",
    "    (data['employment_years'] < 2).astype(float) * 0.10 +\n",
    "    (data['home_ownership'] == 'RENT').astype(float) * 0.10 +\n",
    "    (data['utilization_rate'] > 80).astype(float) * 0.10 +\n",
    "    (data['employment_type'] == 'Unemployed').astype(float) * 0.10\n",
    ")\n",
    "\n",
    "# Gürültü ekle\n",
    "risk_score += np.random.normal(0, 0.05, n_samples)\n",
    "\n",
    "# Default olasılığını hesapla\n",
    "default_prob_adjusted = default_prob_base * (1 + risk_score * 2.5)\n",
    "default_prob_adjusted = np.clip(default_prob_adjusted, 0, 0.5)\n",
    "data['default'] = (np.random.random(n_samples) < default_prob_adjusted).astype(int)\n",
    "\n",
    "print(f\"Veri seti oluşturuldu: {n_samples} kayıt\")\n",
    "print(f\"Default oranı: {data['default'].mean():.2%}\")\n",
    "print(f\"Boyut: {data.shape}\")\n",
    "print(f\"\\nÖzellikler: {list(data.columns)}\")\n",
    "print(f\"\\nİlk 5 satır:\")\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Data Dictionary Oluşturma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Veri sözlüğü oluşturuldu:\n",
      "                  variable                      description     type  \\\n",
      "0                      age               Müşteri yaşı (yıl)  numeric   \n",
      "1                   income               Yıllık gelir (USD)  numeric   \n",
      "2              loan_amount        Talep edilen kredi tutarı  numeric   \n",
      "3         employment_years  Mevcut işyerinde çalışma süresi  numeric   \n",
      "4             credit_score                      Kredi skoru  numeric   \n",
      "5           debt_to_income             Borç/Gelir oranı (%)  numeric   \n",
      "6         num_credit_lines          Açık kredi hesap sayısı  numeric   \n",
      "7  months_since_delinquent     Son gecikme sonrası geçen ay  numeric   \n",
      "8       total_credit_limit              Toplam kredi limiti  numeric   \n",
      "9         utilization_rate         Kredi kullanım oranı (%)  numeric   \n",
      "\n",
      "      category  \n",
      "0  demographic  \n",
      "1    financial  \n",
      "2         loan  \n",
      "3   employment  \n",
      "4       credit  \n",
      "5    financial  \n",
      "6       credit  \n",
      "7       credit  \n",
      "8       credit  \n",
      "9       credit  \n"
     ]
    }
   ],
   "source": [
    "# Veri sözlüğü oluştur\n",
    "data_dictionary = pd.DataFrame([\n",
    "    {'variable': 'age', 'description': 'Müşteri yaşı (yıl)', 'type': 'numeric', 'category': 'demographic'},\n",
    "    {'variable': 'income', 'description': 'Yıllık gelir (USD)', 'type': 'numeric', 'category': 'financial'},\n",
    "    {'variable': 'loan_amount', 'description': 'Talep edilen kredi tutarı', 'type': 'numeric', 'category': 'loan'},\n",
    "    {'variable': 'employment_years', 'description': 'Mevcut işyerinde çalışma süresi', 'type': 'numeric', 'category': 'employment'},\n",
    "    {'variable': 'credit_score', 'description': 'Kredi skoru', 'type': 'numeric', 'category': 'credit'},\n",
    "    {'variable': 'debt_to_income', 'description': 'Borç/Gelir oranı (%)', 'type': 'numeric', 'category': 'financial'},\n",
    "    {'variable': 'num_credit_lines', 'description': 'Açık kredi hesap sayısı', 'type': 'numeric', 'category': 'credit'},\n",
    "    {'variable': 'months_since_delinquent', 'description': 'Son gecikme sonrası geçen ay', 'type': 'numeric', 'category': 'credit'},\n",
    "    {'variable': 'total_credit_limit', 'description': 'Toplam kredi limiti', 'type': 'numeric', 'category': 'credit'},\n",
    "    {'variable': 'utilization_rate', 'description': 'Kredi kullanım oranı (%)', 'type': 'numeric', 'category': 'credit'},\n",
    "    {'variable': 'home_ownership', 'description': 'Ev sahipliği durumu', 'type': 'categorical', 'category': 'demographic'},\n",
    "    {'variable': 'loan_purpose', 'description': 'Kredi amacı', 'type': 'categorical', 'category': 'loan'},\n",
    "    {'variable': 'employment_type', 'description': 'İstihdam türü', 'type': 'categorical', 'category': 'employment'},\n",
    "    {'variable': 'education', 'description': 'Eğitim seviyesi', 'type': 'categorical', 'category': 'demographic'},\n",
    "    {'variable': 'marital_status', 'description': 'Medeni durum', 'type': 'categorical', 'category': 'demographic'},\n",
    "    {'variable': 'state', 'description': 'Eyalet', 'type': 'categorical', 'category': 'geographic'}\n",
    "])\n",
    "\n",
    "print(\"Veri sözlüğü oluşturuldu:\")\n",
    "print(data_dictionary.head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Kalibrasyon Verileri Hazırlama"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stage 1 kalibrasyon verisi (uzun dönem):\n",
      "  Kayıt sayısı: 15000\n",
      "  Default oranı: 12.81%\n",
      "\n",
      "Stage 2 kalibrasyon verisi (son dönem):\n",
      "  Kayıt sayısı: 361\n",
      "  Tarih aralığı: 2030-01-07 18:00:00 - 2030-04-07 18:00:00\n",
      "  Default oranı: 14.68%\n"
     ]
    }
   ],
   "source": [
    "# Stage 1 kalibrasyon verisi (uzun dönem)\n",
    "calibration_data = data.copy()\n",
    "print(f\"Stage 1 kalibrasyon verisi (uzun dönem):\")\n",
    "print(f\"  Kayıt sayısı: {len(calibration_data)}\")\n",
    "print(f\"  Default oranı: {calibration_data['default'].mean():.2%}\")\n",
    "\n",
    "# Stage 2 kalibrasyon verisi (son 3 ay)\n",
    "recent_cutoff = data['application_date'].max() - pd.DateOffset(months=3)\n",
    "stage2_data = data[data['application_date'] >= recent_cutoff].copy()\n",
    "\n",
    "# Son dönemde default oranında hafif artış simüle et\n",
    "additional_defaults = np.random.choice(stage2_data[stage2_data['default'] == 0].index, \n",
    "                                       size=int(len(stage2_data) * 0.02), replace=False)\n",
    "stage2_data.loc[additional_defaults, 'default'] = 1\n",
    "\n",
    "print(f\"\\nStage 2 kalibrasyon verisi (son dönem):\")\n",
    "print(f\"  Kayıt sayısı: {len(stage2_data)}\")\n",
    "print(f\"  Tarih aralığı: {stage2_data['application_date'].min()} - {stage2_data['application_date'].max()}\")\n",
    "print(f\"  Default oranı: {stage2_data['default'].mean():.2%}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Pipeline Konfigürasyonu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline konfigürasyonu oluşturuldu\n",
      "\n",
      "Önemli ayarlar:\n",
      "  Seçim sırası: ['psi', 'vif', 'correlation', 'iv', 'boruta', 'stepwise']\n",
      "  Seçim yöntemi: stepwise\n",
      "  Binning yöntemi: optimized\n",
      "  Eşit default oranları: True\n",
      "  Kalibrasyon aktif: True\n",
      "  Model tipi: all\n"
     ]
    }
   ],
   "source": [
    "# Kapsamlı konfigürasyon oluştur\n",
    "config = Config(\n",
    "    # Temel ayarlar\n",
    "    target_col='default',\n",
    "    id_col='customer_id',\n",
    "    time_col='application_date',\n",
    "    random_state=42,\n",
    "    \n",
    "    # Pipeline modu\n",
    "    enable_scoring=False,  # Skorlama varsayılan olarak kapalı\n",
    "    enable_woe=True,       # WOE transformasyonu aktif\n",
    "    enable_noise_sentinel=True,  # Gürültü değişkeni kontrolü\n",
    "    \n",
    "    # Veri bölme ayarları\n",
    "    test_ratio=0.2,\n",
    "    oot_months=6,\n",
    "    equal_default_splits=True,  # Eşit default oranları\n",
    "    min_oot_size=500,\n",
    "    \n",
    "    # Değişken seçim ayarları\n",
    "    selection_order=['psi', 'vif', 'correlation', 'iv', 'boruta', 'stepwise'],\n",
    "    selection_method='stepwise',  # forward/backward/stepwise\n",
    "    max_features=20,\n",
    "    \n",
    "    # Binning ayarları\n",
    "    binning_method='optimized',  # IV/Gini optimize binning\n",
    "    min_bin_size=0.05,\n",
    "    max_bins=10,\n",
    "    monotonic_woe=True,\n",
    "    \n",
    "    # Eşik değerler\n",
    "    psi_threshold=0.25,\n",
    "    vif_threshold=10,\n",
    "    correlation_threshold=0.9,\n",
    "    iv_threshold=0.02,\n",
    "    \n",
    "    # İmputation ayarları\n",
    "    numeric_imputation='median',\n",
    "    categorical_imputation='missing',\n",
    "    outlier_method='clip',\n",
    "    min_category_freq=0.01,\n",
    "    \n",
    "    # Model ayarları\n",
    "    model_type='all',  # Tüm modelleri eğit\n",
    "    use_optuna=False,  # Hız için kapalı (açılabilir)\n",
    "    n_optuna_trials=30,\n",
    "    \n",
    "    # Kalibrasyon ayarları\n",
    "    enable_calibration=True,\n",
    "    calibration_method='isotonic',  # isotonic/sigmoid/platt/beta\n",
    "    stage2_method='lower_mean',     # lower_mean/upper_bound/weighted/shift\n",
    "    \n",
    "    # Risk band ayarları\n",
    "    n_risk_bands=10,\n",
    "    band_method='optimal',  # quantile/equal_width/optimal\n",
    "    \n",
    "    # Çıktı ayarları\n",
    "    output_dir='../outputs',\n",
    "    save_plots=True,\n",
    "    save_model=True\n",
    ")\n",
    "\n",
    "print(\"Pipeline konfigürasyonu oluşturuldu\")\n",
    "print(f\"\\nÖnemli ayarlar:\")\n",
    "print(f\"  Seçim sırası: {config.selection_order}\")\n",
    "print(f\"  Seçim yöntemi: {config.selection_method}\")\n",
    "print(f\"  Binning yöntemi: {config.binning_method}\")\n",
    "print(f\"  Eşit default oranları: {config.equal_default_splits}\")\n",
    "print(f\"  Kalibrasyon aktif: {config.enable_calibration}\")\n",
    "print(f\"  Model tipi: {config.model_type}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Pipeline'ı Çalıştır"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline başlatıldı!\n",
      "\n",
      "Bileşenler:\n",
      "  Data Processor: DataProcessor\n",
      "  WOE Transformer: EnhancedWOETransformer\n",
      "  Feature Selector: AdvancedFeatureSelector\n",
      "  Model Builder: ComprehensiveModelBuilder\n",
      "  Calibrator: TwoStageCalibrator\n",
      "  Risk Band Optimizer: OptimalRiskBandAnalyzer\n",
      "  Reporter: EnhancedReporter\n"
     ]
    }
   ],
   "source": [
    "# Unified pipeline'ı oluştur\n",
    "pipeline = UnifiedRiskPipeline(config=config)\n",
    "\n",
    "print(\"Pipeline başlatıldı!\")\n",
    "print(f\"\\nBileşenler:\")\n",
    "print(f\"  Data Processor: {type(pipeline.data_processor).__name__}\")\n",
    "print(f\"  WOE Transformer: {type(pipeline.woe_transformer).__name__}\")\n",
    "print(f\"  Feature Selector: {type(pipeline.feature_selector).__name__}\")\n",
    "print(f\"  Model Builder: {type(pipeline.model_builder).__name__}\")\n",
    "print(f\"  Calibrator: {type(pipeline.calibrator).__name__}\")\n",
    "print(f\"  Risk Band Optimizer: {type(pipeline.risk_band_optimizer).__name__}\")\n",
    "print(f\"  Reporter: {type(pipeline.reporter).__name__}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline çalıştırılıyor...\n",
      "================================================================================\n",
      "================================================================================\n",
      "UNIFIED RISK PIPELINE EXECUTION\n",
      "================================================================================\n",
      "\n",
      "[Step 1/10] Data Processing...\n",
      "  Found 8 numeric and 6 categorical features\n",
      "\n",
      "[Step 2/10] Data Splitting...\n",
      "    Performing equal default rate split...\n",
      "      [OK] Equal default rates achieved (mean: 12.82%, std: 0.0004)\n",
      "  oot: 729 samples, default rate: 12.76%\n",
      "  train: 11416 samples, default rate: 12.85%\n",
      "  test: 2855 samples, default rate: 12.85%\n",
      "\n",
      "[Step 3/10] WOE Transformation & Univariate Analysis...\n",
      "  Processing age...\n",
      "  Processing income...\n",
      "  Processing loan_amount...\n",
      "    WARNING: WOE significantly reduces Gini for loan_amount\n",
      "  Processing employment_years...\n",
      "  Processing credit_score...\n",
      "  Processing debt_to_income...\n",
      "    WARNING: WOE significantly reduces Gini for debt_to_income\n",
      "  Processing num_credit_lines...\n",
      "  Processing months_since_delinquent...\n",
      "  Processing total_credit_limit...\n",
      "    WARNING: WOE significantly reduces Gini for total_credit_limit\n",
      "  Processing utilization_rate...\n",
      "    WARNING: WOE significantly reduces Gini for utilization_rate\n",
      "  Processing home_ownership...\n",
      "  Processing loan_purpose...\n",
      "  Processing employment_type...\n",
      "  Processing education...\n",
      "  Processing marital_status...\n",
      "  Processing state...\n",
      "  Processing snapshot_month...\n",
      "  Processing noise_sentinel...\n",
      "\n",
      "[Step 4/10] Feature Selection...\n",
      "  Applying psi selection...\n",
      "    Removing income: PSI=9.209\n",
      "    Removing loan_amount: PSI=9.209\n",
      "    Removing employment_years: PSI=9.209\n",
      "    Removing months_since_delinquent: PSI=9.209\n",
      "    Removing noise_sentinel: PSI=9.209\n",
      "    Remaining features: 13\n",
      "  Applying vif selection...\n",
      "    Removing marital_status: VIF=10.87\n",
      "    Remaining features: 12\n",
      "  Applying correlation selection...\n",
      "    Remaining features: 12\n",
      "  Applying iv selection...\n",
      "    Removing age: IV=0.0000\n",
      "    Removing credit_score: IV=0.0000\n",
      "    Removing debt_to_income: IV=0.0000\n",
      "    Removing num_credit_lines: IV=0.0000\n",
      "    Removing total_credit_limit: IV=0.0000\n",
      "    Removing utilization_rate: IV=0.0000\n",
      "    Removing home_ownership: IV=0.0059\n",
      "    Removing loan_purpose: IV=0.0023\n",
      "    Removing employment_type: IV=0.0006\n",
      "    Removing education: IV=0.0062\n",
      "    Removing state: IV=0.0033\n",
      "    Removing snapshot_month: IV=0.0000\n",
      "    Remaining features: 0\n",
      "  Applying boruta selection...\n",
      "    Boruta skipped: No features to select from\n",
      "    Remaining features: 0\n",
      "  Applying stepwise selection...\n",
      "      Stepwise selection skipped: No features to select from\n",
      "    Remaining features: 0\n",
      "\n",
      "[Step 5/10] Model Training...\n",
      "  Training models on 0 features...\n",
      "    WARNING: No features available for training. Skipping model training.\n",
      "\n",
      "[Step 6/10] Stage 1 Calibration...\n",
      "  Skipping calibration: No model available\n",
      "\n",
      "[Step 7/10] Stage 2 Calibration...\n",
      "  Skipping Stage 2 calibration: No Stage 1 model available\n",
      "\n",
      "[Step 8/10] Risk Band Optimization...\n",
      "  Skipping risk bands: No model available\n",
      "\n",
      "[Step 9/10] Scoring... Skipped\n",
      "\n",
      "[Step 10/10] Generating Reports...\n",
      "\n",
      "================================================================================\n",
      "PIPELINE EXECUTION COMPLETED SUCCESSFULLY\n",
      "================================================================================\n",
      "\n",
      "================================================================================\n",
      "Pipeline başarıyla tamamlandı!\n"
     ]
    }
   ],
   "source": [
    "# Pipeline'ı çalıştır\n",
    "print(\"Pipeline çalıştırılıyor...\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "results = pipeline.fit(\n",
    "    df=data,\n",
    "    data_dictionary=data_dictionary,\n",
    "    calibration_df=calibration_data,\n",
    "    stage2_df=stage2_data\n",
    ")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"Pipeline başarıyla tamamlandı!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Sonuçları Analiz Et"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model performansları\n",
    "print(\"MODEL PERFORMANS ÖZETİ\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "if 'model_results' in results:\n",
    "    model_scores = results['model_results'].get('scores', {})\n",
    "    if model_scores:\n",
    "        scores_df = pd.DataFrame(model_scores).T\n",
    "        print(scores_df.round(4))\n",
    "        \n",
    "        # En iyi model\n",
    "        best_model = results['model_results'].get('best_model_name', 'N/A')\n",
    "        print(f\"\\nEn İyi Model: {best_model}\")\n",
    "\n",
    "# Seçilen özellikler\n",
    "if 'selection_results' in results:\n",
    "    features = results['selection_results'].get('selected_features', [])\n",
    "    print(f\"\\nSeçilen Özellik Sayısı: {len(features)}\")\n",
    "    print(f\"İlk 10 özellik: {features[:10]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# WOE ve Univariate Gini analizi\n",
    "print(\"WOE VE UNIVARIATE GINI ANALİZİ\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "if 'woe_results' in results:\n",
    "    woe_res = results['woe_results']\n",
    "    \n",
    "    if 'univariate_gini' in woe_res:\n",
    "        gini_data = []\n",
    "        for var, gini_info in woe_res['univariate_gini'].items():\n",
    "            gini_data.append({\n",
    "                'Variable': var,\n",
    "                'Gini (Raw)': gini_info.get('gini_raw', 0),\n",
    "                'Gini (WOE)': gini_info.get('gini_woe', 0),\n",
    "                'Gini Drop': gini_info.get('gini_drop', 0)\n",
    "            })\n",
    "        \n",
    "        gini_df = pd.DataFrame(gini_data)\n",
    "        gini_df = gini_df.sort_values('Gini (WOE)', ascending=False)\n",
    "        print(gini_df.head(10).round(4))\n",
    "        \n",
    "        # WOE kalitesi kontrolü\n",
    "        problematic = gini_df[gini_df['Gini Drop'] > 0.05]\n",
    "        if len(problematic) > 0:\n",
    "            print(f\"\\n⚠ WOE sonrası Gini düşüşü olan değişkenler: {len(problematic)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Risk band analizi\n",
    "print(\"RISK BAND ANALİZİ\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "if 'risk_bands' in results:\n",
    "    rb = results['risk_bands']\n",
    "    \n",
    "    if 'bands' in rb:\n",
    "        bands_df = rb['bands']\n",
    "        print(bands_df[['band', 'count', 'bad_rate', 'avg_score', 'ks']].round(4))\n",
    "    \n",
    "    if 'metrics' in rb:\n",
    "        metrics = rb['metrics']\n",
    "        print(f\"\\nRisk Band Metrikleri:\")\n",
    "        print(f\"  Herfindahl Index: {metrics.get('herfindahl_index', 0):.4f}\")\n",
    "        print(f\"  Entropy: {metrics.get('entropy', 0):.4f}\")\n",
    "        print(f\"  Gini Coefficient: {metrics.get('gini_coefficient', 0):.4f}\")\n",
    "        print(f\"  Hosmer-Lemeshow p-value: {metrics.get('hosmer_lemeshow_p', 0):.4f}\")\n",
    "        print(f\"  KS Statistic: {metrics.get('ks_stat', 0):.4f}\")\n",
    "        \n",
    "        # Binomial test sonuçları\n",
    "        if 'binomial_tests' in metrics:\n",
    "            significant = sum(1 for b in metrics['binomial_tests'].values() \n",
    "                            if b.get('significant', False))\n",
    "            print(f\"\\nBinomial Test Sonuçları:\")\n",
    "            print(f\"  Anlamlı band sayısı: {significant}/{len(metrics['binomial_tests'])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Kalibrasyon analizi\n",
    "print(\"KALİBRASYON ANALİZİ\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "if 'calibration_stage1' in results:\n",
    "    stage1 = results['calibration_stage1']\n",
    "    if 'calibration_metrics' in stage1:\n",
    "        s1_metrics = stage1['calibration_metrics']\n",
    "        print(\"Stage 1 Kalibrasyon (Uzun dönem):\")\n",
    "        print(f\"  ECE: {s1_metrics.get('ece', 0):.4f}\")\n",
    "        print(f\"  MCE: {s1_metrics.get('mce', 0):.4f}\")\n",
    "        print(f\"  Brier Score: {s1_metrics.get('brier', 0):.4f}\")\n",
    "        print(f\"  Calibration Gap: {s1_metrics.get('calibration_gap', 0):.4f}\")\n",
    "\n",
    "if 'calibration_stage2' in results:\n",
    "    stage2 = results['calibration_stage2']\n",
    "    if 'stage2_metrics' in stage2:\n",
    "        s2_metrics = stage2['stage2_metrics']\n",
    "        print(\"\\nStage 2 Kalibrasyon (Son dönem):\")\n",
    "        print(f\"  ECE: {s2_metrics.get('ece', 0):.4f}\")\n",
    "        print(f\"  MCE: {s2_metrics.get('mce', 0):.4f}\")\n",
    "        print(f\"  Mean Predicted: {s2_metrics.get('mean_predicted', 0):.4f}\")\n",
    "        print(f\"  Mean Actual: {s2_metrics.get('mean_actual', 0):.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Görselleştirmeler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Görselleştirmeler\n",
    "fig, axes = plt.subplots(2, 3, figsize=(15, 10))\n",
    "\n",
    "# 1. Model AUC karşılaştırması\n",
    "if 'model_results' in results and 'scores' in results['model_results']:\n",
    "    ax = axes[0, 0]\n",
    "    scores = results['model_results']['scores']\n",
    "    models = list(scores.keys())\n",
    "    train_aucs = [scores[m].get('train_auc', 0) for m in models]\n",
    "    test_aucs = [scores[m].get('test_auc', 0) for m in models]\n",
    "    \n",
    "    x = np.arange(len(models))\n",
    "    width = 0.35\n",
    "    \n",
    "    ax.bar(x - width/2, train_aucs, width, label='Train', color='steelblue')\n",
    "    ax.bar(x + width/2, test_aucs, width, label='Test', color='orange')\n",
    "    ax.set_xlabel('Model')\n",
    "    ax.set_ylabel('AUC')\n",
    "    ax.set_title('Model Performans Karşılaştırması')\n",
    "    ax.set_xticks(x)\n",
    "    ax.set_xticklabels(models, rotation=45, ha='right')\n",
    "    ax.legend()\n",
    "    ax.grid(True, alpha=0.3)\n",
    "\n",
    "# 2. Risk Band dağılımı\n",
    "if 'risk_bands' in results and 'bands' in results['risk_bands']:\n",
    "    ax = axes[0, 1]\n",
    "    bands_df = results['risk_bands']['bands']\n",
    "    ax.bar(bands_df['band'], bands_df['count'], color='coral')\n",
    "    ax.set_xlabel('Risk Band')\n",
    "    ax.set_ylabel('Kayıt Sayısı')\n",
    "    ax.set_title('Risk Band Dağılımı')\n",
    "    ax.grid(True, alpha=0.3)\n",
    "\n",
    "# 3. Default oranı by Risk Band\n",
    "if 'risk_bands' in results and 'bands' in results['risk_bands']:\n",
    "    ax = axes[0, 2]\n",
    "    bands_df = results['risk_bands']['bands']\n",
    "    ax.plot(bands_df['band'], bands_df['bad_rate'], 'o-', color='darkred', linewidth=2)\n",
    "    ax.set_xlabel('Risk Band')\n",
    "    ax.set_ylabel('Default Oranı')\n",
    "    ax.set_title('Risk Band Default Oranları')\n",
    "    ax.grid(True, alpha=0.3)\n",
    "\n",
    "# 4. IV değerleri\n",
    "if 'woe_results' in results and 'woe_values' in results['woe_results']:\n",
    "    ax = axes[1, 0]\n",
    "    woe_values = results['woe_results']['woe_values']\n",
    "    iv_data = [(var, info.get('iv', 0)) for var, info in woe_values.items()]\n",
    "    iv_data = sorted(iv_data, key=lambda x: x[1], reverse=True)[:10]\n",
    "    \n",
    "    vars_top = [x[0] for x in iv_data]\n",
    "    ivs_top = [x[1] for x in iv_data]\n",
    "    \n",
    "    ax.barh(range(len(vars_top)), ivs_top, color='green')\n",
    "    ax.set_yticks(range(len(vars_top)))\n",
    "    ax.set_yticklabels(vars_top)\n",
    "    ax.set_xlabel('Information Value')\n",
    "    ax.set_title('Top 10 Değişken (IV)')\n",
    "    ax.invert_yaxis()\n",
    "\n",
    "# 5. KS eğrisi\n",
    "if 'risk_bands' in results and 'bands' in results['risk_bands']:\n",
    "    ax = axes[1, 1]\n",
    "    bands_df = results['risk_bands']['bands']\n",
    "    ax.plot(bands_df['cum_count'] / bands_df['cum_count'].max(),\n",
    "           bands_df['bad_capture'], 'b-', label='Bad Capture', linewidth=2)\n",
    "    ax.plot(bands_df['cum_count'] / bands_df['cum_count'].max(),\n",
    "           bands_df['good_capture'], 'g-', label='Good Capture', linewidth=2)\n",
    "    ax.plot([0, 1], [0, 1], 'k--', alpha=0.5)\n",
    "    ax.set_xlabel('Popülasyon %')\n",
    "    ax.set_ylabel('Kümülatif %')\n",
    "    ax.set_title('KS Eğrisi')\n",
    "    ax.legend()\n",
    "    ax.grid(True, alpha=0.3)\n",
    "\n",
    "# 6. Kalibrasyon grafiği\n",
    "ax = axes[1, 2]\n",
    "ax.plot([0, 1], [0, 1], 'k--', alpha=0.5, label='Perfect Calibration')\n",
    "# Gerçek kalibrasyon verisi varsa eklenebilir\n",
    "ax.set_xlabel('Tahmin Edilen Olasılık')\n",
    "ax.set_ylabel('Gerçekleşen Oran')\n",
    "ax.set_title('Kalibrasyon Grafiği')\n",
    "ax.legend()\n",
    "ax.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Deployment Kodu Üretimi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SQL ve Python deployment kodları\n",
    "print(\"DEPLOYMENT KODU ÜRETİMİ\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "if hasattr(pipeline.risk_band_optimizer, 'export_sql'):\n",
    "    if 'risk_bands' in results and 'bands' in results['risk_bands']:\n",
    "        sql_code = pipeline.risk_band_optimizer.export_sql(results['risk_bands']['bands'])\n",
    "        print(\"SQL Kodu (Risk Bands):\")\n",
    "        print(\"-\"*40)\n",
    "        print(sql_code[:500])\n",
    "        if len(sql_code) > 500:\n",
    "            print(\"...\\n[Kısaltıldı]\")\n",
    "\n",
    "if hasattr(pipeline.risk_band_optimizer, 'export_python'):\n",
    "    if 'risk_bands' in results and 'bands' in results['risk_bands']:\n",
    "        python_code = pipeline.risk_band_optimizer.export_python(results['risk_bands']['bands'])\n",
    "        print(\"\\nPython Kodu (Risk Bands):\")\n",
    "        print(\"-\"*40)\n",
    "        print(python_code[:500])\n",
    "        if len(python_code) > 500:\n",
    "            print(\"...\\n[Kısaltıldı]\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Pipeline'ı Kaydet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pipeline'ı kaydet\n",
    "import os\n",
    "import joblib\n",
    "\n",
    "output_dir = '../outputs'\n",
    "if not os.path.exists(output_dir):\n",
    "    os.makedirs(output_dir)\n",
    "\n",
    "model_path = os.path.join(output_dir, 'unified_pipeline.pkl')\n",
    "pipeline.save_pipeline(model_path)\n",
    "\n",
    "print(f\"Pipeline kaydedildi: {model_path}\")\n",
    "\n",
    "# Sonuçları da kaydet\n",
    "results_path = os.path.join(output_dir, 'pipeline_results.pkl')\n",
    "joblib.dump(results, results_path)\n",
    "print(f\"Sonuçlar kaydedildi: {results_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Final Özet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Final özet raporu\n",
    "print(\"=\"*80)\n",
    "print(\"UNIFIED RISK MODEL PIPELINE - FİNAL ÖZET\")\n",
    "print(\"=\"*80)\n",
    "print()\n",
    "\n",
    "summary = []\n",
    "\n",
    "# Veri özeti\n",
    "summary.append(\"VERİ ÖZETİ:\")\n",
    "summary.append(f\"  Toplam kayıt: {len(data)}\")\n",
    "summary.append(f\"  Özellik sayısı: {len(data.columns) - 3}\")\n",
    "summary.append(f\"  Default oranı: {data['default'].mean():.2%}\")\n",
    "summary.append(\"\")\n",
    "\n",
    "# Pipeline konfigürasyonu\n",
    "summary.append(\"PIPELINE KONFİGÜRASYONU:\")\n",
    "summary.append(f\"  Seçim yöntemi: {config.selection_method}\")\n",
    "summary.append(f\"  Binning yöntemi: {config.binning_method}\")\n",
    "summary.append(f\"  Kalibrasyon: Stage 1 ({config.calibration_method}) + Stage 2 ({config.stage2_method})\")\n",
    "summary.append(f\"  Risk bands: {config.n_risk_bands} band, {config.band_method} yöntemi\")\n",
    "summary.append(\"\")\n",
    "\n",
    "# Model performansı\n",
    "if 'model_results' in results:\n",
    "    summary.append(\"MODEL PERFORMANSI:\")\n",
    "    best_model = results['model_results'].get('best_model_name', 'N/A')\n",
    "    summary.append(f\"  En iyi model: {best_model}\")\n",
    "    \n",
    "    if 'scores' in results['model_results'] and best_model in results['model_results']['scores']:\n",
    "        best_scores = results['model_results']['scores'][best_model]\n",
    "        summary.append(f\"  Train AUC: {best_scores.get('train_auc', 0):.4f}\")\n",
    "        summary.append(f\"  Test AUC: {best_scores.get('test_auc', 0):.4f}\")\n",
    "    summary.append(\"\")\n",
    "\n",
    "# Risk band metrikleri\n",
    "if 'risk_bands' in results and 'metrics' in results['risk_bands']:\n",
    "    metrics = results['risk_bands']['metrics']\n",
    "    summary.append(\"RISK BAND METRİKLERİ:\")\n",
    "    summary.append(f\"  Herfindahl Index: {metrics.get('herfindahl_index', 0):.4f}\")\n",
    "    summary.append(f\"  KS Statistic: {metrics.get('ks_stat', 0):.4f}\")\n",
    "    summary.append(f\"  Hosmer-Lemeshow p: {metrics.get('hosmer_lemeshow_p', 0):.4f}\")\n",
    "    summary.append(\"\")\n",
    "\n",
    "# Test edilen özellikler\n",
    "summary.append(\"TEST EDİLEN ÖZELLİKLER:\")\n",
    "summary.append(\"  ✓ Tek unified pipeline ile tüm kontrol\")\n",
    "summary.append(\"  ✓ WOE transformasyonu ve univariate Gini\")\n",
    "summary.append(\"  ✓ PSI -> VIF -> Correlation -> IV -> Boruta -> Stepwise seçim\")\n",
    "summary.append(\"  ✓ Tüm ML modelleri (Logistic, GAM, CatBoost, LightGBM, XGBoost, RF, ExtraTrees)\")\n",
    "summary.append(\"  ✓ Stage 1 ve Stage 2 kalibrasyon\")\n",
    "summary.append(\"  ✓ Risk band optimizasyonu (Herfindahl, Hosmer-Lemeshow, Binomial)\")\n",
    "summary.append(\"  ✓ Eşit default oranları ile veri bölme\")\n",
    "summary.append(\"  ✓ Data dictionary entegrasyonu\")\n",
    "summary.append(\"  ✓ Deployment kodu üretimi\")\n",
    "\n",
    "# Özeti yazdır\n",
    "for line in summary:\n",
    "    print(line)\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"Pipeline testi başarıyla tamamlandı!\")\n",
    "print(\"=\"*80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (Anaconda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
