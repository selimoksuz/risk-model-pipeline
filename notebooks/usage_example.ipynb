{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Risk Model Pipeline - Notebook Usage Examples\n",
    "\n",
    "Bu notebook risk-model-pipeline paketinin farklı kullanım senaryolarını gösterir."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Paketi Yükleme"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paketi GitHub'dan yükleme\n",
    "!pip install git+https://github.com/selimoksuz/risk-model-pipeline.git\n",
    "\n",
    "# veya local olarak clone'ladıysanız\n",
    "# !pip install -e /path/to/risk-model-pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "import joblib\n",
    "import json\n",
    "\n",
    "# Pipeline imports\n",
    "from risk_pipeline.pipeline16 import Config, RiskModelPipeline\n",
    "from risk_pipeline.utils.scoring import load_model_artifacts, score_data\n",
    "from risk_pipeline.utils.pipeline_runner import run_pipeline_from_dataframe, get_full_config"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Senaryo 1: Sadece Model Eğitimi (Kalibrasyon Yok, Skorlama Yok)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DataFrame hazırlama (sizin verileriniz olacak)\n",
    "train_df = pd.DataFrame({\n",
    "    'app_id': range(1000),\n",
    "    'app_dt': pd.date_range('2024-01-01', periods=1000, freq='D'),\n",
    "    'target': np.random.binomial(1, 0.2, 1000),  # %20 default rate\n",
    "    'age': np.random.randint(18, 70, 1000),\n",
    "    'income': np.random.lognormal(10, 0.5, 1000),\n",
    "    'credit_score': np.random.randint(300, 850, 1000),\n",
    "    'region': np.random.choice(['A', 'B', 'C'], 1000)\n",
    "})\n",
    "\n",
    "print(f\"Training data shape: {train_df.shape}\")\n",
    "print(f\"Default rate: {train_df['target'].mean():.2%}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model eğitimi - SADECE MODEL\n",
    "config = Config(\n",
    "    id_col=\"app_id\",\n",
    "    time_col=\"app_dt\",\n",
    "    target_col=\"target\",\n",
    "    \n",
    "    # Performans ayarları\n",
    "    hpo_trials=5,  # Hızlı test için düşük\n",
    "    hpo_timeout_sec=30,\n",
    "    \n",
    "    # Kalibrasyon YOK\n",
    "    calibration_data_path=None,\n",
    "    \n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# Pipeline çalıştır\n",
    "pipeline = RiskModelPipeline(config)\n",
    "results = pipeline.run(train_df)\n",
    "\n",
    "print(f\"\\nBest Model: {pipeline.best_model_name_}\")\n",
    "print(f\"Final Features: {pipeline.final_vars_}\")\n",
    "print(f\"Model AUC: {results.get('best_auc', 'N/A')}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modeli kaydet\n",
    "model_path = f\"model_{datetime.now().strftime('%Y%m%d_%H%M%S')}.pkl\"\n",
    "joblib.dump(pipeline.models_[pipeline.best_model_name_], model_path)\n",
    "print(f\"Model saved: {model_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Senaryo 2: Model + Kalibrasyon (Skorlama Yok)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Kalibrasyon verisi hazırlama\n",
    "calibration_df = pd.DataFrame({\n",
    "    'app_id': range(2000, 2500),\n",
    "    'app_dt': pd.date_range('2024-06-01', periods=500, freq='D'),\n",
    "    'target': np.random.binomial(1, 0.25, 500),\n",
    "    'age': np.random.randint(18, 70, 500),\n",
    "    'income': np.random.lognormal(10, 0.5, 500),\n",
    "    'credit_score': np.random.randint(300, 850, 500),\n",
    "    'region': np.random.choice(['A', 'B', 'C'], 500)\n",
    "})\n",
    "\n",
    "# Kalibrasyon verisini kaydet\n",
    "calibration_df.to_csv('calibration_data.csv', index=False)\n",
    "print(f\"Calibration data: {calibration_df.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model + Kalibrasyon\n",
    "config_with_cal = Config(\n",
    "    id_col=\"app_id\",\n",
    "    time_col=\"app_dt\",\n",
    "    target_col=\"target\",\n",
    "    \n",
    "    # Kalibrasyon AÇIK\n",
    "    calibration_data_path=\"calibration_data.csv\",\n",
    "    calibration_method=\"isotonic\",  # veya \"sigmoid\"\n",
    "    \n",
    "    hpo_trials=5,\n",
    "    hpo_timeout_sec=30,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "pipeline_cal = RiskModelPipeline(config_with_cal)\n",
    "results_cal = pipeline_cal.run(train_df)\n",
    "\n",
    "print(f\"\\nModel with calibration trained!\")\n",
    "print(f\"Calibrator: {type(pipeline_cal.calibrator_) if hasattr(pipeline_cal, 'calibrator_') else 'None'}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Senaryo 3: Sadece Skorlama (Önceden Eğitilmiş Model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Skorlama verisi hazırlama\n",
    "scoring_df = pd.DataFrame({\n",
    "    'app_id': range(3000, 4000),\n",
    "    'app_dt': pd.date_range('2024-08-01', periods=1000, freq='D'),\n",
    "    'target': [np.nan] * 600 + list(np.random.binomial(1, 0.3, 400)),  # %60'ı targetsız\n",
    "    'age': np.random.randint(18, 70, 1000),\n",
    "    'income': np.random.lognormal(10, 0.5, 1000),\n",
    "    'credit_score': np.random.randint(300, 850, 1000),\n",
    "    'region': np.random.choice(['A', 'B', 'C'], 1000)\n",
    "})\n",
    "\n",
    "print(f\"Scoring data: {scoring_df.shape}\")\n",
    "print(f\"With target: {(~scoring_df['target'].isna()).sum()}\")\n",
    "print(f\"Without target: {scoring_df['target'].isna().sum()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model artifacts'ları yükle\n",
    "run_id = results['run_id']  # Önceki eğitimden\n",
    "output_folder = 'outputs'\n",
    "\n",
    "model, final_features, woe_mapping, calibrator = load_model_artifacts(output_folder, run_id)\n",
    "\n",
    "print(f\"Model loaded: {type(model).__name__}\")\n",
    "print(f\"Calibrator: {'Available' if calibrator else 'Not available'}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Skorlama yap\n",
    "from risk_pipeline.utils.scoring import apply_woe_transform\n",
    "\n",
    "# Training scores for PSI (opsiyonel)\n",
    "train_woe = apply_woe_transform(train_df, woe_mapping)\n",
    "# ... feature mapping logic ...\n",
    "training_scores = None  # PSI istemiyorsanız None bırakabilirsiniz\n",
    "\n",
    "# Skorlama\n",
    "scoring_results = score_data(\n",
    "    scoring_df=scoring_df,\n",
    "    model=model,\n",
    "    final_features=final_features,\n",
    "    woe_mapping=woe_mapping,\n",
    "    calibrator=calibrator,  # Varsa kullanılır\n",
    "    training_scores=training_scores,  # PSI için\n",
    "    feature_mapping=None\n",
    ")\n",
    "\n",
    "print(f\"\\nScoring Results:\")\n",
    "print(f\"Total scored: {scoring_results['n_total']}\")\n",
    "print(f\"With target: {scoring_results['n_with_target']}\")\n",
    "print(f\"Without target: {scoring_results['n_without_target']}\")\n",
    "\n",
    "if 'with_target' in scoring_results:\n",
    "    print(f\"\\nPerformance (with target):\")\n",
    "    print(f\"  AUC: {scoring_results['with_target']['auc']:.3f}\")\n",
    "    print(f\"  Gini: {scoring_results['with_target']['gini']:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Senaryo 4: Sonradan Kalibrasyon Ekleme"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Önceden eğitilmiş model var, şimdi kalibrasyon ekleyelim\n",
    "from sklearn.isotonic import IsotonicRegression\n",
    "from sklearn.calibration import CalibratedClassifierCV\n",
    "\n",
    "# Kalibrasyon verisi hazırla\n",
    "cal_df = pd.DataFrame({\n",
    "    'app_id': range(5000, 5300),\n",
    "    'app_dt': pd.date_range('2024-09-01', periods=300, freq='D'),\n",
    "    'target': np.random.binomial(1, 0.22, 300),\n",
    "    'age': np.random.randint(18, 70, 300),\n",
    "    'income': np.random.lognormal(10, 0.5, 300),\n",
    "    'credit_score': np.random.randint(300, 850, 300),\n",
    "    'region': np.random.choice(['A', 'B', 'C'], 300)\n",
    "})\n",
    "\n",
    "# WOE dönüşümü uygula\n",
    "cal_woe = apply_woe_transform(cal_df, woe_mapping)\n",
    "X_cal = cal_woe[final_features] if isinstance(final_features, list) else cal_woe\n",
    "y_cal = cal_df['target'].values\n",
    "\n",
    "# Model tahminleri al\n",
    "raw_scores = model.predict_proba(X_cal)[:, 1] if hasattr(model, 'predict_proba') else model.predict(X_cal)\n",
    "\n",
    "# Kalibratör eğit\n",
    "calibrator = IsotonicRegression(out_of_bounds='clip')\n",
    "calibrator.fit(raw_scores.reshape(-1, 1), y_cal)\n",
    "\n",
    "# Kalibratörü kaydet\n",
    "joblib.dump(calibrator, f'calibrator_{run_id}.pkl')\n",
    "print(\"Calibrator trained and saved!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Senaryo 5: Tümleşik Kullanım (Helper Function ile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# En kolay kullanım: helper function\n",
    "from risk_pipeline.utils.pipeline_runner import run_pipeline_from_dataframe\n",
    "\n",
    "# Tek fonksiyonda her şey\n",
    "results = run_pipeline_from_dataframe(\n",
    "    df=train_df,\n",
    "    id_col=\"app_id\",\n",
    "    time_col=\"app_dt\",\n",
    "    target_col=\"target\",\n",
    "    \n",
    "    # Opsiyonel parametreler\n",
    "    calibration_data_path=\"calibration_data.csv\",  # İsterseniz\n",
    "    scoring_df=scoring_df,  # İsterseniz\n",
    "    \n",
    "    # Performans\n",
    "    hpo_trials=10,\n",
    "    hpo_timeout_sec=60,\n",
    "    \n",
    "    # Çıktılar\n",
    "    output_folder=\"my_outputs\",\n",
    "    output_excel=\"my_report.xlsx\"\n",
    ")\n",
    "\n",
    "print(f\"\\nPipeline Results:\")\n",
    "print(f\"Best Model: {results['best_model']}\")\n",
    "print(f\"Final Features: {results['final_features']}\")\n",
    "print(f\"Files saved to: {results['output_folder']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Özel Kullanım: Kendi Modelinizi Entegre Etme"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Kendi modelinizi kullanmak isterseniz\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "# Pipeline'dan WOE dönüşümlerini al\n",
    "woe_mapping = pipeline.woe_map\n",
    "final_features = pipeline.final_vars_\n",
    "\n",
    "# WOE dönüşümü uygula\n",
    "from risk_pipeline.stages.woe import apply_woe\n",
    "train_woe = apply_woe(train_df, woe_mapping)\n",
    "X_train = train_woe[final_features]\n",
    "y_train = train_df['target']\n",
    "\n",
    "# Kendi modelinizi eğitin\n",
    "my_model = GradientBoostingClassifier(n_estimators=100, random_state=42)\n",
    "my_model.fit(X_train, y_train)\n",
    "\n",
    "print(\"Custom model trained!\")\n",
    "\n",
    "# Skorlama için kullanabilirsiniz\n",
    "scoring_results = score_data(\n",
    "    scoring_df=scoring_df,\n",
    "    model=my_model,  # Kendi modeliniz\n",
    "    final_features=final_features,\n",
    "    woe_mapping=woe_mapping,\n",
    "    calibrator=None,  # İsterseniz ekleyin\n",
    "    training_scores=None\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Batch Scoring Örneği"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Büyük veri için batch scoring\n",
    "def batch_score(df, model, features, woe_mapping, batch_size=1000):\n",
    "    \"\"\"Score large datasets in batches\"\"\"\n",
    "    all_scores = []\n",
    "    \n",
    "    for i in range(0, len(df), batch_size):\n",
    "        batch = df.iloc[i:i+batch_size]\n",
    "        \n",
    "        # Score batch\n",
    "        batch_results = score_data(\n",
    "            scoring_df=batch,\n",
    "            model=model,\n",
    "            final_features=features,\n",
    "            woe_mapping=woe_mapping,\n",
    "            calibrator=None,\n",
    "            training_scores=None\n",
    "        )\n",
    "        \n",
    "        all_scores.extend(batch_results['scores'])\n",
    "        print(f\"Batch {i//batch_size + 1}: {len(batch)} records scored\")\n",
    "    \n",
    "    return np.array(all_scores)\n",
    "\n",
    "# Kullanım\n",
    "large_df = pd.concat([scoring_df] * 10)  # 10,000 rows\n",
    "scores = batch_score(large_df, model, final_features, woe_mapping)\n",
    "print(f\"\\nTotal scored: {len(scores)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Model Performans Monitoring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Zaman içinde PSI takibi\n",
    "def monitor_psi(model, features, woe_mapping, training_scores, new_data_list):\n",
    "    \"\"\"Monitor PSI over time\"\"\"\n",
    "    psi_history = []\n",
    "    \n",
    "    for period, new_df in enumerate(new_data_list):\n",
    "        results = score_data(\n",
    "            scoring_df=new_df,\n",
    "            model=model,\n",
    "            final_features=features,\n",
    "            woe_mapping=woe_mapping,\n",
    "            calibrator=None,\n",
    "            training_scores=training_scores\n",
    "        )\n",
    "        \n",
    "        psi = results.get('psi_score', None)\n",
    "        if psi:\n",
    "            psi_history.append({\n",
    "                'period': period,\n",
    "                'psi': psi,\n",
    "                'status': 'Stable' if psi < 0.1 else 'Drift' if psi < 0.25 else 'Significant Drift'\n",
    "            })\n",
    "    \n",
    "    return pd.DataFrame(psi_history)\n",
    "\n",
    "# Simülasyon\n",
    "monthly_data = [scoring_df.sample(100) for _ in range(6)]  # 6 aylık veri\n",
    "psi_df = monitor_psi(model, final_features, woe_mapping, training_scores, monthly_data)\n",
    "print(psi_df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}